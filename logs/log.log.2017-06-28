2017-06-28 09:32:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 09:32:16  [ main:167 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 09:32:16  [ main:171 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 09:32:16  [ main:172 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 09:32:16  [ main:180 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 09:32:16  [ main:180 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 09:32:16  [ main:180 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 09:32:16  [ main:181 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 09:32:16  [ main:182 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 09:32:16  [ main:182 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 09:32:16  [ main:183 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 09:32:16  [ main:187 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 09:32:16  [ main:187 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 09:32:16  [ main:188 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 09:32:16  [ main:188 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 09:32:16  [ main:188 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 09:32:16  [ main:190 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 09:32:16  [ main:190 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 09:32:16  [ main:190 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 09:32:16  [ main:190 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 09:32:16  [ kafka-producer-network-thread | DemoProducer1:196 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 09:32:16  [ main:197 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 09:32:16  [ main:198 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 09:32:16  [ main:198 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 09:32:16  [ main:201 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 09:32:16  [ main:201 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 09:32:16  [ main:207 ] - [ DEBUG ]  Kafka producer started
2017-06-28 09:32:32  [ main:16279 ] - [ INFO ]  user number : 190596  , send message count : 3303507
2017-06-28 09:33:18  [ main:61876 ] - [ INFO ]  user number : 190597  , send message count : 3303509
2017-06-28 09:34:32  [ main:136118 ] - [ INFO ]  user number : 190598  , send message count : 3303514
2017-06-28 09:35:26  [ main:190351 ] - [ INFO ]  user number : 190598  , send message count : 3303519
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300199 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300199 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300241 ] - [ DEBUG ]  Added sensor with name node--2.bytes-sent
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300242 ] - [ DEBUG ]  Added sensor with name node--2.bytes-received
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300242 ] - [ DEBUG ]  Added sensor with name node--2.latency
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300243 ] - [ DEBUG ]  Completed connection to node -2
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300257 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -2
2017-06-28 09:37:16  [ kafka-producer-network-thread | DemoProducer1:300261 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 09:38:16  [ main:359779 ] - [ INFO ]  user number : 190598  , send message count : 3303521
2017-06-28 09:38:36  [ main:380573 ] - [ INFO ]  user number : 190598  , send message count : 3303523
2017-06-28 09:38:55  [ main:399121 ] - [ INFO ]  user number : 190599  , send message count : 3303528
2017-06-28 09:41:31  [ main:554951 ] - [ INFO ]  user number : 190599  , send message count : 3303533
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600288 ] - [ DEBUG ]  Initialize connection to node 4 for sending metadata request
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600289 ] - [ DEBUG ]  Initiating connection to node 4 at 192.168.0.221:9092.
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600289 ] - [ DEBUG ]  Added sensor with name node-4.bytes-sent
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600290 ] - [ DEBUG ]  Added sensor with name node-4.bytes-received
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600290 ] - [ DEBUG ]  Added sensor with name node-4.latency
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600290 ] - [ DEBUG ]  Completed connection to node 4
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600390 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 09:42:16  [ kafka-producer-network-thread | DemoProducer1:600391 ] - [ DEBUG ]  Updated cluster metadata version 3 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 09:43:16  [ main:660422 ] - [ INFO ]  user number : 190600  , send message count : 3303541
2017-06-28 09:46:12  [ main:836001 ] - [ INFO ]  user number : 190600  , send message count : 3303543
2017-06-28 09:46:16  [ kafka-producer-network-thread | DemoProducer1:840602 ] - [ DEBUG ]  Node -2 disconnected.
2017-06-28 09:46:16  [ kafka-producer-network-thread | DemoProducer1:840603 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 09:46:16  [ kafka-producer-network-thread | DemoProducer1:840604 ] - [ DEBUG ]  Updated cluster metadata version 4 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 09:47:18  [ main:902122 ] - [ INFO ]  user number : 190601  , send message count : 3303551
2017-06-28 09:49:21  [ main:1025252 ] - [ INFO ]  user number : 190601  , send message count : 3303556
2017-06-28 09:50:54  [ main:1118654 ] - [ INFO ]  user number : 190601  , send message count : 3303558
2017-06-28 09:51:11  [ main:1135664 ] - [ INFO ]  user number : 190602  , send message count : 3303566
2017-06-28 09:51:16  [ kafka-producer-network-thread | DemoProducer1:1140634 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 09:51:16  [ kafka-producer-network-thread | DemoProducer1:1140635 ] - [ DEBUG ]  Updated cluster metadata version 5 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 09:54:10  [ main:1314489 ] - [ INFO ]  user number : 190603  , send message count : 3303587
2017-06-28 09:56:16  [ kafka-producer-network-thread | DemoProducer1:1440659 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 09:56:16  [ kafka-producer-network-thread | DemoProducer1:1440660 ] - [ DEBUG ]  Updated cluster metadata version 6 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 09:57:01  [ main:1485169 ] - [ INFO ]  user number : 190604  , send message count : 3303598
2017-06-28 09:57:40  [ main:1524580 ] - [ INFO ]  user number : 190604  , send message count : 3303618
2017-06-28 09:57:59  [ main:1542756 ] - [ INFO ]  user number : 190604  , send message count : 3303620
2017-06-28 09:58:52  [ main:1596218 ] - [ INFO ]  user number : 190605  , send message count : 3303628
2017-06-28 10:01:16  [ kafka-producer-network-thread | DemoProducer1:1740685 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:01:16  [ kafka-producer-network-thread | DemoProducer1:1740686 ] - [ DEBUG ]  Updated cluster metadata version 7 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 10:01:48  [ main:1772039 ] - [ INFO ]  user number : 190606  , send message count : 3303630
2017-06-28 10:04:16  [ main:1920343 ] - [ INFO ]  user number : 190606  , send message count : 3303632
2017-06-28 10:05:24  [ main:1988518 ] - [ INFO ]  user number : 190607  , send message count : 3303650
2017-06-28 10:06:16  [ kafka-producer-network-thread | DemoProducer1:2040716 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:06:16  [ kafka-producer-network-thread | DemoProducer1:2040717 ] - [ DEBUG ]  Updated cluster metadata version 8 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:07:39  [ main:2123702 ] - [ INFO ]  user number : 190608  , send message count : 3303658
2017-06-28 10:08:35  [ main:2179377 ] - [ INFO ]  user number : 190609  , send message count : 3303660
2017-06-28 10:10:27  [ main:2291433 ] - [ INFO ]  user number : 190609  , send message count : 3303662
2017-06-28 10:11:17  [ kafka-producer-network-thread | DemoProducer1:2340747 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:11:17  [ kafka-producer-network-thread | DemoProducer1:2340748 ] - [ DEBUG ]  Updated cluster metadata version 9 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:12:11  [ main:2395255 ] - [ INFO ]  user number : 190610  , send message count : 3303664
2017-06-28 10:14:15  [ main:2518949 ] - [ INFO ]  user number : 190610  , send message count : 3303678
2017-06-28 10:16:17  [ kafka-producer-network-thread | DemoProducer1:2640768 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:16:17  [ kafka-producer-network-thread | DemoProducer1:2640769 ] - [ DEBUG ]  Updated cluster metadata version 10 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 10:16:53  [ main:2677339 ] - [ INFO ]  user number : 190611  , send message count : 3303686
2017-06-28 10:19:51  [ main:2855068 ] - [ INFO ]  user number : 190611  , send message count : 3303688
2017-06-28 10:21:15  [ main:2939579 ] - [ INFO ]  user number : 190612  , send message count : 3303693
2017-06-28 10:21:17  [ kafka-producer-network-thread | DemoProducer1:2940798 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:21:17  [ kafka-producer-network-thread | DemoProducer1:2940799 ] - [ DEBUG ]  Updated cluster metadata version 11 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:22:25  [ main:3009721 ] - [ INFO ]  user number : 190612  , send message count : 3303705
2017-06-28 10:25:10  [ main:3173776 ] - [ INFO ]  user number : 190613  , send message count : 3303707
2017-06-28 10:25:16  [ main:3180023 ] - [ INFO ]  user number : 190613  , send message count : 3303709
2017-06-28 10:26:17  [ kafka-producer-network-thread | DemoProducer1:3240826 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:26:17  [ kafka-producer-network-thread | DemoProducer1:3240827 ] - [ DEBUG ]  Updated cluster metadata version 12 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 10:27:27  [ main:3311674 ] - [ INFO ]  user number : 190613  , send message count : 3303711
2017-06-28 10:27:59  [ main:3343466 ] - [ INFO ]  user number : 190614  , send message count : 3303716
2017-06-28 10:29:08  [ main:3411786 ] - [ INFO ]  user number : 190614  , send message count : 3303721
2017-06-28 10:30:42  [ main:3506017 ] - [ INFO ]  user number : 190615  , send message count : 3303723
2017-06-28 10:31:17  [ kafka-producer-network-thread | DemoProducer1:3540856 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:31:17  [ kafka-producer-network-thread | DemoProducer1:3540857 ] - [ DEBUG ]  Updated cluster metadata version 13 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:33:27  [ main:3671600 ] - [ INFO ]  user number : 190615  , send message count : 3303731
2017-06-28 10:34:38  [ main:3741749 ] - [ INFO ]  user number : 190615  , send message count : 3303736
2017-06-28 10:35:21  [ main:3785174 ] - [ INFO ]  user number : 190615  , send message count : 3303738
2017-06-28 10:36:17  [ kafka-producer-network-thread | DemoProducer1:3840880 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:36:17  [ kafka-producer-network-thread | DemoProducer1:3840881 ] - [ DEBUG ]  Updated cluster metadata version 14 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 10:38:11  [ main:3954739 ] - [ INFO ]  user number : 190615  , send message count : 3303752
2017-06-28 10:39:03  [ main:4006927 ] - [ INFO ]  user number : 190615  , send message count : 3303769
2017-06-28 10:41:17  [ kafka-producer-network-thread | DemoProducer1:4140910 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:41:17  [ kafka-producer-network-thread | DemoProducer1:4140912 ] - [ DEBUG ]  Updated cluster metadata version 15 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:41:35  [ main:4158927 ] - [ INFO ]  user number : 190615  , send message count : 3303774
2017-06-28 10:44:10  [ main:4314621 ] - [ INFO ]  user number : 190615  , send message count : 3303776
2017-06-28 10:44:31  [ main:4335226 ] - [ INFO ]  user number : 190615  , send message count : 3303778
2017-06-28 10:46:17  [ kafka-producer-network-thread | DemoProducer1:4440942 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:46:17  [ kafka-producer-network-thread | DemoProducer1:4440943 ] - [ DEBUG ]  Updated cluster metadata version 16 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:47:13  [ main:4497641 ] - [ INFO ]  user number : 190615  , send message count : 3303789
2017-06-28 10:47:46  [ main:4530591 ] - [ INFO ]  user number : 190615  , send message count : 3303791
2017-06-28 10:50:30  [ main:4693965 ] - [ INFO ]  user number : 190615  , send message count : 3303793
2017-06-28 10:51:17  [ kafka-producer-network-thread | DemoProducer1:4740971 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:51:17  [ kafka-producer-network-thread | DemoProducer1:4740972 ] - [ DEBUG ]  Updated cluster metadata version 17 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 10:52:41  [ main:4825601 ] - [ INFO ]  user number : 190616  , send message count : 3303798
2017-06-28 10:55:23  [ main:4987162 ] - [ INFO ]  user number : 190617  , send message count : 3303806
2017-06-28 10:56:17  [ kafka-producer-network-thread | DemoProducer1:5041000 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 10:56:17  [ kafka-producer-network-thread | DemoProducer1:5041001 ] - [ DEBUG ]  Updated cluster metadata version 18 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 10:56:56  [ main:5080057 ] - [ INFO ]  user number : 190618  , send message count : 3303808
2017-06-28 10:58:26  [ main:5170210 ] - [ INFO ]  user number : 190619  , send message count : 3303819
2017-06-28 11:00:08  [ main:5272414 ] - [ INFO ]  user number : 190619  , send message count : 3303821
2017-06-28 11:00:20  [ main:5284076 ] - [ INFO ]  user number : 190619  , send message count : 3303826
2017-06-28 11:01:17  [ kafka-producer-network-thread | DemoProducer1:5341031 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 11:01:17  [ kafka-producer-network-thread | DemoProducer1:5341032 ] - [ DEBUG ]  Updated cluster metadata version 19 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 11:01:48  [ main:5372626 ] - [ INFO ]  user number : 190620  , send message count : 3303844
2017-06-28 11:02:02  [ main:5386216 ] - [ INFO ]  user number : 190621  , send message count : 3303856
2017-06-28 11:03:06  [ main:5449998 ] - [ INFO ]  user number : 190621  , send message count : 3303858
2017-06-28 11:04:06  [ main:5510469 ] - [ INFO ]  user number : 190621  , send message count : 3303860
2017-06-28 11:06:17  [ kafka-producer-network-thread | DemoProducer1:5641062 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 11:06:17  [ kafka-producer-network-thread | DemoProducer1:5641063 ] - [ DEBUG ]  Updated cluster metadata version 20 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 11:06:24  [ main:5648310 ] - [ INFO ]  user number : 190622  , send message count : 3303871
2017-06-28 11:09:00  [ main:5803820 ] - [ INFO ]  user number : 190623  , send message count : 3303873
2017-06-28 11:10:57  [ main:5921388 ] - [ INFO ]  user number : 190623  , send message count : 3303878
2017-06-28 11:11:17  [ kafka-producer-network-thread | DemoProducer1:5941092 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 11:11:17  [ kafka-producer-network-thread | DemoProducer1:5941094 ] - [ DEBUG ]  Updated cluster metadata version 21 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 11:11:37  [ main:5960935 ] - [ INFO ]  user number : 190623  , send message count : 3303880
2017-06-28 11:13:52  [ main:6096140 ] - [ INFO ]  user number : 190624  , send message count : 3303888
2017-06-28 11:14:05  [ main:6109725 ] - [ INFO ]  user number : 190625  , send message count : 3303890
2017-06-28 11:15:07  [ main:6171114 ] - [ INFO ]  user number : 190625  , send message count : 3303892
2017-06-28 11:16:17  [ kafka-producer-network-thread | DemoProducer1:6241122 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 11:16:17  [ kafka-producer-network-thread | DemoProducer1:6241123 ] - [ DEBUG ]  Updated cluster metadata version 22 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 11:17:33  [ main:6316991 ] - [ INFO ]  user number : 190625  , send message count : 3303900
2017-06-28 11:18:30  [ main:6373816 ] - [ INFO ]  user number : 190625  , send message count : 3303902
2017-06-28 11:20:25  [ main:6489427 ] - [ INFO ]  user number : 190625  , send message count : 3303904
2017-06-28 11:21:17  [ kafka-producer-network-thread | DemoProducer1:6541152 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 4
2017-06-28 11:21:17  [ kafka-producer-network-thread | DemoProducer1:6541153 ] - [ DEBUG ]  Updated cluster metadata version 23 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 11:21:47  [ main:6571045 ] - [ INFO ]  user number : 190625  , send message count : 3303906
2017-06-28 11:23:17  [ main:6660999 ] - [ INFO ]  user number : 190625  , send message count : 3303908
2017-06-28 11:24:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:24:54  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 11:24:54  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 11:24:54  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 11:24:54  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 11:24:54  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 11:24:54  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 11:24:54  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 11:24:54  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 11:24:54  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 11:24:54  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 11:24:54  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 11:24:54  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 11:24:54  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 11:24:54  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 11:24:54  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 11:24:54  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 11:24:54  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 11:24:54  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 11:24:54  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 11:24:54  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 11:24:54  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:24:54  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 11:24:54  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 11:24:54  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 11:24:54  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 11:24:54  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-28 11:25:11  [ main:16670 ] - [ INFO ]  user number : 190522  , send message count : 3295528
2017-06-28 11:39:16  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:39:16  [ main:80 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 11:39:16  [ main:86 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 11:39:16  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 11:39:17  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 11:39:17  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 11:39:17  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 11:39:17  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 11:39:17  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 11:39:17  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 11:39:17  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 11:39:17  [ main:109 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 11:39:17  [ main:110 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 11:39:17  [ main:110 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 11:39:17  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 11:39:17  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 11:39:17  [ main:121 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 11:39:17  [ main:122 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 11:39:17  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 11:39:17  [ main:123 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 11:39:17  [ kafka-producer-network-thread | DemoProducer1:126 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 11:39:17  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:39:17  [ main:127 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 11:39:17  [ main:127 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 11:39:17  [ main:135 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 11:39:17  [ main:135 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 11:39:17  [ main:136 ] - [ DEBUG ]  Kafka producer started
2017-06-28 11:39:33  [ main:16526 ] - [ INFO ]  user number : 190403  , send message count : 3306840
2017-06-28 11:40:50  [ main:93899 ] - [ INFO ]  user number : 190404  , send message count : 3306845
2017-06-28 11:42:50  [ main:213510 ] - [ INFO ]  user number : 190405  , send message count : 3306853
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300118 ] - [ DEBUG ]  Initialize connection to node -3 for sending metadata request
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300118 ] - [ DEBUG ]  Initiating connection to node -3 at 192.168.0.222:9092.
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300171 ] - [ DEBUG ]  Added sensor with name node--3.bytes-sent
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300171 ] - [ DEBUG ]  Added sensor with name node--3.bytes-received
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300171 ] - [ DEBUG ]  Added sensor with name node--3.latency
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300172 ] - [ DEBUG ]  Completed connection to node -3
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300188 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -3
2017-06-28 11:44:17  [ kafka-producer-network-thread | DemoProducer1:300192 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-28 11:44:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:44:55  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 11:44:55  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 11:44:55  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 11:44:55  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 11:44:55  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 11:44:55  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 11:44:55  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 11:44:55  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 11:44:55  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 11:44:55  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 11:44:55  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 11:44:55  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 11:44:55  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 11:44:55  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 11:44:55  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 11:44:55  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 11:44:55  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 11:44:55  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 11:44:55  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 11:44:55  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 11:44:55  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:44:55  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 11:44:55  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 11:44:55  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 11:44:55  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 11:44:55  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-28 11:45:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:45:04  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 11:45:04  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 11:45:04  [ main:90 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 11:45:04  [ main:97 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 11:45:04  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 11:45:04  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 11:45:04  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 11:45:04  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 11:45:04  [ main:100 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 11:45:04  [ main:101 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 11:45:04  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 11:45:04  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 11:45:04  [ main:106 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 11:45:04  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 11:45:04  [ main:107 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 11:45:04  [ main:110 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 11:45:04  [ main:111 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 11:45:04  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 11:45:04  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 11:45:04  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 11:45:04  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 11:45:04  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 11:45:04  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 11:45:04  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 11:45:04  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 11:45:04  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-28 11:45:21  [ main:16857 ] - [ INFO ]  user number : 189498  , send message count : 3295834
2017-06-28 11:46:41  [ main:97630 ] - [ INFO ]  user number : 189498  , send message count : 3295843
2017-06-28 11:47:40  [ main:156473 ] - [ INFO ]  user number : 189499  , send message count : 3295845
2017-06-28 11:49:32  [ main:268086 ] - [ INFO ]  user number : 189500  , send message count : 3295847
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300115 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300116 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300158 ] - [ DEBUG ]  Added sensor with name node--2.bytes-sent
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300159 ] - [ DEBUG ]  Added sensor with name node--2.bytes-received
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300159 ] - [ DEBUG ]  Added sensor with name node--2.latency
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300160 ] - [ DEBUG ]  Completed connection to node -2
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300175 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -2
2017-06-28 11:50:04  [ kafka-producer-network-thread | DemoProducer1:300178 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 11:51:19  [ main:374886 ] - [ INFO ]  user number : 189501  , send message count : 3295855
2017-06-28 11:52:19  [ main:435327 ] - [ INFO ]  user number : 189502  , send message count : 3295857
2017-06-28 11:53:27  [ main:503119 ] - [ INFO ]  user number : 189503  , send message count : 3295865
2017-06-28 11:53:54  [ main:529745 ] - [ INFO ]  user number : 189503  , send message count : 3295879
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600206 ] - [ DEBUG ]  Initialize connection to node 3 for sending metadata request
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600206 ] - [ DEBUG ]  Initiating connection to node 3 at 192.168.0.220:9092.
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600207 ] - [ DEBUG ]  Added sensor with name node-3.bytes-sent
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600207 ] - [ DEBUG ]  Added sensor with name node-3.bytes-received
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600207 ] - [ DEBUG ]  Added sensor with name node-3.latency
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600208 ] - [ DEBUG ]  Completed connection to node 3
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600306 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 3
2017-06-28 11:55:04  [ kafka-producer-network-thread | DemoProducer1:600309 ] - [ DEBUG ]  Updated cluster metadata version 3 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 11:55:54  [ main:650201 ] - [ INFO ]  user number : 189504  , send message count : 3295881
2017-06-28 11:57:38  [ main:753684 ] - [ INFO ]  user number : 189505  , send message count : 3295883
2017-06-28 11:59:04  [ kafka-producer-network-thread | DemoProducer1:840514 ] - [ DEBUG ]  Node -2 disconnected.
2017-06-28 11:59:04  [ kafka-producer-network-thread | DemoProducer1:840514 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 3
2017-06-28 11:59:04  [ kafka-producer-network-thread | DemoProducer1:840515 ] - [ DEBUG ]  Updated cluster metadata version 4 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [])
2017-06-28 11:59:22  [ main:857722 ] - [ INFO ]  user number : 189505  , send message count : 3295900
2017-06-28 12:01:35  [ main:990932 ] - [ INFO ]  user number : 189505  , send message count : 3295908
2017-06-28 12:01:55  [ main:1011291 ] - [ INFO ]  user number : 189505  , send message count : 3295914
2017-06-28 12:01:57  [ main:1012703 ] - [ INFO ]  user number : 189506  , send message count : 3295925
2017-06-28 12:02:10  [ main:1025851 ] - [ INFO ]  user number : 189507  , send message count : 3295931
2017-06-28 12:04:04  [ kafka-producer-network-thread | DemoProducer1:1140543 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node 3
2017-06-28 12:04:04  [ kafka-producer-network-thread | DemoProducer1:1140544 ] - [ DEBUG ]  Updated cluster metadata version 5 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [])
2017-06-28 12:04:36  [ main:1172606 ] - [ INFO ]  user number : 189508  , send message count : 3295939
2017-06-28 12:05:21  [ main:1217528 ] - [ INFO ]  user number : 189508  , send message count : 3295941
2017-06-28 12:05:28  [ main:1224541 ] - [ INFO ]  user number : 189509  , send message count : 3295943
2017-06-28 12:06:07  [ main:1263166 ] - [ INFO ]  user number : 189509  , send message count : 3295948
2017-06-28 12:06:21  [ main:1277490 ] - [ INFO ]  user number : 189509  , send message count : 3295965
2017-06-28 14:10:12  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:10:13  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:10:13  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:10:13  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:10:13  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:10:13  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:10:13  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:10:13  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:10:13  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:10:13  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:10:13  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:10:13  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:10:13  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:10:13  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:10:13  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:10:13  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:10:13  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:10:13  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:10:13  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:10:13  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:10:13  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:10:13  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:10:13  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:10:13  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:10:13  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:10:13  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:10:13  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:11:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:11:07  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:11:07  [ main:90 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:11:07  [ main:93 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:11:07  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:11:07  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:11:07  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:11:07  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:11:07  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:11:07  [ main:102 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:11:07  [ main:103 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:11:07  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:11:07  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:11:07  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:11:07  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:11:07  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:11:08  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:11:08  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:11:08  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:11:08  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:11:08  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:11:08  [ main:134 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:11:08  [ main:134 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:11:08  [ kafka-producer-network-thread | DemoProducer1:134 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:11:08  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:11:08  [ main:137 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:11:08  [ main:138 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:12:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:31  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:12:31  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:12:31  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:12:31  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:12:31  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:12:31  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:12:31  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:12:31  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:12:31  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:12:31  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:12:31  [ main:104 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:12:31  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:12:31  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:12:31  [ main:105 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:12:31  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:12:31  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:12:31  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:12:31  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:12:31  [ main:108 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:12:31  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:12:31  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:31  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:12:31  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:12:31  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:12:31  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:12:31  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:12:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:35  [ main:115 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:12:35  [ main:121 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:12:35  [ main:126 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 14:12:35  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:12:35  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:12:35  [ main:135 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:12:35  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:12:35  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:12:35  [ main:138 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:12:35  [ main:139 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:12:35  [ main:146 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:12:35  [ main:147 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:12:35  [ main:147 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:12:35  [ main:148 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:12:35  [ main:149 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:12:35  [ main:160 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:12:35  [ main:160 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:12:35  [ main:160 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:12:35  [ main:160 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:12:35  [ main:170 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:35  [ kafka-producer-network-thread | DemoProducer1:171 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:12:35  [ main:172 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:12:35  [ main:172 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:12:35  [ main:190 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:12:35  [ main:190 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:12:35  [ main:194 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:12:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:38  [ main:77 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:12:38  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:12:38  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:12:38  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:12:38  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:12:38  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:12:38  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:12:38  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:12:38  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:12:38  [ main:99 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:12:38  [ main:103 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:12:38  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:12:38  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:12:38  [ main:105 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:12:38  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:12:38  [ main:108 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:12:38  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:12:38  [ main:108 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:12:38  [ main:109 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:12:38  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:12:38  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:12:38  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:12:38  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:12:38  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:12:38  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:12:38  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:13:01  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:01  [ main:100 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:13:01  [ main:105 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:13:01  [ main:126 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 14:13:01  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:13:01  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:13:01  [ main:135 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:13:01  [ main:141 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:13:01  [ main:143 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:13:01  [ main:143 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:13:01  [ main:144 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:13:01  [ main:148 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:13:01  [ main:149 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:13:01  [ main:149 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:13:01  [ main:150 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:13:01  [ main:151 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:13:01  [ main:156 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:13:01  [ main:160 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:13:01  [ main:160 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:13:01  [ main:161 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:13:01  [ main:165 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:01  [ kafka-producer-network-thread | DemoProducer1:166 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:13:01  [ main:173 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:13:01  [ main:173 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:13:01  [ main:178 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:13:01  [ main:179 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:13:01  [ main:179 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:13:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:06  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:13:06  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:13:06  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:13:06  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:13:06  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:13:06  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:13:06  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:13:06  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:13:06  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:13:06  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:13:06  [ main:103 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:13:06  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:13:06  [ main:104 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:13:06  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:13:06  [ main:108 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:13:06  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:13:06  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:13:06  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:13:06  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:13:06  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:13:06  [ main:120 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:06  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:13:06  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:13:06  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:13:06  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:13:06  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:13:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:59  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:13:59  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:13:59  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:13:59  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:13:59  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:13:59  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:13:59  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:13:59  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:13:59  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:13:59  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:13:59  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:13:59  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:13:59  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:13:59  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:13:59  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:13:59  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:13:59  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:13:59  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:13:59  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:13:59  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:13:59  [ main:112 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:13:59  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:13:59  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:13:59  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:13:59  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:13:59  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-28 14:15:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:15:33  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 14:15:33  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 14:15:33  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 14:15:33  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 14:15:33  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 14:15:33  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 14:15:33  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 14:15:33  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 14:15:33  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 14:15:33  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 14:15:33  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 14:15:33  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 14:15:33  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 14:15:33  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 14:15:33  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 14:15:33  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 14:15:33  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 14:15:33  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 14:15:33  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 14:15:33  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 14:15:33  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 14:15:33  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0627 was supplied but isn't a known config.
2017-06-28 14:15:33  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 14:15:33  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 14:15:33  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 14:15:33  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-28 15:46:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 15:46:20  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 15:46:20  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 15:46:20  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 15:46:20  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 15:46:20  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 15:46:20  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 15:46:20  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 15:46:20  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 15:46:20  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 15:46:20  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 15:46:20  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 15:46:20  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 15:46:20  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 15:46:20  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 15:46:20  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 15:46:20  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 15:46:20  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 15:46:20  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 15:46:20  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 15:46:20  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 15:46:20  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 15:46:20  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 15:46:20  [ kafka-producer-network-thread | DemoProducer1:124 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 15:46:20  [ main:136 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 15:46:20  [ main:136 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 15:46:20  [ main:137 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:19:00  [ main:2 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:00  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:19:00  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:19:00  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:19:00  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:19:00  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:19:00  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:19:00  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:19:00  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:19:00  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:19:00  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:19:00  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:19:00  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:19:00  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:19:00  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:19:00  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:19:00  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:19:00  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:19:00  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:19:00  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:19:00  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:19:00  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:00  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:19:00  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:19:00  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:19:00  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:19:00  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:19:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:18  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:19:18  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:19:18  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:19:18  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:19:18  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:19:18  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:19:18  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:19:18  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:19:18  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:19:18  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:19:19  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:19:19  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:19:19  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:19:19  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:19:19  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:19:19  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:19:19  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:19:19  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:19:19  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:19:19  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:19:19  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:19  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:19:19  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:19:19  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:19:19  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:19:19  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:19:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:21  [ main:88 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:19:21  [ main:96 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:19:21  [ main:102 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 16:19:21  [ main:111 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:19:21  [ main:111 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:19:21  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:19:21  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:19:21  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:19:21  [ main:114 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:19:21  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:19:21  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:19:21  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:19:21  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:19:21  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:19:21  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:19:21  [ main:122 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:19:21  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:19:21  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:19:21  [ main:123 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:19:21  [ kafka-producer-network-thread | DemoProducer1:132 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:19:21  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:21  [ main:133 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:19:21  [ main:133 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:19:21  [ main:136 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:19:21  [ main:136 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:19:21  [ main:137 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:19:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:23  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:19:23  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:19:23  [ main:98 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:19:23  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:19:23  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:19:23  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:19:23  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:19:23  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:19:23  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:19:23  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:19:23  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:19:23  [ main:118 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:19:23  [ main:118 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:19:23  [ main:119 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:19:23  [ main:119 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:19:23  [ main:126 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:19:23  [ main:126 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:19:23  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:19:23  [ main:127 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:19:23  [ main:146 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:23  [ main:147 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:19:23  [ main:147 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:19:23  [ kafka-producer-network-thread | DemoProducer1:156 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:19:23  [ main:163 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:19:23  [ main:164 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:19:23  [ main:175 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:19:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:25  [ main:103 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:19:25  [ main:123 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:19:25  [ main:125 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 16:19:25  [ main:136 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:19:25  [ main:136 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:19:25  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:19:25  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:19:25  [ main:139 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:19:25  [ main:139 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:19:25  [ main:140 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:19:25  [ main:144 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:19:25  [ main:145 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:19:25  [ main:146 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:19:25  [ main:147 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:19:25  [ main:148 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:19:25  [ main:150 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:19:25  [ main:151 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:19:25  [ main:152 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:19:25  [ main:152 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:19:25  [ kafka-producer-network-thread | DemoProducer1:154 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:19:25  [ main:155 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:19:25  [ main:156 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:19:25  [ main:156 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:19:25  [ main:160 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:19:25  [ main:170 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:19:25  [ main:178 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:21:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:21:17  [ main:131 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:21:17  [ main:138 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:21:17  [ main:143 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 16:21:17  [ main:157 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:21:17  [ main:157 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:21:17  [ main:158 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:21:17  [ main:159 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:21:17  [ main:161 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:21:17  [ main:161 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:21:17  [ main:162 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:21:17  [ main:167 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:21:17  [ main:168 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:21:17  [ main:169 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:21:17  [ main:170 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:21:17  [ main:171 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:21:17  [ main:179 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:21:17  [ main:179 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:21:17  [ main:179 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:21:17  [ main:180 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:21:17  [ kafka-producer-network-thread | DemoProducer1:182 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:21:17  [ main:183 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:21:17  [ main:184 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:21:17  [ main:184 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:21:17  [ main:202 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:21:17  [ main:203 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:21:17  [ main:206 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:21:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:21:57  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:21:57  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:21:57  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 16:21:57  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:21:57  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:21:57  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:21:57  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:21:57  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:21:57  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:21:57  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:21:57  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:21:57  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:21:57  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:21:57  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:21:57  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:21:57  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:21:57  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:21:57  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:21:57  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:21:57  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:21:57  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:21:57  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:21:57  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:21:57  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:21:57  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:21:57  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:22:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:22:16  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:22:16  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:22:16  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 16:22:16  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:22:16  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:22:16  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:22:16  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:22:16  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:22:16  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:22:16  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:22:16  [ main:99 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:22:16  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:22:16  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:22:16  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:22:16  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:22:16  [ main:106 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:22:16  [ main:106 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:22:16  [ main:106 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:22:16  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:22:16  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:22:16  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:22:16  [ main:121 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:22:16  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:22:16  [ main:124 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:22:16  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:22:16  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:23:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:23:07  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:23:07  [ main:83 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:23:07  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:23:07  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:23:07  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:23:07  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:23:07  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:23:07  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:23:07  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:23:07  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:23:07  [ main:104 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:23:07  [ main:105 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:23:07  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:23:07  [ main:105 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:23:07  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:23:07  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:23:07  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:23:07  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:23:07  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:23:07  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:23:07  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:23:07  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:23:07  [ main:116 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:23:07  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:23:07  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:23:07  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:26:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:26:49  [ main:95 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:26:49  [ main:103 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:26:49  [ main:108 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 16:26:49  [ main:123 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:26:49  [ main:123 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:26:49  [ main:124 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:26:49  [ main:125 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:26:49  [ main:127 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:26:49  [ main:127 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:26:49  [ main:128 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:26:49  [ main:133 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:26:49  [ main:134 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:26:49  [ main:135 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:26:49  [ main:135 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:26:49  [ main:135 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:26:49  [ main:145 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:26:49  [ main:146 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:26:49  [ main:146 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:26:49  [ main:146 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:26:49  [ kafka-producer-network-thread | DemoProducer1:149 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:26:49  [ main:150 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:26:49  [ main:150 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:26:49  [ main:151 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:26:49  [ main:168 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:26:49  [ main:168 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:26:49  [ main:172 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:30:01  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:30:01  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:30:01  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:30:01  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 16:30:01  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:30:01  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:30:01  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:30:01  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:30:01  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:30:01  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:30:01  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:30:01  [ main:103 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:30:01  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:30:01  [ main:104 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:30:01  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:30:01  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:30:01  [ main:106 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:30:01  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:30:01  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:30:01  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:30:01  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:30:01  [ main:114 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:30:01  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:30:01  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:30:01  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:30:01  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:30:01  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:30:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:30:33  [ main:83 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:30:33  [ main:90 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:30:33  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:30:33  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:30:33  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:30:33  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:30:33  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:30:33  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:30:33  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:30:33  [ main:114 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:30:33  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:30:33  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:30:33  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:30:33  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:30:33  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:30:33  [ main:123 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:30:33  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:30:33  [ main:124 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:30:33  [ main:124 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:30:33  [ kafka-producer-network-thread | DemoProducer1:134 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:30:33  [ main:136 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:30:33  [ main:137 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:30:33  [ main:137 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:30:33  [ main:150 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:30:33  [ main:150 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:30:33  [ main:151 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:32:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:32:24  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:32:24  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:32:24  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 16:32:24  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:32:24  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:32:24  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:32:24  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:32:24  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:32:24  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:32:24  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:32:24  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:32:24  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:32:24  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:32:24  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:32:24  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:32:24  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:32:24  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:32:24  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:32:24  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:32:24  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:32:24  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:32:24  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:32:24  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:32:24  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:32:24  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:32:24  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-28 16:32:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:32:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 16:32:32  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 16:32:32  [ main:89 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 16:32:32  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 16:32:32  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 16:32:32  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 16:32:32  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 16:32:32  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 16:32:32  [ main:105 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 16:32:32  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 16:32:32  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 16:32:32  [ main:110 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 16:32:32  [ main:110 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 16:32:32  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 16:32:32  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 16:32:32  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 16:32:32  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 16:32:32  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 16:32:32  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 16:32:32  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 16:32:32  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 16:32:32  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 16:32:32  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 16:32:32  [ main:155 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 16:32:32  [ main:155 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 16:32:32  [ main:157 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:01:50  [ kafka-producer-network-thread | DemoProducer1:1757896 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-06-28 17:01:50  [ kafka-producer-network-thread | DemoProducer1:1757896 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-06-28 17:01:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:01:53  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:01:53  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:01:53  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:01:53  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:01:53  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:01:53  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:01:53  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:01:53  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:01:53  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:01:53  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:01:53  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:01:53  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:01:53  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:01:53  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:01:53  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:01:53  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:01:53  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:01:53  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:01:53  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:01:53  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:01:53  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:01:53  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:01:53  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:01:53  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:01:53  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:01:53  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:10:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:18  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:10:18  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:10:18  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 17:10:18  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:10:18  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:10:18  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:10:18  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:10:18  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:10:18  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:10:18  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:10:18  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:10:18  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:10:18  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:10:18  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:10:18  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:10:18  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:10:18  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:10:18  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:10:18  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:10:18  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:18  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:10:18  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:10:18  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:10:18  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:10:18  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:10:18  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:10:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:24  [ main:93 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:10:24  [ main:108 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:10:24  [ main:111 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 17:10:24  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:10:24  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:10:24  [ main:126 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:10:24  [ main:128 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:10:24  [ main:130 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:10:24  [ main:130 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:10:24  [ main:130 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:10:24  [ main:134 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:10:24  [ main:135 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:10:24  [ main:135 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:10:24  [ main:135 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:10:24  [ main:136 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:10:24  [ main:137 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:10:24  [ main:137 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:10:24  [ main:138 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:10:24  [ main:138 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:10:24  [ kafka-producer-network-thread | DemoProducer1:141 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:10:24  [ main:142 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:24  [ main:143 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:10:24  [ main:143 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:10:24  [ main:146 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:10:24  [ main:147 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:10:24  [ main:147 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:10:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:37  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:10:37  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:10:37  [ main:98 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 17:10:37  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:10:37  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:10:37  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:10:37  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:10:37  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:10:37  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:10:37  [ main:114 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:10:37  [ main:118 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:10:37  [ main:118 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:10:37  [ main:119 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:10:37  [ main:119 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:10:37  [ main:120 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:10:37  [ main:128 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:10:37  [ main:128 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:10:37  [ main:128 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:10:37  [ main:129 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:10:37  [ kafka-producer-network-thread | DemoProducer1:136 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:10:37  [ main:143 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:10:37  [ main:145 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:10:37  [ main:145 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:10:37  [ main:148 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:10:37  [ main:148 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:10:37  [ main:153 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:16:21  [ kafka-producer-network-thread | DemoProducer1:344225 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-06-28 17:16:21  [ kafka-producer-network-thread | DemoProducer1:344226 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-06-28 17:16:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:29  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:16:29  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:16:29  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:16:29  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:16:29  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:16:29  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:16:29  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:16:29  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:16:29  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:16:29  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:16:29  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:16:29  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:16:29  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:16:29  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:16:29  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:16:29  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:16:29  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:16:29  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:16:29  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:16:29  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:29  [ main:134 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:16:29  [ main:134 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:16:29  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:16:29  [ main:137 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:16:29  [ main:138 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:16:29  [ kafka-producer-network-thread | DemoProducer1:142 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:16:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:35  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:16:35  [ main:94 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:16:35  [ main:98 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 17:16:35  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:16:35  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:16:35  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:16:35  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:16:35  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:16:35  [ main:108 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:16:35  [ main:109 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:16:35  [ main:116 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:16:35  [ main:117 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:16:35  [ main:118 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:16:35  [ main:118 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:16:35  [ main:120 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:16:35  [ main:129 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:16:35  [ main:129 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:16:35  [ main:129 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:16:35  [ main:130 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:16:35  [ kafka-producer-network-thread | DemoProducer1:132 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:16:35  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:35  [ main:133 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:16:35  [ main:134 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:16:35  [ main:155 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:16:35  [ main:156 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:16:35  [ main:156 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:16:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:47  [ main:83 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:16:47  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:16:47  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 17:16:47  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:16:47  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:16:47  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:16:47  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:16:47  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:16:47  [ main:107 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:16:47  [ main:109 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:16:47  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:16:47  [ main:115 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:16:47  [ main:116 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:16:47  [ main:116 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:16:47  [ main:117 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:16:47  [ main:125 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:16:47  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:16:47  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:16:47  [ main:126 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:16:47  [ kafka-producer-network-thread | DemoProducer1:128 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:16:47  [ main:129 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:47  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:16:47  [ main:130 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:16:47  [ main:142 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:16:47  [ main:150 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:16:47  [ main:160 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:16:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:53  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:16:53  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:16:53  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:16:53  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:16:53  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:16:53  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:16:53  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:16:53  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:16:53  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:16:53  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:16:53  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:16:53  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:16:53  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:16:53  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:16:53  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:16:53  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:16:53  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:16:53  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:16:53  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:16:53  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:16:53  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:16:53  [ main:112 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:16:53  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:16:53  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:16:53  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:16:53  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:17:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:17:00  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:17:00  [ main:91 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:17:00  [ main:95 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:17:00  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:17:00  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:17:00  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:17:00  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:17:00  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:17:00  [ main:111 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:17:00  [ main:111 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:17:00  [ main:115 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:17:00  [ main:116 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:17:00  [ main:116 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:17:00  [ main:117 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:17:00  [ main:117 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:17:00  [ main:119 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:17:00  [ main:119 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:17:00  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:17:00  [ main:119 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:17:00  [ main:124 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:17:00  [ main:125 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:17:00  [ main:125 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:17:00  [ kafka-producer-network-thread | DemoProducer1:137 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:17:00  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:17:00  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:17:00  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:18:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:18:46  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:18:46  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:18:46  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:18:46  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:18:46  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:18:46  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:18:46  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:18:46  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:18:46  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:18:46  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:18:46  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:18:46  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:18:46  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:18:46  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:18:46  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:18:46  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:18:46  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:18:46  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:18:46  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:18:46  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:18:46  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:18:46  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:18:46  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:18:46  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:18:46  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:18:46  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:29:15  [ kafka-producer-network-thread | DemoProducer1:629497 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-28 17:29:15  [ kafka-producer-network-thread | DemoProducer1:629497 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-28 17:57:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:57:33  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:57:33  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:57:33  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 17:57:33  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:57:33  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:57:33  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:57:33  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:57:33  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:57:33  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:57:33  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:57:33  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:57:33  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:57:33  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:57:33  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:57:33  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:57:33  [ main:106 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:57:33  [ main:106 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:57:33  [ main:106 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:57:33  [ main:106 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:57:33  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:57:33  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:57:33  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:57:33  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:57:33  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:57:33  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:57:33  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:57:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:57:55  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:57:55  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:57:55  [ main:99 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 17:57:55  [ main:110 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:57:55  [ main:110 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:57:55  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:57:55  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:57:55  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:57:55  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:57:55  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:57:55  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:57:55  [ main:118 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:57:55  [ main:118 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:57:55  [ main:118 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:57:55  [ main:119 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:57:55  [ main:120 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:57:55  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:57:55  [ main:121 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:57:55  [ main:121 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:57:55  [ kafka-producer-network-thread | DemoProducer1:135 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:57:55  [ main:135 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:57:55  [ main:143 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:57:55  [ main:144 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:57:55  [ main:150 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:57:55  [ main:151 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:57:55  [ main:154 ] - [ DEBUG ]  Kafka producer started
2017-06-28 17:59:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:59:43  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 17:59:43  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 17:59:43  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 17:59:44  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 17:59:44  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 17:59:44  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 17:59:44  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 17:59:44  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 17:59:44  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 17:59:44  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 17:59:44  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 17:59:44  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 17:59:44  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 17:59:44  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 17:59:44  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 17:59:44  [ main:119 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 17:59:44  [ main:119 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 17:59:44  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 17:59:44  [ main:120 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 17:59:44  [ main:122 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 17:59:44  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 17:59:44  [ main:123 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 17:59:44  [ kafka-producer-network-thread | DemoProducer1:123 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 17:59:44  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 17:59:44  [ main:128 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 17:59:44  [ main:129 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:02:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:02:08  [ main:86 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:02:08  [ main:90 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:02:08  [ main:92 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:02:08  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:02:08  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:02:08  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:02:08  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:02:08  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:02:08  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:02:08  [ main:103 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:02:08  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:02:08  [ main:107 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:02:08  [ main:107 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:02:08  [ main:108 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:02:08  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:02:08  [ main:112 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:02:08  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:02:08  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:02:08  [ main:113 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:02:08  [ main:116 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:02:08  [ main:117 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:02:08  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:02:08  [ main:120 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:02:08  [ main:120 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:02:08  [ kafka-producer-network-thread | DemoProducer1:121 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:02:08  [ main:122 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:02:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:02:46  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:02:46  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:02:46  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:02:46  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:02:46  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:02:46  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:02:46  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:02:46  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:02:46  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:02:46  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:02:46  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:02:46  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:02:46  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:02:46  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:02:46  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:02:46  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:02:46  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:02:46  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:02:46  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:02:46  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:02:46  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:02:46  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:02:46  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:02:46  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:02:46  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:02:46  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:03:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:03:25  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:03:25  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:03:25  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:03:25  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:03:25  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:03:25  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:03:25  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:03:25  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:03:25  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:03:25  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:03:25  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:03:25  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:03:25  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:03:25  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:03:25  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:03:25  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:03:25  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:03:25  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:03:25  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:03:25  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:03:25  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:03:25  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:03:25  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:03:25  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:03:25  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:03:25  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:03:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:03:39  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:03:39  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:03:39  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:03:39  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:03:39  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:03:39  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:03:39  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:03:39  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:03:39  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:03:39  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:03:39  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:03:39  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:03:39  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:03:39  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:03:39  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:03:39  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:03:39  [ main:111 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:03:39  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:03:39  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:03:40  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:03:40  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:03:40  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:03:40  [ main:117 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:03:40  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:03:40  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:03:40  [ main:135 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:09:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:07  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:09:07  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:09:07  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 18:09:07  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:09:07  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:09:07  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:09:07  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:09:07  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:09:07  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:09:07  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:09:07  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:09:07  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:09:07  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:09:07  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:09:07  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:09:07  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:09:07  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:09:07  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:09:07  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:09:07  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:07  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:09:07  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:09:07  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:09:07  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:09:07  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:09:07  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:09:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:15  [ main:89 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:09:15  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:09:15  [ main:97 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 18:09:15  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:09:15  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:09:15  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:09:15  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:09:15  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:09:15  [ main:107 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:09:15  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:09:15  [ main:112 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:09:15  [ main:113 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:09:15  [ main:113 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:09:15  [ main:113 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:09:15  [ main:114 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:09:15  [ main:115 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:09:15  [ main:115 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:09:15  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:09:15  [ main:116 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:09:15  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:09:15  [ main:130 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:15  [ main:131 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:09:15  [ main:131 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:09:15  [ main:133 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:09:15  [ main:134 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:09:15  [ main:139 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:09:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:37  [ main:95 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:09:37  [ main:99 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:09:37  [ main:101 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:09:37  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:09:37  [ main:110 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:09:37  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:09:37  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:09:37  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:09:37  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:09:37  [ main:114 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:09:37  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:09:37  [ main:119 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:09:37  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:09:37  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:09:37  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:09:37  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:09:37  [ main:131 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:09:37  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:09:37  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:09:37  [ kafka-producer-network-thread | DemoProducer1:139 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:09:37  [ main:139 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:37  [ main:140 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:09:37  [ main:140 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:09:37  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:09:37  [ main:145 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:09:37  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:09:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:43  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:09:43  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:09:43  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 18:09:43  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:09:43  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:09:43  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:09:43  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:09:43  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:09:43  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:09:43  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:09:43  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:09:43  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:09:43  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:09:43  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:09:43  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:09:43  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:09:43  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:09:43  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:09:43  [ main:116 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:09:43  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:09:43  [ main:121 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:43  [ main:122 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:09:43  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:09:43  [ main:156 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:09:43  [ main:156 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:09:43  [ main:157 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:09:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:47  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:09:47  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:09:47  [ main:87 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 18:09:47  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:09:47  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:09:47  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:09:47  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:09:47  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:09:47  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:09:47  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:09:47  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:09:47  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:09:47  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:09:47  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:09:47  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:09:47  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:09:47  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:09:47  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:09:47  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:09:47  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:09:47  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:09:47  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:09:47  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:09:47  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:09:47  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:09:47  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:10:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:09  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:10:09  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:10:09  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 18:10:09  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:10:09  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:10:09  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:10:09  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:10:09  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:10:09  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:10:09  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:10:09  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:10:09  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:10:09  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:10:09  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:10:09  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:10:09  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:10:09  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:10:09  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:10:09  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:10:09  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:09  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:10:09  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:10:09  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:10:09  [ main:128 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:10:09  [ main:128 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:10:09  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:10:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:19  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:10:19  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:10:19  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 18:10:19  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:10:19  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:10:19  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:10:19  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:10:19  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:10:19  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:10:19  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:10:19  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:10:19  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:10:19  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:10:19  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:10:19  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:10:19  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:10:19  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:10:19  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:10:19  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:10:19  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:19  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:10:19  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:10:19  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:10:19  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:10:19  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:10:19  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:10:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:36  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:10:36  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:10:36  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 18:10:36  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:10:36  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:10:36  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:10:36  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:10:36  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:10:36  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:10:36  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:10:36  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:10:36  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:10:36  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:10:36  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:10:36  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:10:36  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:10:36  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:10:36  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:10:36  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:10:36  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:10:36  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:10:36  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:10:36  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:10:36  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:10:36  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:10:36  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:13:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:13:33  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:13:33  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:13:33  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 18:13:33  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:13:33  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:13:33  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:13:33  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:13:33  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:13:33  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:13:33  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:13:33  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:13:33  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:13:33  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:13:33  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:13:33  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:13:33  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:13:33  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:13:33  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:13:33  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:13:33  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:13:33  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:13:33  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-28 18:13:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:13:43  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 18:13:43  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 18:13:43  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 18:13:43  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 18:13:43  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 18:13:43  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 18:13:43  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 18:13:43  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 18:13:43  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 18:13:43  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 18:13:43  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 18:13:43  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 18:13:43  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 18:13:43  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 18:13:43  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 18:13:43  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 18:13:43  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 18:13:43  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 18:13:43  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 18:13:43  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 18:13:43  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 18:13:43  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 18:13:43  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 18:13:43  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 18:13:43  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 18:13:43  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-28 19:47:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:47:18  [ main:99 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 19:47:18  [ main:108 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 19:47:18  [ main:114 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 19:47:18  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 19:47:18  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 19:47:18  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 19:47:18  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 19:47:18  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 19:47:18  [ main:138 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 19:47:18  [ main:138 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 19:47:18  [ main:143 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 19:47:18  [ main:144 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 19:47:18  [ main:145 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 19:47:18  [ main:146 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 19:47:18  [ main:147 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 19:47:18  [ main:158 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 19:47:18  [ main:159 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 19:47:18  [ main:159 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 19:47:18  [ main:160 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 19:47:18  [ main:163 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:47:18  [ main:164 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 19:47:18  [ main:164 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 19:47:18  [ main:186 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 19:47:18  [ main:194 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 19:47:18  [ main:195 ] - [ DEBUG ]  Kafka producer started
2017-06-28 19:47:18  [ kafka-producer-network-thread | DemoProducer1:206 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 19:49:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:49:45  [ main:113 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 19:49:45  [ main:118 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 19:49:45  [ main:122 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 19:49:45  [ main:134 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 19:49:45  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 19:49:45  [ main:135 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 19:49:45  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 19:49:45  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 19:49:45  [ main:138 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 19:49:45  [ main:138 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 19:49:45  [ main:142 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 19:49:45  [ main:143 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 19:49:45  [ main:143 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 19:49:45  [ main:144 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 19:49:45  [ main:144 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 19:49:45  [ main:148 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 19:49:45  [ main:148 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 19:49:45  [ main:148 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 19:49:45  [ main:149 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 19:49:45  [ main:157 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:49:45  [ main:158 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 19:49:45  [ main:158 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 19:49:45  [ kafka-producer-network-thread | DemoProducer1:170 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 19:49:45  [ main:173 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 19:49:45  [ main:173 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 19:49:45  [ main:174 ] - [ DEBUG ]  Kafka producer started
2017-06-28 19:50:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:50:39  [ main:88 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 19:50:39  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 19:50:39  [ main:95 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 19:50:39  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 19:50:39  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 19:50:39  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 19:50:39  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 19:50:39  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 19:50:39  [ main:108 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 19:50:39  [ main:109 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 19:50:39  [ main:112 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 19:50:39  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 19:50:39  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 19:50:39  [ main:115 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 19:50:39  [ main:116 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 19:50:39  [ main:120 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 19:50:39  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 19:50:39  [ main:121 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 19:50:39  [ main:121 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 19:50:39  [ kafka-producer-network-thread | DemoProducer1:134 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 19:50:39  [ main:134 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:50:39  [ main:136 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 19:50:39  [ main:137 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 19:50:39  [ main:140 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 19:50:39  [ main:140 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 19:50:39  [ main:141 ] - [ DEBUG ]  Kafka producer started
2017-06-28 19:53:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:53:33  [ main:86 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 19:53:33  [ main:96 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 19:53:33  [ main:100 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 19:53:33  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 19:53:33  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 19:53:33  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 19:53:33  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 19:53:33  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 19:53:33  [ main:117 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 19:53:33  [ main:120 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 19:53:33  [ main:125 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 19:53:33  [ main:126 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 19:53:33  [ main:126 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 19:53:33  [ main:128 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 19:53:33  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 19:53:33  [ main:138 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 19:53:33  [ main:139 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 19:53:33  [ main:139 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 19:53:33  [ main:140 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 19:53:33  [ kafka-producer-network-thread | DemoProducer1:147 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 19:53:33  [ main:148 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:53:33  [ main:149 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 19:53:33  [ main:149 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 19:53:33  [ main:152 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 19:53:33  [ main:152 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 19:53:33  [ main:167 ] - [ DEBUG ]  Kafka producer started
2017-06-28 19:54:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:54:19  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 19:54:19  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 19:54:19  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 19:54:19  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 19:54:19  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 19:54:19  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 19:54:19  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 19:54:19  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 19:54:19  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 19:54:19  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 19:54:19  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 19:54:19  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 19:54:19  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 19:54:19  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 19:54:19  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 19:54:19  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 19:54:19  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 19:54:19  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 19:54:19  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 19:54:19  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 19:54:19  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 19:54:19  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 19:54:19  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 19:54:19  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 19:54:19  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 19:54:19  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:03:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:03:21  [ main:129 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:03:21  [ main:137 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:03:21  [ main:141 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:03:21  [ main:150 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:03:21  [ main:151 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:03:21  [ main:152 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:03:21  [ main:152 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:03:21  [ main:154 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:03:21  [ main:155 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:03:21  [ main:156 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:03:21  [ main:160 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:03:21  [ main:161 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:03:21  [ main:161 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:03:21  [ main:162 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:03:21  [ main:162 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:03:21  [ main:164 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:03:21  [ main:164 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:03:21  [ main:164 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:03:21  [ main:164 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:03:21  [ main:167 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:03:21  [ main:167 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:03:21  [ main:168 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:03:21  [ kafka-producer-network-thread | DemoProducer1:177 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:03:21  [ main:183 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:03:21  [ main:211 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:03:21  [ main:212 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:16:36  [ kafka-producer-network-thread | DemoProducer1:795338 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-28 20:16:36  [ kafka-producer-network-thread | DemoProducer1:795338 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-28 20:16:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:16:39  [ main:148 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:16:39  [ main:169 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:16:39  [ main:176 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:16:39  [ main:200 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:16:39  [ main:201 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:16:39  [ main:202 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:16:39  [ main:203 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:16:39  [ main:204 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:16:39  [ main:205 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:16:39  [ main:206 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:16:39  [ main:210 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:16:39  [ main:210 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:16:39  [ main:211 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:16:39  [ main:211 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:16:39  [ main:211 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:16:39  [ main:213 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:16:39  [ main:213 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:16:39  [ main:214 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:16:39  [ main:214 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:16:39  [ main:216 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:16:39  [ main:217 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:16:39  [ main:217 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:16:39  [ main:242 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:16:39  [ main:242 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:16:39  [ main:243 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:16:39  [ kafka-producer-network-thread | DemoProducer1:257 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:19:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:19:29  [ main:107 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:19:29  [ main:131 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:19:29  [ main:140 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:19:29  [ main:173 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:19:29  [ main:174 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:19:29  [ main:175 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:19:29  [ main:176 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:19:29  [ main:178 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:19:29  [ main:178 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:19:29  [ main:179 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:19:29  [ main:184 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:19:29  [ main:185 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:19:29  [ main:186 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:19:29  [ main:187 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:19:29  [ main:187 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:19:29  [ main:198 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:19:29  [ main:199 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:19:29  [ main:199 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:19:29  [ main:200 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:19:29  [ main:269 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:19:29  [ main:270 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:19:29  [ main:270 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:19:29  [ main:294 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:19:29  [ main:295 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:19:29  [ main:296 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:19:29  [ kafka-producer-network-thread | DemoProducer1:306 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:19:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:19:34  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:19:34  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:19:34  [ main:107 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:19:34  [ main:125 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:19:34  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:19:34  [ main:129 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:19:34  [ main:130 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:19:34  [ main:132 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:19:34  [ main:133 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:19:34  [ main:135 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:19:34  [ main:142 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:19:34  [ main:143 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:19:34  [ main:150 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:19:34  [ main:152 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:19:34  [ main:154 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:19:34  [ main:168 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:19:34  [ main:169 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:19:34  [ main:170 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:19:34  [ main:171 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:19:34  [ main:200 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:19:34  [ kafka-producer-network-thread | DemoProducer1:201 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:19:34  [ main:202 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:19:34  [ main:203 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:19:34  [ main:214 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:19:34  [ main:214 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:19:34  [ main:217 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:20:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:20:00  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:20:00  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:20:00  [ main:96 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:20:00  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:20:00  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:20:00  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:20:00  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:20:00  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:20:00  [ main:122 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:20:00  [ main:126 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:20:00  [ main:135 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:20:00  [ main:135 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:20:00  [ main:136 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:20:00  [ main:136 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:20:00  [ main:136 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:20:00  [ main:140 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:20:00  [ main:140 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:20:00  [ main:140 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:20:00  [ main:140 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:20:00  [ main:149 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:20:00  [ main:150 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:20:00  [ main:150 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:20:00  [ kafka-producer-network-thread | DemoProducer1:152 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:20:00  [ main:154 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:20:00  [ main:154 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:20:00  [ main:155 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:21:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:21:04  [ main:88 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:21:04  [ main:94 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:21:04  [ main:98 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:21:04  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:21:04  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:21:04  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:21:04  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:21:04  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:21:04  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:21:04  [ main:112 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:21:04  [ main:124 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:21:04  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:21:04  [ main:125 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:21:04  [ main:125 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:21:04  [ main:125 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:21:04  [ main:127 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:21:04  [ main:127 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:21:04  [ main:128 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:21:04  [ main:128 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:21:04  [ main:131 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:21:04  [ main:132 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:21:04  [ main:132 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:21:04  [ main:135 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:21:04  [ main:136 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:21:04  [ main:137 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:21:04  [ kafka-producer-network-thread | DemoProducer1:138 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:21:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:21:16  [ main:100 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:21:16  [ main:108 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:21:16  [ main:115 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:21:16  [ main:138 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:21:16  [ main:139 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:21:16  [ main:140 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:21:16  [ main:141 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:21:16  [ main:155 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:21:16  [ main:162 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:21:16  [ main:163 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:21:16  [ main:171 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:21:16  [ main:172 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:21:16  [ main:172 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:21:16  [ main:172 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:21:16  [ main:173 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:21:16  [ main:176 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:21:16  [ main:176 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:21:16  [ main:177 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:21:16  [ main:177 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:21:16  [ main:192 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:21:16  [ main:193 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:21:16  [ main:193 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:21:16  [ kafka-producer-network-thread | DemoProducer1:199 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:21:16  [ main:213 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:21:16  [ main:214 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:21:16  [ main:214 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:22:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:05  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:22:05  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:22:05  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:22:05  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:22:05  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:22:05  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:22:05  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:22:05  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:22:05  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:22:05  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:22:05  [ main:113 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:22:05  [ main:113 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:22:05  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:22:05  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:22:05  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:22:05  [ main:125 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:22:05  [ main:126 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:22:05  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:22:05  [ main:126 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:22:05  [ main:129 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:05  [ main:130 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:22:05  [ main:130 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:22:05  [ kafka-producer-network-thread | DemoProducer1:138 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:22:05  [ main:142 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:22:05  [ main:143 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:22:05  [ main:143 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:22:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:28  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:22:28  [ main:83 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:22:28  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:22:28  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:22:28  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:22:28  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:22:28  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:22:28  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:22:28  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:22:28  [ main:101 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:22:28  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:22:28  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:22:28  [ main:106 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:22:28  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:22:28  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:22:29  [ main:108 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:22:29  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:22:29  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:22:29  [ main:109 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:22:29  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:29  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:22:29  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:22:29  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:22:29  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:22:29  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:22:29  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:22:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:36  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:22:36  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:22:36  [ main:101 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:22:36  [ main:116 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:22:36  [ main:117 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:22:36  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:22:36  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:22:36  [ main:119 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:22:36  [ main:120 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:22:36  [ main:121 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:22:36  [ main:126 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:22:36  [ main:127 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:22:36  [ main:127 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:22:36  [ main:127 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:22:36  [ main:128 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:22:36  [ main:130 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:22:36  [ main:131 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:22:36  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:22:36  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:22:36  [ kafka-producer-network-thread | DemoProducer1:144 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:22:36  [ main:145 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:36  [ main:149 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:22:36  [ main:149 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:22:36  [ main:160 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:22:36  [ main:160 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:22:36  [ main:161 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:22:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:40  [ main:93 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:22:40  [ main:99 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:22:40  [ main:103 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:22:40  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:22:40  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:22:40  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:22:40  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:22:40  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:22:40  [ main:117 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:22:40  [ main:117 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:22:40  [ main:121 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:22:40  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:22:40  [ main:122 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:22:40  [ main:122 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:22:40  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:22:40  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:22:40  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:22:40  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:22:40  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:22:41  [ main:131 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:22:41  [ main:132 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:22:41  [ main:132 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:22:41  [ kafka-producer-network-thread | DemoProducer1:134 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:22:41  [ main:143 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:22:41  [ main:143 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:22:41  [ main:144 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:23:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:23:18  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:23:18  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:23:18  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:23:18  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:23:18  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:23:18  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:23:18  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:23:18  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:23:18  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:23:18  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:23:18  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:23:18  [ main:110 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:23:18  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:23:18  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:23:18  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:23:18  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:23:18  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:23:18  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:23:18  [ main:114 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:23:18  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:23:18  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:23:18  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:23:18  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:23:18  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:23:18  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:23:18  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:24:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:24:40  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:24:40  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:24:40  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:24:40  [ main:117 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:24:40  [ main:117 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:24:40  [ main:118 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:24:40  [ main:118 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:24:40  [ main:119 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:24:40  [ main:120 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:24:40  [ main:121 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:24:40  [ main:126 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:24:40  [ main:127 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:24:40  [ main:127 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:24:40  [ main:127 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:24:40  [ main:127 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:24:40  [ main:129 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:24:40  [ main:129 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:24:40  [ main:129 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:24:40  [ main:130 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:24:40  [ kafka-producer-network-thread | DemoProducer1:132 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:24:40  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:24:40  [ main:134 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:24:40  [ main:134 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:24:40  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:24:40  [ main:137 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:24:40  [ main:138 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:24:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:24:49  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:24:49  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:24:49  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:24:49  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:24:49  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:24:49  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:24:49  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:24:49  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:24:49  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:24:49  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:24:49  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:24:49  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:24:49  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:24:49  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:24:49  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:24:49  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:24:49  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:24:49  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:24:49  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:24:49  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:24:49  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:24:49  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:24:49  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:24:49  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:24:49  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:24:49  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:19  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:25:19  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:25:19  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:25:19  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:25:19  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:25:19  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:25:19  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:25:19  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:25:19  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:25:19  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:25:19  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:25:19  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:25:19  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:25:19  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:25:19  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:25:19  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:25:19  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:25:19  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:25:19  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:25:19  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:19  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:25:19  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:25:19  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:19  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:25:19  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:25:19  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:25:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:23  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:25:23  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:25:23  [ main:87 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:25:23  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:25:23  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:25:23  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:25:23  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:25:23  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:25:23  [ main:106 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:25:23  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:25:23  [ main:118 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:25:23  [ main:119 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:25:23  [ main:119 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:25:23  [ main:119 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:25:23  [ main:119 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:25:23  [ main:137 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:25:23  [ main:137 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:25:23  [ main:137 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:25:23  [ main:138 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:25:23  [ main:161 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:23  [ main:162 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:25:23  [ main:162 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:25:23  [ main:165 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:25:23  [ main:165 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:25:23  [ main:166 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:25:23  [ kafka-producer-network-thread | DemoProducer1:173 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:32  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:25:32  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:25:32  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:25:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:25:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:25:32  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:25:32  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:25:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:25:32  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:25:32  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:25:32  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:25:32  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:25:32  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:25:32  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:25:32  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:25:32  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:25:32  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:25:32  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:25:32  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:25:32  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:32  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:25:32  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:32  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:25:32  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:25:32  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:25:32  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:25:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:55  [ main:98 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:25:55  [ main:103 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:25:55  [ main:104 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:25:55  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:25:55  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:25:55  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:25:55  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:25:55  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:25:55  [ main:115 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:25:55  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:25:55  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:25:55  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:25:55  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:25:55  [ main:120 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:25:55  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:25:55  [ main:122 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:25:55  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:25:55  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:25:55  [ main:123 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:25:55  [ main:125 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:55  [ main:126 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:25:55  [ main:126 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:25:55  [ main:130 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:25:55  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:25:55  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:25:55  [ kafka-producer-network-thread | DemoProducer1:150 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:59  [ main:130 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:25:59  [ main:136 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:25:59  [ main:139 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:25:59  [ main:148 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:25:59  [ main:148 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:25:59  [ main:149 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:25:59  [ main:150 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:25:59  [ main:152 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:25:59  [ main:152 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:25:59  [ main:153 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:25:59  [ main:157 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:25:59  [ main:158 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:25:59  [ main:159 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:25:59  [ main:160 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:25:59  [ main:161 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:25:59  [ main:179 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:25:59  [ main:179 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:25:59  [ main:180 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:25:59  [ main:180 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:25:59  [ main:183 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:25:59  [ main:183 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:25:59  [ main:183 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:25:59  [ kafka-producer-network-thread | DemoProducer1:185 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:25:59  [ main:191 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:25:59  [ main:191 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:25:59  [ main:192 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:26:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:04  [ main:105 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:26:04  [ main:112 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:26:04  [ main:115 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:26:04  [ main:128 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:26:04  [ main:129 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:26:04  [ main:129 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:26:04  [ main:130 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:26:04  [ main:131 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:26:04  [ main:132 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:26:04  [ main:133 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:26:04  [ main:137 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:26:04  [ main:139 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:26:04  [ main:140 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:26:04  [ main:141 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:26:04  [ main:141 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:26:04  [ main:152 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:26:04  [ main:153 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:26:04  [ main:154 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:26:04  [ main:155 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:26:04  [ kafka-producer-network-thread | DemoProducer1:175 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:26:04  [ main:175 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:04  [ main:176 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:26:04  [ main:176 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:26:04  [ main:179 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:26:04  [ main:179 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:26:04  [ main:180 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:26:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:28  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:26:28  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:26:28  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:26:28  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:26:28  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:26:28  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:26:28  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:26:28  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:26:28  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:26:28  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:26:28  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:26:28  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:26:28  [ main:108 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:26:28  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:26:28  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:26:28  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:26:28  [ main:118 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:26:28  [ main:118 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:26:28  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:26:28  [ kafka-producer-network-thread | DemoProducer1:121 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:26:28  [ main:122 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:28  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:26:28  [ main:123 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:26:28  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:26:28  [ main:126 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:26:28  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:26:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:35  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:26:35  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:26:35  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:26:35  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:26:35  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:26:35  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:26:35  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:26:35  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:26:35  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:26:35  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:26:35  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:26:35  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:26:35  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:26:35  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:26:35  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:26:35  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:26:35  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:26:35  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:26:35  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:26:35  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:26:35  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:26:35  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:26:35  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:26:35  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:26:35  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:26:35  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:04  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:27:04  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:27:04  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:27:04  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:27:04  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:27:04  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:27:04  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:27:04  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:27:04  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:27:04  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:27:04  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:27:04  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:27:04  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:27:04  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:27:04  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:27:04  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:27:04  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:27:04  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:27:04  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:27:04  [ main:106 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:04  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:27:04  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:27:04  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:27:04  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:27:04  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:27:04  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:09  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:27:09  [ main:81 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:27:09  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:27:09  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:27:09  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:27:09  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:27:09  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:27:09  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:27:09  [ main:115 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:27:09  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:27:09  [ main:120 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:27:09  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:27:09  [ main:121 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:27:09  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:27:09  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:27:09  [ main:123 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:27:09  [ main:124 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:27:09  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:27:09  [ main:126 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:27:09  [ kafka-producer-network-thread | DemoProducer1:128 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:27:09  [ main:128 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:09  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:27:09  [ main:129 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:27:09  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:27:09  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:27:09  [ main:140 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:20  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:27:20  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:27:20  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:27:20  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:27:20  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:27:20  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:27:20  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:27:20  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:27:20  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:27:20  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:27:20  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:27:20  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:27:20  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:27:20  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:27:20  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:27:20  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:27:20  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:27:20  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:27:20  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:27:20  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:27:20  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:20  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:27:20  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:27:20  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:27:20  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:27:20  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:27  [ main:169 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:27:27  [ main:176 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:27:27  [ main:178 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:27:27  [ main:186 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:27:27  [ main:187 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:27:27  [ main:187 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:27:27  [ main:187 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:27:27  [ main:188 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:27:27  [ main:189 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:27:27  [ main:189 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:27:27  [ main:193 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:27:27  [ main:194 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:27:27  [ main:195 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:27:27  [ main:195 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:27:27  [ main:196 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:27:27  [ main:206 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:27:27  [ main:207 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:27:27  [ main:207 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:27:27  [ main:208 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:27:27  [ kafka-producer-network-thread | DemoProducer1:225 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:27:27  [ main:228 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:27  [ main:228 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:27:27  [ main:228 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:27:27  [ main:261 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:27:27  [ main:262 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:27:27  [ main:262 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:34  [ main:186 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:27:34  [ main:199 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:27:34  [ main:202 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:27:34  [ main:215 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:27:34  [ main:215 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:27:34  [ main:216 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:27:34  [ main:216 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:27:34  [ main:218 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:27:34  [ main:218 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:27:34  [ main:218 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:27:34  [ main:222 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:27:34  [ main:223 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:27:34  [ main:224 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:27:34  [ main:225 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:27:34  [ main:225 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:27:34  [ main:235 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:27:34  [ main:236 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:27:34  [ main:237 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:27:34  [ main:237 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:27:34  [ main:239 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:27:34  [ main:240 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:27:34  [ main:240 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:27:34  [ main:255 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:27:34  [ main:256 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:27:34  [ main:256 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:27:34  [ kafka-producer-network-thread | DemoProducer1:267 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:04  [ main:149 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:28:04  [ main:155 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:28:04  [ main:158 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:28:04  [ main:169 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:28:04  [ main:169 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:28:04  [ main:170 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:28:04  [ main:171 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:28:04  [ main:172 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:28:04  [ main:172 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:28:04  [ main:173 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:28:04  [ main:177 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:28:04  [ main:179 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:28:04  [ main:180 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:28:04  [ main:180 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:28:04  [ main:183 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:28:04  [ main:193 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:28:04  [ main:194 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:28:04  [ main:194 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:28:04  [ main:195 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:28:04  [ kafka-producer-network-thread | DemoProducer1:197 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:04  [ main:200 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:04  [ main:201 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:28:04  [ main:201 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:28:04  [ main:226 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:28:04  [ main:226 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:28:04  [ main:230 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:28:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:08  [ main:88 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:28:08  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:28:08  [ main:97 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:28:08  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:28:08  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:28:08  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:28:08  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:28:08  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:28:08  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:28:08  [ main:114 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:28:08  [ main:120 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:28:08  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:28:08  [ main:121 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:28:08  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:28:08  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:28:08  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:28:08  [ main:124 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:28:08  [ main:124 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:28:08  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:28:08  [ kafka-producer-network-thread | DemoProducer1:127 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:08  [ main:128 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:08  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:28:08  [ main:135 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:28:08  [ main:140 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:28:08  [ main:140 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:28:08  [ main:153 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:28:22  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:22  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:28:22  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:28:22  [ main:96 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:28:22  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:28:22  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:28:22  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:28:22  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:28:22  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:28:22  [ main:109 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:28:22  [ main:109 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:28:22  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:28:22  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:28:22  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:28:22  [ main:115 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:28:22  [ main:115 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:28:22  [ main:117 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:28:22  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:28:22  [ main:118 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:28:22  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:28:22  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:22  [ main:125 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:22  [ main:131 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:28:22  [ main:131 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:28:22  [ main:143 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:28:22  [ main:143 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:28:22  [ main:144 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:28:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:43  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:28:43  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:28:43  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:28:43  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:28:43  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:28:43  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:28:43  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:28:43  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:28:43  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:28:43  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:28:43  [ main:99 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:28:43  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:28:43  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:28:43  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:28:43  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:28:43  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:28:43  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:28:43  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:28:43  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:28:43  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:43  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:28:43  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:28:43  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:43  [ main:121 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:28:43  [ main:121 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:28:43  [ main:122 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:28:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:46  [ main:106 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:28:46  [ main:112 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:28:46  [ main:117 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:28:46  [ main:142 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:28:46  [ main:142 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:28:46  [ main:144 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:28:46  [ main:146 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:28:46  [ main:148 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:28:46  [ main:148 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:28:46  [ main:148 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:28:46  [ main:153 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:28:46  [ main:154 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:28:46  [ main:155 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:28:46  [ main:156 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:28:46  [ main:157 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:28:46  [ main:168 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:28:46  [ main:168 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:28:46  [ main:169 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:28:46  [ main:169 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:28:46  [ main:196 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:28:46  [ main:197 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:28:46  [ main:197 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:28:46  [ kafka-producer-network-thread | DemoProducer1:198 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:28:46  [ main:214 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:28:46  [ main:215 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:28:46  [ main:219 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:32:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:32:54  [ main:98 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:32:54  [ main:105 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:32:54  [ main:109 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:32:54  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:32:54  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:32:54  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:32:54  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:32:54  [ main:123 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:32:54  [ main:124 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:32:54  [ main:124 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:32:54  [ main:128 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:32:54  [ main:128 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:32:54  [ main:129 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:32:54  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:32:54  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:32:54  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:32:54  [ main:131 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:32:54  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:32:54  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:32:54  [ kafka-producer-network-thread | DemoProducer1:150 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:32:54  [ main:151 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:32:54  [ main:154 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:32:54  [ main:154 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:32:54  [ main:158 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:32:54  [ main:158 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:32:54  [ main:167 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:35:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:35:47  [ main:100 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:35:47  [ main:116 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:35:47  [ main:129 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:35:47  [ main:139 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:35:47  [ main:139 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:35:47  [ main:139 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:35:47  [ main:140 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:35:47  [ main:142 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:35:47  [ main:142 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:35:47  [ main:143 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:35:47  [ main:156 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:35:47  [ main:160 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:35:47  [ main:161 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:35:47  [ main:162 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:35:47  [ main:163 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:35:47  [ main:175 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:35:47  [ main:176 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:35:47  [ main:176 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:35:47  [ main:176 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:35:47  [ kafka-producer-network-thread | DemoProducer1:179 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:35:47  [ main:179 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:35:47  [ main:180 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:35:47  [ main:180 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:35:47  [ main:183 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:35:47  [ main:183 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:35:47  [ main:184 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:35:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:35:49  [ main:122 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:35:49  [ main:130 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:35:49  [ main:136 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:35:49  [ main:173 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:35:49  [ main:173 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:35:49  [ main:174 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:35:49  [ main:174 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:35:49  [ main:175 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:35:49  [ main:177 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:35:49  [ main:177 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:35:49  [ main:184 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:35:49  [ main:186 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:35:49  [ main:186 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:35:49  [ main:187 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:35:49  [ main:187 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:35:49  [ main:202 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:35:49  [ main:203 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:35:49  [ main:205 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:35:49  [ main:205 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:35:49  [ main:248 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:35:49  [ main:249 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:35:49  [ main:249 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:35:49  [ main:275 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:35:49  [ main:275 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:35:49  [ main:276 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:35:49  [ kafka-producer-network-thread | DemoProducer1:285 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:36:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:36:48  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:36:48  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:36:48  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:36:48  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:36:48  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:36:48  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:36:48  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:36:48  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:36:48  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:36:48  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:36:48  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:36:48  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:36:48  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:36:48  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:36:48  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:36:48  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:36:48  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:36:48  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:36:48  [ main:106 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:36:48  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:36:48  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:36:48  [ main:121 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:36:48  [ main:121 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:36:48  [ main:124 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:36:48  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:36:48  [ main:125 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:40:25  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:40:25  [ main:110 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:40:25  [ main:118 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:40:25  [ main:124 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:40:25  [ main:140 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:40:25  [ main:140 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:40:25  [ main:141 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:40:25  [ main:142 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:40:25  [ main:144 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:40:25  [ main:145 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:40:25  [ main:146 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:40:25  [ main:151 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:40:25  [ main:152 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:40:25  [ main:153 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:40:25  [ main:154 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:40:25  [ main:155 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:40:25  [ main:167 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:40:25  [ main:167 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:40:25  [ main:167 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:40:25  [ main:167 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:40:25  [ main:170 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:40:25  [ main:171 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:40:25  [ main:171 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:40:25  [ main:175 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:40:25  [ main:176 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:40:25  [ main:176 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:40:25  [ kafka-producer-network-thread | DemoProducer1:182 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:41:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:41:30  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:41:30  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:41:30  [ main:84 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:41:30  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:41:30  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:41:30  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:41:30  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:41:30  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:41:30  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:41:30  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:41:30  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:41:30  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:41:30  [ main:104 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:41:30  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:41:30  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:41:30  [ main:106 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:41:30  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:41:30  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:41:30  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:41:30  [ kafka-producer-network-thread | DemoProducer1:127 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:41:30  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:41:30  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:41:30  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:41:30  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:41:30  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:41:30  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:43:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:16  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:43:16  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:43:16  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:43:16  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:43:16  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:43:16  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:43:16  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:43:16  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:43:16  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:43:16  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:43:16  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:43:16  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:43:16  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:43:16  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:43:16  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:43:16  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:43:16  [ main:106 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:43:16  [ main:106 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:43:16  [ main:106 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:43:16  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:16  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:43:16  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:43:16  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:43:16  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:43:16  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:43:16  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:43:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:19  [ main:91 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:43:19  [ main:96 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:43:19  [ main:100 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:43:19  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:43:19  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:43:19  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:43:19  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:43:19  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:43:19  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:43:19  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:43:19  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:43:19  [ main:118 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:43:19  [ main:118 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:43:19  [ main:119 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:43:19  [ main:120 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:43:19  [ main:122 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:43:19  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:43:19  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:43:19  [ main:123 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:43:19  [ main:138 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:19  [ main:139 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:43:19  [ main:140 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:43:19  [ kafka-producer-network-thread | DemoProducer1:141 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:43:19  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:43:19  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:43:19  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:43:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:39  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:43:39  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:43:39  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:43:39  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:43:39  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:43:39  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:43:39  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:43:39  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:43:39  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:43:39  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:43:39  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:43:39  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:43:39  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:43:39  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:43:39  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:43:39  [ main:121 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:43:39  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:43:39  [ main:122 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:43:39  [ main:122 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:43:39  [ kafka-producer-network-thread | DemoProducer1:139 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:43:39  [ main:140 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:39  [ main:141 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:43:39  [ main:141 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:43:39  [ main:143 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:43:39  [ main:143 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:43:39  [ main:144 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:43:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:48  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:43:48  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:43:48  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:43:48  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:43:48  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:43:48  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:43:48  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:43:48  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:43:48  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:43:48  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:43:48  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:43:48  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:43:48  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:43:48  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:43:48  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:43:48  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:43:48  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:43:48  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:43:48  [ main:109 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:43:48  [ kafka-producer-network-thread | DemoProducer1:127 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:43:48  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:43:48  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:43:48  [ main:129 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:43:48  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:43:48  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:43:48  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:53:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:53:35  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:53:35  [ main:96 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:53:35  [ main:100 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:53:35  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:53:35  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:53:35  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:53:35  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:53:35  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:53:35  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:53:35  [ main:112 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:53:35  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:53:35  [ main:117 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:53:35  [ main:118 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:53:35  [ main:118 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:53:35  [ main:118 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:53:35  [ main:120 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:53:35  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:53:35  [ main:121 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:53:35  [ main:121 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:53:35  [ kafka-producer-network-thread | DemoProducer1:142 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:53:35  [ main:142 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:53:35  [ main:143 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:53:35  [ main:143 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:53:35  [ main:147 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:53:35  [ main:147 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:53:35  [ main:151 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:56:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:56:57  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:56:57  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:56:57  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:56:57  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:56:57  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:56:57  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:56:57  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:56:57  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:56:57  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:56:57  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:56:57  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:56:57  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:56:57  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:56:57  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:56:57  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:56:57  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:56:57  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:56:57  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:56:57  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:56:57  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:56:57  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:56:57  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:56:57  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:56:57  [ main:128 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:56:57  [ main:128 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:56:57  [ main:129 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:57:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:19  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:57:19  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:57:19  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 20:57:19  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:57:19  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:57:19  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:57:19  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:57:19  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:57:19  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:57:19  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:57:19  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:57:19  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:57:19  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:57:19  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:57:19  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:57:19  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:57:19  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:57:19  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:57:19  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:57:19  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:57:19  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:19  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:57:19  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:57:19  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:57:19  [ main:87 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:57:19  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:57:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:23  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:57:23  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:57:23  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:57:23  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:57:23  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:57:23  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:57:23  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:57:23  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:57:23  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:57:23  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:57:23  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:57:23  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:57:23  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:57:23  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:57:23  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:57:23  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:57:23  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:57:23  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:57:23  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:57:23  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:57:23  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:23  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:57:23  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:57:23  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:57:23  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:57:23  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:57:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:31  [ main:80 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:57:31  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:57:31  [ main:92 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 20:57:31  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:57:31  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:57:31  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:57:31  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:57:31  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:57:31  [ main:107 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:57:31  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:57:31  [ main:113 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:57:31  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:57:31  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:57:31  [ main:114 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:57:31  [ main:115 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:57:31  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:57:31  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:57:31  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:57:31  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:57:31  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:31  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:57:31  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:57:31  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:57:31  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:57:31  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:57:31  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 20:57:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:38  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 20:57:38  [ main:91 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 20:57:38  [ main:97 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 20:57:38  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 20:57:38  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 20:57:38  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 20:57:38  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 20:57:38  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 20:57:38  [ main:109 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 20:57:38  [ main:110 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 20:57:38  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 20:57:38  [ main:115 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 20:57:38  [ main:115 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 20:57:38  [ main:116 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 20:57:38  [ main:116 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 20:57:38  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 20:57:38  [ main:118 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 20:57:38  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 20:57:38  [ main:119 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 20:57:38  [ main:121 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 20:57:38  [ main:122 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 20:57:38  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 20:57:38  [ main:133 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 20:57:38  [ main:133 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 20:57:38  [ main:134 ] - [ DEBUG ]  Kafka producer started
2017-06-28 20:57:38  [ kafka-producer-network-thread | DemoProducer1:135 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:00:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:00:19  [ main:93 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:00:19  [ main:98 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:00:19  [ main:102 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:00:19  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:00:19  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:00:19  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:00:19  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:00:19  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:00:19  [ main:115 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:00:19  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:00:19  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:00:19  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:00:19  [ main:121 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:00:19  [ main:122 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:00:19  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:00:19  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:00:19  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:00:19  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:00:19  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:00:19  [ main:140 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:00:19  [ main:140 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:00:19  [ main:141 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:00:19  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:00:19  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:00:19  [ main:146 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:00:19  [ kafka-producer-network-thread | DemoProducer1:147 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:03:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:03:37  [ main:93 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:03:37  [ main:100 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:03:37  [ main:104 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:03:37  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:03:37  [ main:114 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:03:37  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:03:37  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:03:37  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:03:37  [ main:116 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:03:37  [ main:117 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:03:37  [ main:121 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:03:37  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:03:37  [ main:122 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:03:37  [ main:122 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:03:37  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:03:37  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:03:37  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:03:37  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:03:37  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:03:37  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:03:37  [ kafka-producer-network-thread | DemoProducer1:134 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:03:37  [ main:134 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:03:37  [ main:134 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:03:37  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:03:37  [ main:137 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:03:37  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:05:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:17  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:05:17  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:05:17  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:05:17  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:05:17  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:05:17  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:05:17  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:05:17  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:05:17  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:05:17  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:05:17  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:05:17  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:05:17  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:05:17  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:05:17  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:05:17  [ main:115 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:05:17  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:05:17  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:05:17  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:05:17  [ main:122 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:17  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:05:17  [ main:123 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:05:17  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:05:17  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:05:17  [ main:128 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:05:17  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:05:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:30  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:05:30  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:05:30  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:05:30  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:05:30  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:05:30  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:05:30  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:05:30  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:05:30  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:05:30  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:05:30  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:05:30  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:05:30  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:05:30  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:05:30  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:05:30  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:05:30  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:05:30  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:05:30  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:05:30  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:05:30  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:30  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:05:30  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:05:30  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:05:30  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:05:30  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:05:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:41  [ main:107 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:05:41  [ main:113 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:05:41  [ main:117 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:05:41  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:05:41  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:05:41  [ main:127 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:05:41  [ main:127 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:05:41  [ main:128 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:05:41  [ main:128 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:05:41  [ main:129 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:05:41  [ main:133 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:05:41  [ main:133 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:05:41  [ main:133 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:05:41  [ main:134 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:05:41  [ main:134 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:05:41  [ main:137 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:05:41  [ main:138 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:05:41  [ main:139 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:05:41  [ main:139 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:05:41  [ kafka-producer-network-thread | DemoProducer1:154 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:05:41  [ main:154 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:41  [ main:155 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:05:41  [ main:155 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:05:41  [ main:171 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:05:41  [ main:171 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:05:41  [ main:172 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:05:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:46  [ main:95 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:05:46  [ main:102 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:05:46  [ main:106 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 21:05:46  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:05:46  [ main:116 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:05:46  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:05:46  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:05:46  [ main:118 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:05:46  [ main:118 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:05:46  [ main:119 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:05:46  [ main:123 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:05:46  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:05:46  [ main:124 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:05:46  [ main:125 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:05:46  [ main:126 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:05:46  [ main:129 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:05:46  [ main:129 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:05:46  [ main:129 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:05:46  [ main:129 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:05:46  [ main:140 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:05:46  [ main:141 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:05:46  [ main:142 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:05:46  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:05:46  [ main:145 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:05:46  [ main:146 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:05:46  [ kafka-producer-network-thread | DemoProducer1:147 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:06:01  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:01  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:06:01  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:06:01  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 21:06:01  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:06:01  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:06:01  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:06:01  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:06:01  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:06:01  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:06:01  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:06:01  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:06:01  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:06:01  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:06:01  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:06:01  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:06:01  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:06:01  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:06:01  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:06:01  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:06:01  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:06:01  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:01  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:06:01  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:06:01  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:06:01  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:06:01  [ main:100 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:06:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:03  [ main:114 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:06:03  [ main:129 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:06:03  [ main:141 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:06:03  [ main:166 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:06:03  [ main:166 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:06:03  [ main:167 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:06:03  [ main:167 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:06:03  [ main:168 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:06:03  [ main:169 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:06:03  [ main:169 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:06:03  [ main:175 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:06:03  [ main:176 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:06:03  [ main:176 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:06:03  [ main:177 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:06:03  [ main:177 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:06:03  [ main:180 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:06:03  [ main:180 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:06:03  [ main:181 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:06:03  [ main:181 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:06:03  [ main:193 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:03  [ main:194 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:06:03  [ main:195 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:06:03  [ kafka-producer-network-thread | DemoProducer1:197 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:06:03  [ main:215 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:06:03  [ main:215 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:06:03  [ main:217 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:06:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:19  [ main:98 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:06:19  [ main:104 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:06:19  [ main:109 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:06:19  [ main:119 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:06:19  [ main:120 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:06:19  [ main:120 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:06:19  [ main:120 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:06:19  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:06:19  [ main:122 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:06:19  [ main:122 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:06:19  [ main:126 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:06:19  [ main:127 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:06:19  [ main:128 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:06:19  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:06:19  [ main:130 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:06:19  [ main:141 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:06:19  [ main:142 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:06:19  [ main:142 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:06:19  [ main:142 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:06:19  [ kafka-producer-network-thread | DemoProducer1:145 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:06:19  [ main:146 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:06:19  [ main:147 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:06:19  [ main:147 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:06:19  [ main:149 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:06:19  [ main:150 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:06:19  [ main:151 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:07:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:07:59  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:07:59  [ main:81 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:07:59  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:07:59  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:07:59  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:07:59  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:07:59  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:07:59  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:07:59  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:07:59  [ main:99 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:07:59  [ main:103 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:07:59  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:07:59  [ main:106 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:07:59  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:07:59  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:07:59  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:07:59  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:07:59  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:07:59  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:07:59  [ main:117 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:07:59  [ main:120 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:07:59  [ main:120 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:07:59  [ main:121 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:11:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:04  [ main:82 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:11:04  [ main:89 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:11:04  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:11:04  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:11:04  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:11:04  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:11:04  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:11:04  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:11:04  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:11:04  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:11:04  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:11:04  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:11:04  [ main:108 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:11:04  [ main:108 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:11:04  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:11:04  [ main:110 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:11:04  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:11:04  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:11:04  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:11:04  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:11:04  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:04  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:11:04  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:11:04  [ main:130 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:11:04  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:11:04  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:11:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:13  [ main:92 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:11:13  [ main:98 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:11:13  [ main:103 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:11:13  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:11:13  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:11:13  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:11:13  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:11:13  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:11:13  [ main:116 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:11:13  [ main:117 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:11:13  [ main:121 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:11:13  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:11:13  [ main:123 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:11:13  [ main:123 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:11:13  [ main:125 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:11:13  [ main:135 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:11:13  [ main:136 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:11:13  [ main:136 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:11:13  [ main:136 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:11:13  [ kafka-producer-network-thread | DemoProducer1:146 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:11:13  [ main:146 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:13  [ main:148 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:11:13  [ main:148 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:11:13  [ main:154 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:11:13  [ main:154 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:11:13  [ main:162 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:11:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:32  [ main:99 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:11:32  [ main:105 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:11:32  [ main:115 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 21:11:32  [ main:125 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:11:32  [ main:125 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:11:32  [ main:125 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:11:32  [ main:126 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:11:32  [ main:129 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:11:32  [ main:129 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:11:32  [ main:130 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:11:32  [ main:134 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:11:32  [ main:135 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:11:32  [ main:136 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:11:32  [ main:136 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:11:32  [ main:136 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:11:32  [ main:138 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:11:32  [ main:138 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:11:32  [ main:138 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:11:32  [ main:139 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:11:32  [ main:141 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:11:32  [ main:142 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:11:32  [ main:142 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:11:32  [ main:145 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:11:32  [ main:145 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:11:32  [ main:146 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:11:32  [ kafka-producer-network-thread | DemoProducer1:147 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:12:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:12:27  [ main:102 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:12:27  [ main:108 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:12:27  [ main:111 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-28 21:12:27  [ main:120 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:12:27  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:12:27  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:12:27  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:12:27  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:12:27  [ main:123 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:12:27  [ main:123 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:12:27  [ main:127 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:12:27  [ main:128 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:12:27  [ main:128 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:12:27  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:12:27  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:12:27  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:12:27  [ main:132 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:12:27  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:12:27  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:12:27  [ main:141 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:12:27  [ main:142 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:12:27  [ main:142 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:12:27  [ kafka-producer-network-thread | DemoProducer1:144 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:12:27  [ main:147 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:12:27  [ main:147 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:12:27  [ main:148 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:24:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:24:04  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:24:04  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:24:04  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:24:04  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:24:04  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:24:04  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:24:04  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:24:04  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:24:04  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:24:04  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:24:04  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:24:04  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:24:04  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:24:04  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:24:04  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:24:04  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:24:04  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:24:04  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:24:04  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:24:04  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:24:04  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:24:04  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:24:04  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:24:04  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:24:04  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:24:04  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:24:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:24:13  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:24:13  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:24:13  [ main:84 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-28 21:24:13  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:24:13  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:24:13  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:24:13  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:24:13  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:24:13  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:24:13  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:24:13  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:24:13  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:24:13  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:24:13  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:24:13  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:24:13  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:24:13  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:24:13  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:24:13  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:24:13  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:24:13  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:24:13  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:24:13  [ main:121 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:24:13  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:24:13  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-28 21:24:13  [ kafka-producer-network-thread | DemoProducer1:132 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:27:11  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:27:11  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-28 21:27:11  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-28 21:27:11  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-28 21:27:11  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-28 21:27:11  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-28 21:27:11  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-28 21:27:11  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-28 21:27:11  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-28 21:27:11  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-28 21:27:11  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-28 21:27:11  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-28 21:27:11  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-28 21:27:11  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-28 21:27:11  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-28 21:27:11  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-28 21:27:11  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-28 21:27:11  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-28 21:27:11  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-28 21:27:11  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-28 21:27:11  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-28 21:27:11  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-28 21:27:11  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-06-28 21:27:11  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-06-28 21:27:11  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-28 21:27:11  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-28 21:27:11  [ main:107 ] - [ DEBUG ]  Kafka producer started
