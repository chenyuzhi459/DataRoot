2017-07-10 09:03:12  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:12  [ main:149 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:03:12  [ main:153 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:03:12  [ main:155 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:03:12  [ main:162 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:03:12  [ main:162 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:03:12  [ main:163 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:03:12  [ main:163 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:03:12  [ main:164 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:03:12  [ main:164 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:03:12  [ main:165 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:03:12  [ main:168 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:03:12  [ main:168 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:03:12  [ main:168 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:03:12  [ main:169 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:03:12  [ main:169 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:03:12  [ main:170 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:03:12  [ main:171 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:03:12  [ main:171 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:03:12  [ main:171 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:03:12  [ main:173 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:12  [ kafka-producer-network-thread | DemoProducer1:173 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:03:12  [ main:174 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:03:12  [ main:174 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:03:12  [ main:176 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:03:12  [ main:177 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:03:12  [ main:177 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:03:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:52  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:03:52  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:03:52  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:03:52  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:03:52  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:03:52  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:03:52  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:03:52  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:03:52  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:03:52  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:03:52  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:03:52  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:03:52  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:03:52  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:03:52  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:03:52  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:03:52  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:03:52  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:03:52  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:03:52  [ kafka-producer-network-thread | DemoProducer1:76 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:03:52  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:52  [ main:76 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:03:52  [ main:77 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:03:52  [ main:79 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:03:52  [ main:79 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:03:52  [ main:80 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:03:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:55  [ main:91 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:03:55  [ main:97 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:03:55  [ main:99 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:03:55  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:03:55  [ main:110 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:03:55  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:03:55  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:03:55  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:03:55  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:03:55  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:03:55  [ main:118 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:03:55  [ main:119 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:03:55  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:03:55  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:03:55  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:03:55  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:03:55  [ main:132 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:03:55  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:03:55  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:03:55  [ kafka-producer-network-thread | DemoProducer1:137 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:03:55  [ main:138 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:55  [ main:138 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:03:55  [ main:138 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:03:55  [ main:141 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:03:55  [ main:141 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:03:55  [ main:142 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:03:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:58  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:03:58  [ main:127 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:03:58  [ main:133 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:03:58  [ main:145 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:03:58  [ main:145 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:03:58  [ main:146 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:03:58  [ main:147 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:03:58  [ main:149 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:03:58  [ main:149 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:03:58  [ main:151 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:03:58  [ main:164 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:03:58  [ main:169 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:03:58  [ main:170 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:03:58  [ main:171 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:03:58  [ main:172 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:03:58  [ main:183 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:03:58  [ main:183 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:03:58  [ main:183 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:03:58  [ main:184 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:03:58  [ main:201 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:03:58  [ main:202 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:03:58  [ main:202 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:03:58  [ kafka-producer-network-thread | DemoProducer1:203 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:03:58  [ main:205 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:03:58  [ main:205 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:03:58  [ main:206 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:04:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:00  [ main:98 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:04:00  [ main:106 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:04:00  [ main:108 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:04:00  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:04:00  [ main:138 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:04:00  [ main:139 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:04:00  [ main:139 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:04:00  [ main:140 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:04:00  [ main:140 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:04:00  [ main:141 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:04:00  [ main:145 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:04:00  [ main:146 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:04:00  [ main:147 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:04:00  [ main:147 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:04:00  [ main:148 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:04:00  [ main:159 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:04:00  [ main:160 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:04:00  [ main:160 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:04:00  [ main:161 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:04:00  [ main:172 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:00  [ main:172 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:04:00  [ main:173 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:04:00  [ kafka-producer-network-thread | DemoProducer1:179 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:04:00  [ main:180 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:04:00  [ main:180 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:04:00  [ main:181 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:04:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:02  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:04:02  [ main:94 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:04:02  [ main:96 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:04:02  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:04:02  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:04:02  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:04:02  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:04:02  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:04:02  [ main:108 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:04:02  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:04:02  [ main:112 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:04:02  [ main:112 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:04:02  [ main:113 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:04:02  [ main:113 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:04:02  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:04:02  [ main:115 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:04:02  [ main:115 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:04:02  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:04:02  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:04:02  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:02  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:04:02  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:04:02  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:04:02  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:04:02  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:04:02  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:04:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:05  [ main:82 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:04:05  [ main:87 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:04:05  [ main:90 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:04:05  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:04:05  [ main:116 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:04:05  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:04:05  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:04:05  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:04:05  [ main:117 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:04:05  [ main:118 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:04:05  [ main:121 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:04:05  [ main:121 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:04:05  [ main:122 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:04:05  [ main:122 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:04:05  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:04:05  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:04:05  [ main:124 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:04:05  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:04:05  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:04:05  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:04:05  [ main:130 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:05  [ main:130 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:04:05  [ main:131 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:04:05  [ main:134 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:04:05  [ main:134 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:04:05  [ main:135 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:04:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:07  [ main:88 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:04:07  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:04:07  [ main:98 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:04:07  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:04:07  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:04:07  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:04:07  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:04:07  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:04:07  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:04:07  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:04:07  [ main:116 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:04:07  [ main:117 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:04:07  [ main:117 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:04:07  [ main:118 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:04:07  [ main:118 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:04:07  [ main:119 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:04:07  [ main:120 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:04:07  [ main:120 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:04:07  [ main:120 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:04:07  [ kafka-producer-network-thread | DemoProducer1:126 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:04:07  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:04:07  [ main:127 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:04:07  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:04:07  [ main:139 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:04:07  [ main:139 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:04:07  [ main:144 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:05:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:05:33  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:05:33  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:05:33  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:05:33  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:05:33  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:05:33  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:05:33  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:05:33  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:05:33  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:05:33  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:05:33  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:05:33  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:05:33  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:05:33  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:05:33  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:05:33  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:05:33  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:05:33  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:05:33  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:05:33  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:05:33  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:05:33  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:05:33  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:05:33  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:05:33  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:05:33  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:05:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:05:39  [ main:48 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:05:39  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:05:39  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:05:39  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:05:39  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:05:39  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:05:39  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:05:39  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:05:39  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:05:39  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:05:39  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:05:39  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:05:39  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:05:39  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:05:39  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:05:39  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:05:39  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:05:39  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:05:39  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:05:39  [ kafka-producer-network-thread | DemoProducer1:76 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:05:39  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:05:39  [ main:77 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:05:39  [ main:77 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:05:39  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:05:39  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:05:39  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:06:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:06:05  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:06:05  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:06:05  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:06:05  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:06:05  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:06:05  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:06:05  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:06:05  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:06:05  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:06:05  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:06:05  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:06:05  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:06:05  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:06:05  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:06:05  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:06:05  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:06:05  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:06:05  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:06:05  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:06:05  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:06:05  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:06:05  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:06:05  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:06:05  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:06:05  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:06:05  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:08:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:08:58  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:08:58  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:08:58  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:08:58  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:08:58  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:08:58  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:08:58  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:08:58  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:08:58  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:08:58  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:08:58  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:08:58  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:08:58  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:08:58  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:08:58  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:08:58  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:08:58  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:08:58  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:08:58  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:08:58  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:08:58  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:08:58  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:08:58  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:08:58  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:08:58  [ main:87 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:08:58  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:09:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:05  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:09:05  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:09:05  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:09:05  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:09:05  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:09:05  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:09:05  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:09:05  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:09:05  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:09:05  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:09:05  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:09:05  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:09:05  [ main:107 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:09:05  [ main:108 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:09:05  [ main:108 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:09:05  [ main:110 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:09:05  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:09:05  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:09:05  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:09:05  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:05  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:09:05  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:09:05  [ kafka-producer-network-thread | DemoProducer1:116 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:09:05  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:09:05  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:09:05  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:09:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:18  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:09:18  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:09:18  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:09:18  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:09:18  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:09:18  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:09:18  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:09:18  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:09:18  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:09:18  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:09:18  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:09:18  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:09:18  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:09:18  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:09:18  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:09:18  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:09:18  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:09:18  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:09:18  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:09:18  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:09:18  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:18  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:09:18  [ main:97 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:09:18  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:09:18  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:09:18  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:09:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:20  [ main:103 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:09:20  [ main:109 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:09:20  [ main:112 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:09:20  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:09:20  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:09:20  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:09:20  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:09:20  [ main:123 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:09:20  [ main:124 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:09:20  [ main:124 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:09:20  [ main:128 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:09:20  [ main:128 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:09:20  [ main:129 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:09:20  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:09:20  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:09:20  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:09:20  [ main:131 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:09:20  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:09:20  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:09:20  [ kafka-producer-network-thread | DemoProducer1:144 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:09:20  [ main:144 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:09:20  [ main:145 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:09:20  [ main:145 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:09:20  [ main:148 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:09:20  [ main:148 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:09:20  [ main:149 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:12:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:12:18  [ main:97 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:12:18  [ main:102 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:12:18  [ main:106 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:12:18  [ main:123 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:12:18  [ main:123 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:12:18  [ main:123 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:12:18  [ main:124 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:12:18  [ main:126 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:12:18  [ main:126 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:12:18  [ main:126 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:12:18  [ main:131 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:12:18  [ main:131 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:12:18  [ main:132 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:12:18  [ main:132 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:12:18  [ main:132 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:12:18  [ main:134 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:12:18  [ main:134 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:12:18  [ main:134 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:12:18  [ main:135 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:12:18  [ kafka-producer-network-thread | DemoProducer1:149 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:12:18  [ main:151 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:12:18  [ main:151 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:12:18  [ main:151 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:12:18  [ main:166 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:12:18  [ main:167 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:12:18  [ main:172 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:13:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:28  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:13:28  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:13:28  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:13:28  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:13:28  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:13:28  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:13:28  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:13:28  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:13:28  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:13:28  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:13:28  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:13:28  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:13:28  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:13:28  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:13:28  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:13:28  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:13:28  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:13:28  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:13:28  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:13:28  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:13:28  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:28  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:13:28  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:13:28  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:13:28  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:13:28  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:13:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:41  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:13:41  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:13:41  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:13:41  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:13:41  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:13:41  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:13:41  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:13:41  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:13:41  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:13:41  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:13:41  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:13:41  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:13:41  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:13:41  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:13:41  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:13:41  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:13:41  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:13:41  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:13:41  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:13:41  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:13:41  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:41  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:13:41  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:13:41  [ main:81 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:13:41  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:13:41  [ main:82 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:13:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:44  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:13:44  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:13:44  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:13:44  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:13:44  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:13:44  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:13:44  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:13:44  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:13:44  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:13:44  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:13:44  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:13:44  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:13:44  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:13:44  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:13:44  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:13:44  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:13:44  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:13:44  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:13:44  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:13:44  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:44  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:13:44  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:13:44  [ kafka-producer-network-thread | DemoProducer1:110 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:13:44  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:13:44  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:13:45  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:13:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:58  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:13:58  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:13:58  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:13:58  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:13:58  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:13:58  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:13:58  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:13:58  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:13:58  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:13:58  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:13:58  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:13:58  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:13:58  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:13:58  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:13:58  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:13:58  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:13:58  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:13:58  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:13:58  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:13:58  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:13:58  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:13:58  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:13:58  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:13:58  [ main:130 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:13:58  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:13:58  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:15:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:15:50  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:15:50  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:15:50  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:15:50  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:15:50  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:15:50  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:15:50  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:15:50  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:15:50  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:15:50  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:15:50  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:15:50  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:15:50  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:15:50  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:15:50  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:15:50  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:15:50  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:15:50  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:15:50  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:15:50  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:15:50  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:15:50  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:15:50  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:15:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:15:56  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:15:56  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:15:56  [ main:84 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:15:56  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:15:56  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:15:56  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:15:56  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:15:56  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:15:56  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:15:56  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:15:56  [ main:99 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:15:56  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:15:56  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:15:56  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:15:56  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:15:56  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:15:56  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:15:56  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:15:56  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:15:57  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:15:57  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:15:57  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:15:57  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:15:57  [ main:120 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:15:57  [ main:120 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:15:57  [ main:121 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:18:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:18:33  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:18:33  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:18:33  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:18:33  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:18:33  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:18:33  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:18:33  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:18:33  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:18:33  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:18:33  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:18:33  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:18:33  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:18:33  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:18:33  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:18:33  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:18:33  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:18:33  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:18:33  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:18:33  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:18:33  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:18:33  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:18:33  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:18:33  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:18:33  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:18:33  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:18:33  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:11  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:11  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:11  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:21:11  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:11  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:11  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:11  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:11  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:11  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:11  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:11  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:11  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:11  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:11  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:11  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:11  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:11  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:11  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:11  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:11  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:11  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:11  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:11  [ kafka-producer-network-thread | DemoProducer1:93 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:11  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:11  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:11  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:19  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:19  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:19  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:21:19  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:19  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:19  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:19  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:19  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:19  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:19  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:19  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:19  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:19  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:19  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:19  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:19  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:19  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:19  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:19  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:19  [ kafka-producer-network-thread | DemoProducer1:76 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:19  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:19  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:19  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:19  [ main:80 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:19  [ main:81 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:19  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:21  [ main:48 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:21  [ main:52 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:21  [ main:54 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:21:21  [ main:61 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:21  [ main:61 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:21  [ main:62 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:21  [ main:62 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:21  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:21  [ main:63 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:21  [ main:64 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:21  [ main:67 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:21  [ main:67 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:21  [ main:67 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:21  [ main:68 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:21  [ main:68 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:21  [ main:69 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:21  [ main:70 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:21  [ main:70 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:21  [ main:70 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:21  [ kafka-producer-network-thread | DemoProducer1:71 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:21  [ main:72 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:21  [ main:72 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:21  [ main:72 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:21  [ main:75 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:21  [ main:75 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:21  [ main:76 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:24  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:24  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:24  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:21:24  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:24  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:24  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:24  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:24  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:24  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:24  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:24  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:24  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:24  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:24  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:24  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:24  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:24  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:24  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:24  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:24  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:24  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:24  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:24  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:24  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:24  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:24  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:33  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:33  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:33  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:21:33  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:33  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:33  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:33  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:33  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:33  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:33  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:33  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:33  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:33  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:33  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:33  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:33  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:33  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:33  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:33  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:33  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:33  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:33  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:33  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:33  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:33  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:33  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:21:46  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:46  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:21:46  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:21:46  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:21:46  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:21:46  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:21:46  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:21:46  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:21:46  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:21:46  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:21:46  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:21:46  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:21:46  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:21:46  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:21:46  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:21:46  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:21:46  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:21:46  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:21:46  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:21:46  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:21:46  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:21:46  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:21:46  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:21:46  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:21:46  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:21:46  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:21:46  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:23:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:04  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:23:04  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:23:04  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:23:04  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:23:04  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:23:04  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:23:04  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:23:04  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:23:04  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:23:04  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:23:04  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:23:04  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:23:04  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:23:04  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:23:04  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:23:04  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:23:04  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:23:04  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:23:04  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:23:04  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:23:04  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:04  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:23:04  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:23:04  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:23:04  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:23:04  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:23:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:09  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:23:09  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:23:09  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:23:09  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:23:09  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:23:09  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:23:09  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:23:09  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:23:09  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:23:09  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:23:09  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:23:09  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:23:09  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:23:09  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:23:09  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:23:09  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:23:09  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:23:09  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:23:09  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:23:09  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:23:09  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:09  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:23:09  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:23:09  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:23:09  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:23:09  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:23:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:13  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:23:13  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:23:13  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:23:13  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:23:13  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:23:13  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:23:13  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:23:13  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:23:13  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:23:13  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:23:13  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:23:13  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:23:13  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:23:13  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:23:13  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:23:13  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:23:13  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:23:13  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:23:13  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:23:13  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:23:13  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:23:13  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:23:13  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:23:13  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:23:13  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:23:13  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:24:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:24:55  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:24:55  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:24:55  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:24:55  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:24:55  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:24:55  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:24:55  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:24:55  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:24:55  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:24:55  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:24:55  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:24:55  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:24:55  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:24:55  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:24:55  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:24:55  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:24:55  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:24:55  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:24:55  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:24:55  [ main:94 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:24:55  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:24:55  [ main:95 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:24:55  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:24:55  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:24:55  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:24:55  [ main:98 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:24:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:24:59  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:24:59  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:24:59  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:24:59  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:24:59  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:24:59  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:24:59  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:24:59  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:24:59  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:24:59  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:24:59  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:24:59  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:24:59  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:24:59  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:24:59  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:24:59  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:24:59  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:24:59  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:24:59  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:24:59  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:24:59  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:24:59  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:24:59  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:24:59  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:24:59  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:24:59  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:33:01  [ kafka-producer-network-thread | DemoProducer1:482381 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-07-10 09:33:01  [ kafka-producer-network-thread | DemoProducer1:482382 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-07-10 09:33:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:33:03  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:33:03  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:33:03  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:33:03  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:33:03  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:33:03  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:33:03  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:33:03  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:33:03  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:33:03  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:33:03  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:33:03  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:33:03  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:33:03  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:33:03  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:33:03  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:33:03  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:33:03  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:33:03  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:33:03  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:33:03  [ main:82 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:33:03  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:33:03  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:33:03  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:33:03  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:33:03  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:34:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:34:23  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:34:23  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:34:23  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:34:23  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:34:23  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:34:23  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:34:23  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:34:23  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:34:23  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:34:23  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:34:23  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:34:23  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:34:23  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:34:23  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:34:23  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:34:23  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:34:23  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:34:23  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:34:23  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:34:23  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:34:23  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:34:23  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:34:23  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:34:23  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:34:23  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:34:23  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:36:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:36:15  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:36:15  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:36:15  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:36:15  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:36:15  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:36:15  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:36:15  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:36:15  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:36:15  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:36:15  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:36:15  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:36:15  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:36:15  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:36:15  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:36:15  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:36:15  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:36:15  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:36:15  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:36:15  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:36:15  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:36:15  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:36:15  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:36:15  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:36:15  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:36:15  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:36:15  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:36:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:36:38  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:36:38  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:36:38  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:36:38  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:36:38  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:36:38  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:36:38  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:36:38  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:36:38  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:36:38  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:36:38  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:36:38  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:36:38  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:36:38  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:36:38  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:36:38  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:36:38  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:36:38  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:36:38  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:36:38  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:36:38  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:36:38  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:36:38  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:36:38  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:36:38  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:36:38  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:39:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:16  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:39:16  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:39:16  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:39:16  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:39:16  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:39:16  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:39:16  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:39:16  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:39:16  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:39:16  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:39:16  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:39:16  [ main:69 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:39:16  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:39:16  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:39:16  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:39:16  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:39:16  [ main:72 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:39:16  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:39:16  [ main:72 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:39:16  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:39:16  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:16  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:39:16  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:39:16  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:39:16  [ main:87 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:39:16  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:39:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:32  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:39:32  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:39:32  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:39:32  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:39:32  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:39:32  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:39:32  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:39:32  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:39:32  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:39:32  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:39:32  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:39:32  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:39:32  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:39:32  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:39:32  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:39:32  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:39:32  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:39:32  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:39:32  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:39:32  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:32  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:39:32  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:39:32  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:39:32  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:39:32  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:39:32  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:39:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:38  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:39:38  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:39:38  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:39:38  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:39:38  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:39:38  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:39:38  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:39:38  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:39:38  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:39:38  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:39:38  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:39:38  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:39:38  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:39:38  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:39:38  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:39:38  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:39:38  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:39:38  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:39:38  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:39:38  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:39:38  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:39:38  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:39:38  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:39:38  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:39:38  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:39:38  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:40:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:40:02  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:40:02  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:40:02  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:40:02  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:40:02  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:40:02  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:40:02  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:40:02  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:40:02  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:40:02  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:40:02  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:40:02  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:40:02  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:40:02  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:40:02  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:40:02  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:40:02  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:40:02  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:40:02  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:40:02  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:40:02  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:40:02  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:40:02  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:40:02  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:40:02  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:40:02  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:41:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:41:25  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:41:25  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:41:25  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:41:25  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:41:25  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:41:25  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:41:25  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:41:25  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:41:25  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:41:25  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:41:25  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:41:25  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:41:25  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:41:25  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:41:25  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:41:25  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:41:25  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:41:25  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:41:25  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:41:25  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:41:25  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:41:25  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:41:25  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:41:25  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:41:25  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:41:25  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:48:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:48:34  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:48:34  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:48:34  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:48:34  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:48:34  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:48:34  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:48:34  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:48:34  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:48:34  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:48:34  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:48:34  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:48:34  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:48:34  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:48:34  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:48:34  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:48:34  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:48:34  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:48:34  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:48:34  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:48:34  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:48:34  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:48:34  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:48:34  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:48:34  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:48:34  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:48:34  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:48:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:48:52  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:48:52  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:48:52  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:48:52  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:48:52  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:48:52  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:48:52  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:48:52  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:48:52  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:48:52  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:48:52  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:48:52  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:48:52  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:48:52  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:48:52  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:48:52  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:48:52  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:48:52  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:48:52  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:48:52  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:48:52  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:48:52  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:48:52  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:48:52  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:48:52  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:48:52  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:49:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:15  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:49:15  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:49:15  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:49:15  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:49:15  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:49:15  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:49:15  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:49:15  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:49:15  [ main:66 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:49:15  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:49:15  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:49:15  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:49:15  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:49:15  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:49:15  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:49:15  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:49:15  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:49:15  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:49:15  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:49:15  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:49:15  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:15  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:49:15  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:49:15  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:49:15  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:49:15  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:49:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:26  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:49:26  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:49:26  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:49:26  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:49:26  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:49:26  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:49:26  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:49:26  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:49:26  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:49:26  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:49:26  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:49:26  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:49:26  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:49:26  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:49:26  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:49:26  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:49:26  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:49:26  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:49:26  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:49:26  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:49:26  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:26  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:49:26  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:49:26  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:49:26  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:49:26  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:49:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:59  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:49:59  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:49:59  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:49:59  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:49:59  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:49:59  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:49:59  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:49:59  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:49:59  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:49:59  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:49:59  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:49:59  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:49:59  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:49:59  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:49:59  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:49:59  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:49:59  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:49:59  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:49:59  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:49:59  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:49:59  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:49:59  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:49:59  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:49:59  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:49:59  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:49:59  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:51:10  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:10  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:51:10  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:51:10  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:51:10  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:51:10  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:51:10  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:51:10  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:51:10  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:51:10  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:51:10  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:51:10  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:51:10  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:51:10  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:51:10  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:51:10  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:51:10  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:51:10  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:51:10  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:51:10  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:51:10  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:51:10  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:10  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:51:10  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:51:10  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:51:10  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:51:10  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:51:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:24  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:51:24  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:51:24  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:51:24  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:51:24  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:51:24  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:51:24  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:51:24  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:51:24  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:51:24  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:51:24  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:51:24  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:51:24  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:51:24  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:51:24  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:51:24  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:51:24  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:51:24  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:51:24  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:51:24  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:51:24  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:24  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:51:24  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:51:24  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:51:24  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:51:24  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:51:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:52  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:51:52  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:51:52  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:51:52  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:51:52  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:51:52  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:51:52  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:51:52  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:51:52  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:51:52  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:51:52  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:51:52  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:51:52  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:51:52  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:51:52  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:51:52  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:51:52  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:51:52  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:51:52  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:51:52  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:51:52  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:51:52  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:51:52  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:51:52  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:51:52  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:51:52  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:52:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:25  [ main:82 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:52:25  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:52:25  [ main:92 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:52:25  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:52:25  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:52:25  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:52:25  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:52:25  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:52:25  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:52:25  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:52:25  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:52:25  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:52:25  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:52:25  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:52:25  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:52:25  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:52:25  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:52:25  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:52:25  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:52:25  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:52:25  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:25  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:52:25  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:52:25  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:52:25  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:52:25  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:52:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:32  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:52:32  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:52:32  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:52:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:52:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:52:32  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:52:32  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:52:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:52:32  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:52:32  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:52:32  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:52:32  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:52:32  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:52:32  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:52:32  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:52:32  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:52:32  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:52:32  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:52:32  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:52:32  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:52:32  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:32  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:52:32  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:52:33  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:52:33  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:52:33  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:52:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:35  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:52:35  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:52:35  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:52:35  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:52:35  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:52:35  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:52:35  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:52:35  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:52:35  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:52:35  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:52:35  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:52:35  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:52:35  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:52:35  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:52:35  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:52:35  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:52:35  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:52:35  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:52:35  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:52:35  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:52:35  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:52:35  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:52:35  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:52:35  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:52:35  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:52:35  [ main:121 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:55:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:55:06  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:55:06  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:55:06  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:55:06  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:55:06  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:55:06  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:55:06  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:55:06  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:55:06  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:55:06  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:55:06  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:55:06  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:55:06  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:55:06  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:55:06  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:55:06  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:55:06  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:55:06  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:55:06  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:55:06  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:55:06  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:55:06  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:55:06  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:55:06  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:55:06  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:55:06  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:55:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:55:48  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:55:48  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:55:48  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:55:48  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:55:48  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:55:48  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:55:48  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:55:48  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:55:48  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:55:48  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:55:48  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:55:48  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:55:48  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:55:48  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:55:48  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:55:48  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:55:48  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:55:48  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:55:48  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:55:48  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:55:48  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:55:48  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:55:48  [ kafka-producer-network-thread | DemoProducer1:93 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:55:48  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:55:48  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:55:48  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:56:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:56:29  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:56:29  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:56:29  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:56:29  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:56:29  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:56:29  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:56:29  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:56:29  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:56:29  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:56:29  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:56:29  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:56:29  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:56:29  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:56:29  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:56:29  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:56:29  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:56:29  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:56:29  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:56:29  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:56:29  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:56:29  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:56:29  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:56:29  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:56:29  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:56:29  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:56:29  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:56:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:56:47  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:56:47  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:56:47  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 09:56:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:56:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:56:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:56:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:56:47  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:56:47  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:56:47  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:56:47  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:56:47  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:56:47  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:56:47  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:56:47  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:56:47  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:56:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:56:47  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:56:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:56:47  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:56:47  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:56:47  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:56:47  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:56:47  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:56:47  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:56:47  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:59:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:45  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:59:45  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:59:45  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 09:59:45  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:59:45  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:59:45  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:59:45  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:59:45  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:59:45  [ main:66 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:59:45  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:59:45  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:59:45  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:59:45  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:59:45  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:59:45  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:59:45  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:59:45  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:59:45  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:59:45  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:59:45  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:45  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:59:45  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:59:45  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:59:45  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:59:45  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:59:45  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:59:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:49  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:59:49  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:59:49  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:59:49  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:59:49  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:59:49  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:59:49  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:59:49  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:59:49  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:59:49  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:59:49  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:59:49  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:59:49  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:59:49  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:59:49  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:59:49  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:59:49  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:59:49  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:59:49  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:59:49  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:59:49  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:49  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:59:49  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:59:49  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:59:49  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:59:49  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:59:51  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:51  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:59:51  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:59:51  [ main:87 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 09:59:51  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 09:59:51  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 09:59:51  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 09:59:51  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 09:59:51  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 09:59:51  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 09:59:51  [ main:103 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 09:59:51  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 09:59:51  [ main:109 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 09:59:51  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 09:59:51  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 09:59:51  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 09:59:51  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 09:59:51  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 09:59:51  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 09:59:51  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 09:59:51  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 09:59:51  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:51  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 09:59:51  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 09:59:51  [ main:124 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 09:59:51  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 09:59:51  [ main:128 ] - [ DEBUG ]  Kafka producer started
2017-07-10 09:59:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 09:59:59  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 09:59:59  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 09:59:59  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 10:00:00  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:00:00  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:00:00  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:00:00  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:00:00  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:00:00  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:00:00  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:00:00  [ main:104 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:00:00  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:00:00  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:00:00  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:00:00  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:00:00  [ main:112 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:00:00  [ main:113 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:00:00  [ main:113 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:00:00  [ main:113 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:00:00  [ kafka-producer-network-thread | DemoProducer1:117 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:00:00  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:00:00  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:00:00  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:00:00  [ main:121 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:00:00  [ main:121 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:00:00  [ main:122 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:00:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:00:02  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:00:02  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:00:02  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 10:00:02  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:00:02  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:00:02  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:00:02  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:00:02  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:00:02  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:00:02  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:00:02  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:00:02  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:00:02  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:00:02  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:00:02  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:00:02  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:00:02  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:00:02  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:00:02  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:00:02  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:00:02  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:00:02  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:00:02  [ main:130 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:00:02  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:00:02  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:00:02  [ kafka-producer-network-thread | DemoProducer1:145 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:30:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:30:06  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:30:06  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:30:06  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 10:30:06  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:30:06  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:30:06  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:30:06  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:30:06  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:30:06  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:30:06  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:30:06  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:30:06  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:30:06  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:30:06  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:30:06  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:30:06  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:30:06  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:30:06  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:30:06  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:30:06  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:30:06  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:30:06  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:30:06  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:30:06  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:30:06  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:30:06  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:30:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:30:42  [ main:47 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:30:42  [ main:51 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:30:42  [ main:53 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 10:30:42  [ main:60 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:30:42  [ main:60 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:30:42  [ main:61 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:30:42  [ main:61 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:30:42  [ main:62 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:30:42  [ main:62 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:30:42  [ main:62 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:30:42  [ main:66 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:30:42  [ main:67 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:30:42  [ main:67 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:30:42  [ main:68 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:30:42  [ main:69 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:30:42  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:30:42  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:30:42  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:30:42  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:30:42  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:30:42  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:30:42  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:30:42  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:30:42  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:30:42  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:30:42  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:31:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:31:16  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:31:16  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:31:16  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 10:31:16  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:31:16  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:31:16  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:31:16  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:31:16  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:31:16  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:31:16  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:31:16  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:31:16  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:31:16  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:31:16  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:31:16  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:31:16  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:31:16  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:31:16  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:31:16  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:31:16  [ kafka-producer-network-thread | DemoProducer1:93 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:31:16  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:31:16  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:31:16  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:31:16  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:31:16  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:31:16  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:31:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:31:33  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:31:33  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:31:33  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 10:31:33  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:31:33  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:31:33  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:31:33  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:31:33  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:31:33  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:31:33  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:31:33  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:31:33  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:31:33  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:31:33  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:31:33  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:31:33  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:31:33  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:31:33  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:31:33  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:31:33  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:31:33  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:31:33  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:31:33  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:31:33  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:31:33  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:31:33  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-07-10 10:33:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:33:04  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 10:33:04  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 10:33:04  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 10:33:04  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 10:33:04  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 10:33:04  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 10:33:04  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 10:33:04  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 10:33:04  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 10:33:04  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 10:33:04  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 10:33:04  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 10:33:04  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 10:33:04  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 10:33:04  [ main:71 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 10:33:04  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 10:33:04  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 10:33:04  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 10:33:04  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 10:33:04  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 10:33:04  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 180 was supplied but isn't a known config.
2017-07-10 10:33:04  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0628 was supplied but isn't a known config.
2017-07-10 10:33:04  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 10:33:04  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 10:33:04  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 10:33:04  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-07-10 11:36:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:36:49  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 11:36:49  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 11:36:49  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 11:36:49  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 11:36:49  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 11:36:49  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 11:36:49  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 11:36:49  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 11:36:49  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 11:36:49  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 11:36:49  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 11:36:49  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 11:36:49  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 11:36:49  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 11:36:49  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 11:36:49  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 11:36:49  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 11:36:49  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 11:36:49  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 11:36:49  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 11:36:49  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:36:49  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 11:36:49  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0710 was supplied but isn't a known config.
2017-07-10 11:36:49  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 11:36:49  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 11:36:49  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-07-10 11:36:52  [ main:3248 ] - [ INFO ]  user number : 10595  , send message count : 163845
2017-07-10 11:38:41  [ main:112734 ] - [ INFO ]  user number : 10596  , send message count : 163847
2017-07-10 11:39:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:39:31  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 11:39:31  [ main:83 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 11:39:31  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 11:39:31  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 11:39:31  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 11:39:31  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 11:39:31  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 11:39:31  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 11:39:31  [ main:112 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 11:39:31  [ main:114 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 11:39:31  [ main:118 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 11:39:31  [ main:119 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 11:39:31  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 11:39:31  [ main:120 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 11:39:31  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 11:39:31  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 11:39:31  [ main:132 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 11:39:31  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 11:39:31  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 11:39:31  [ kafka-producer-network-thread | DemoProducer1:137 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 11:39:31  [ main:137 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:39:31  [ main:137 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 11:39:31  [ main:138 ] - [ WARN ]  The configuration topic = testRealTime0710 was supplied but isn't a known config.
2017-07-10 11:39:31  [ main:140 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 11:39:31  [ main:140 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 11:39:31  [ main:141 ] - [ DEBUG ]  Kafka producer started
2017-07-10 11:40:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:40:24  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 11:40:24  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 11:40:24  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 11:40:24  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 11:40:24  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 11:40:24  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 11:40:24  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 11:40:24  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 11:40:24  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 11:40:24  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 11:40:24  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 11:40:24  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 11:40:24  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 11:40:24  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 11:40:24  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 11:40:24  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 11:40:24  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 11:40:24  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 11:40:24  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 11:40:24  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:40:24  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 11:40:24  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0710 was supplied but isn't a known config.
2017-07-10 11:40:24  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 11:40:24  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 11:40:24  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 11:40:24  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-07-10 11:40:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:40:39  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 11:40:39  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 11:40:39  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 11:40:39  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 11:40:39  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 11:40:39  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 11:40:39  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 11:40:39  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 11:40:39  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 11:40:39  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 11:40:39  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 11:40:39  [ main:91 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 11:40:39  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 11:40:39  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 11:40:39  [ main:92 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 11:40:39  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 11:40:39  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 11:40:39  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 11:40:39  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 11:40:39  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 11:40:39  [ main:106 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 11:40:39  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 11:40:39  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0710 was supplied but isn't a known config.
2017-07-10 11:40:39  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 11:40:39  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 11:40:39  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-07-10 11:40:42  [ main:3141 ] - [ INFO ]  user number : 10808  , send message count : 164360
2017-07-10 14:16:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:16:54  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:16:54  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:16:54  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 14:16:54  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:16:54  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:16:54  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:16:54  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:16:54  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:16:54  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:16:54  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:16:54  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:16:54  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:16:54  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:16:54  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:16:54  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:16:54  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:16:54  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:16:54  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:16:54  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:16:54  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:16:54  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:16:54  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:16:54  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime071001 was supplied but isn't a known config.
2017-07-10 14:16:54  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:16:54  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:16:54  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3892 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3892 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3940 ] - [ DEBUG ]  Added sensor with name node--1.bytes-sent
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3940 ] - [ DEBUG ]  Added sensor with name node--1.bytes-received
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3940 ] - [ DEBUG ]  Added sensor with name node--1.latency
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3941 ] - [ DEBUG ]  Completed connection to node -1
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3959 ] - [ DEBUG ]  Sending metadata request {topics=[testRealTime071001]} to node -1
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3973 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null)], partitions = [Partition(topic = testRealTime071001, partition = 0, leader = 2, replicas = [2,], isr = [2,]])
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3982 ] - [ DEBUG ]  Initiating connection to node 2 at 192.168.0.222:9092.
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3983 ] - [ DEBUG ]  Added sensor with name node-2.bytes-sent
2017-07-10 14:16:58  [ kafka-producer-network-thread | DemoProducer1:3984 ] - [ DEBUG ]  Added sensor with name node-2.bytes-received
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8588 ] - [ DEBUG ]  Added sensor with name node-2.latency
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8589 ] - [ DEBUG ]  Completed connection to node 2
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8589 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.records-per-batch
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8589 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.bytes
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8590 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.compression-rate
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8590 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.record-retries
2017-07-10 14:17:02  [ kafka-producer-network-thread | DemoProducer1:8590 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.record-errors
2017-07-10 14:18:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:18:46  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:18:46  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:18:46  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 14:18:46  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:18:46  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:18:46  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:18:46  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:18:46  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:18:46  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:18:46  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:18:46  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:18:46  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:18:46  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:18:46  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:18:46  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:18:46  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:18:46  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:18:46  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:18:46  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:18:46  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:18:46  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:18:46  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:18:46  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime071001 was supplied but isn't a known config.
2017-07-10 14:18:46  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:18:46  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:18:46  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:18:46  [ kafka-producer-network-thread | DemoProducer1:224 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-07-10 14:18:46  [ kafka-producer-network-thread | DemoProducer1:224 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:296 ] - [ DEBUG ]  Added sensor with name node--1.bytes-sent
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:296 ] - [ DEBUG ]  Added sensor with name node--1.bytes-received
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:296 ] - [ DEBUG ]  Added sensor with name node--1.latency
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:297 ] - [ DEBUG ]  Completed connection to node -1
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:313 ] - [ DEBUG ]  Sending metadata request {topics=[testRealTime071001]} to node -1
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:326 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [Partition(topic = testRealTime071001, partition = 0, leader = 2, replicas = [2,], isr = [2,]])
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:344 ] - [ DEBUG ]  Initiating connection to node 2 at 192.168.0.222:9092.
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:345 ] - [ DEBUG ]  Added sensor with name node-2.bytes-sent
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:345 ] - [ DEBUG ]  Added sensor with name node-2.bytes-received
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:346 ] - [ DEBUG ]  Added sensor with name node-2.latency
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:346 ] - [ DEBUG ]  Completed connection to node 2
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:346 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.records-per-batch
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:346 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.bytes
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:347 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.compression-rate
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:347 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.record-retries
2017-07-10 14:18:47  [ kafka-producer-network-thread | DemoProducer1:347 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071001.record-errors
2017-07-10 14:18:56  [ main:9784 ] - [ INFO ]  user number : 10849  , send message count : 164361
2017-07-10 14:34:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:34:52  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:34:52  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:34:52  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 14:34:52  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:34:52  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:34:52  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:34:52  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:34:52  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:34:52  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:34:52  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:34:52  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:34:52  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:34:52  [ main:120 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:34:52  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:34:52  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:34:52  [ main:122 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:34:52  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:34:52  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:34:52  [ main:123 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:34:53  [ main:130 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:34:53  [ main:131 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:34:53  [ main:131 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:34:53  [ kafka-producer-network-thread | DemoProducer1:132 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:34:53  [ main:134 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:34:53  [ main:135 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:34:53  [ main:135 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:35:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:35:31  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:35:31  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:35:31  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 14:35:31  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:35:31  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:35:31  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:35:31  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:35:31  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:35:31  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:35:31  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:35:31  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:35:31  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:35:31  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:35:31  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:35:31  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:35:31  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:35:31  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:35:31  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:35:31  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:35:31  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:35:31  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:35:31  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:35:31  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:35:31  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:35:31  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:35:31  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:36:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:36:38  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:36:38  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:36:38  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 14:36:38  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:36:38  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:36:38  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:36:38  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:36:38  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:36:38  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:36:38  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:36:38  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:36:38  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:36:38  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:36:38  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:36:39  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:36:39  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:36:39  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:36:39  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:36:39  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:36:39  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:36:39  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:36:39  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:36:39  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:36:39  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:36:39  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:36:39  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:37:56  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:37:56  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:37:56  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:37:56  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 14:37:56  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:37:56  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:37:56  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:37:56  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:37:56  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:37:56  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:37:56  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:37:56  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:37:56  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:37:56  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:37:56  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:37:56  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:37:56  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:37:56  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:37:56  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:37:56  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:37:56  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:37:56  [ main:130 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:37:56  [ main:130 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:37:56  [ main:131 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:37:56  [ main:138 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:37:56  [ main:138 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:37:56  [ main:139 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:38:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:38:30  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:38:30  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:38:30  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 14:38:30  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:38:30  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:38:30  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:38:30  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:38:30  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:38:30  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:38:30  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:38:30  [ main:99 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:38:30  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:38:30  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:38:30  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:38:30  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:38:30  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:38:30  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:38:30  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:38:30  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:38:30  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:38:30  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:38:30  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:38:30  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:38:30  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:38:30  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:38:30  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:42:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:42:21  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:42:21  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:42:21  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-07-10 14:42:21  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:42:21  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:42:21  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:42:21  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:42:21  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:42:21  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:42:21  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:42:21  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:42:21  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:42:21  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:42:21  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:42:21  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:42:21  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:42:21  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:42:21  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:42:21  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:42:21  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:42:21  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:42:21  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:42:21  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:42:21  [ main:80 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:42:21  [ main:81 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:42:21  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:42:22  [ main:1714 ] - [ INFO ]  user number : 10616  , send message count : 164248
2017-07-10 14:42:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:42:27  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:42:27  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:42:27  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 14:42:27  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:42:27  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:42:27  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:42:27  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:42:27  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:42:27  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:42:27  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:42:27  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:42:27  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:42:27  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:42:27  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:42:27  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:42:27  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:42:27  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:42:27  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:42:27  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:42:27  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:42:27  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:42:27  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:42:27  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime071002 was supplied but isn't a known config.
2017-07-10 14:42:27  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:42:27  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:42:27  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:58:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:58:12  [ main:77 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 14:58:12  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 14:58:12  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-07-10 14:58:12  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 14:58:12  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 14:58:12  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 14:58:12  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 14:58:12  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 14:58:12  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 14:58:12  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 14:58:12  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 14:58:12  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 14:58:12  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 14:58:12  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 14:58:12  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 14:58:12  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 14:58:12  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 14:58:12  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 14:58:12  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 14:58:12  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 14:58:12  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 14:58:12  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 14:58:12  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime071003 was supplied but isn't a known config.
2017-07-10 14:58:12  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 14:58:12  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 14:58:12  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14474 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14474 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14522 ] - [ DEBUG ]  Added sensor with name node--1.bytes-sent
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14523 ] - [ DEBUG ]  Added sensor with name node--1.bytes-received
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14523 ] - [ DEBUG ]  Added sensor with name node--1.latency
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14523 ] - [ DEBUG ]  Completed connection to node -1
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14541 ] - [ DEBUG ]  Sending metadata request {topics=[testRealTime071003]} to node -1
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14553 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.221:9092 (id: 4 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [Partition(topic = testRealTime071003, partition = 0, leader = 4, replicas = [4,], isr = [4,]])
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14563 ] - [ DEBUG ]  Initiating connection to node 4 at 192.168.0.221:9092.
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14566 ] - [ DEBUG ]  Added sensor with name node-4.bytes-sent
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14567 ] - [ DEBUG ]  Added sensor with name node-4.bytes-received
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14567 ] - [ DEBUG ]  Added sensor with name node-4.latency
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14567 ] - [ DEBUG ]  Completed connection to node 4
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14568 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.records-per-batch
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14568 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.bytes
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14568 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.compression-rate
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14568 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-retries
2017-07-10 14:58:26  [ kafka-producer-network-thread | DemoProducer1:14569 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-errors
2017-07-10 15:00:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 15:00:20  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 15:00:20  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 15:00:20  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 15:00:20  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 15:00:20  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 15:00:20  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 15:00:20  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 15:00:20  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 15:00:20  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 15:00:20  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 15:00:20  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 15:00:20  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 15:00:20  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 15:00:20  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 15:00:20  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 15:00:20  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 15:00:20  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 15:00:20  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 15:00:20  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 15:00:20  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 15:00:20  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 15:00:20  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime071003 was supplied but isn't a known config.
2017-07-10 15:00:20  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 15:00:20  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 15:00:20  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:196 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:196 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:258 ] - [ DEBUG ]  Added sensor with name node--1.bytes-sent
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:266 ] - [ DEBUG ]  Added sensor with name node--1.bytes-received
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:266 ] - [ DEBUG ]  Added sensor with name node--1.latency
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:266 ] - [ DEBUG ]  Completed connection to node -1
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:286 ] - [ DEBUG ]  Sending metadata request {topics=[testRealTime071003]} to node -1
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:297 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [Partition(topic = testRealTime071003, partition = 0, leader = 4, replicas = [4,], isr = [4,]])
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:310 ] - [ DEBUG ]  Initiating connection to node 4 at 192.168.0.221:9092.
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:311 ] - [ DEBUG ]  Added sensor with name node-4.bytes-sent
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:312 ] - [ DEBUG ]  Added sensor with name node-4.bytes-received
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:312 ] - [ DEBUG ]  Added sensor with name node-4.latency
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:314 ] - [ DEBUG ]  Completed connection to node 4
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:315 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.records-per-batch
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:315 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.bytes
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:315 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.compression-rate
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:315 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-retries
2017-07-10 15:00:20  [ kafka-producer-network-thread | DemoProducer1:316 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-errors
2017-07-10 15:00:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 15:00:28  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-07-10 15:00:28  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-07-10 15:00:28  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-07-10 15:00:28  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-07-10 15:00:28  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-07-10 15:00:28  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-07-10 15:00:28  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-07-10 15:00:28  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-07-10 15:00:28  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-07-10 15:00:28  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-07-10 15:00:28  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-07-10 15:00:28  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-07-10 15:00:28  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-07-10 15:00:28  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-07-10 15:00:28  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-07-10 15:00:28  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-07-10 15:00:28  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-07-10 15:00:28  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-07-10 15:00:28  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-07-10 15:00:28  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-07-10 15:00:28  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 10 was supplied but isn't a known config.
2017-07-10 15:00:28  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime071003 was supplied but isn't a known config.
2017-07-10 15:00:28  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-07-10 15:00:28  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-07-10 15:00:28  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:233 ] - [ DEBUG ]  Initialize connection to node -3 for sending metadata request
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:234 ] - [ DEBUG ]  Initiating connection to node -3 at 192.168.0.222:9092.
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:318 ] - [ DEBUG ]  Added sensor with name node--3.bytes-sent
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:318 ] - [ DEBUG ]  Added sensor with name node--3.bytes-received
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:319 ] - [ DEBUG ]  Added sensor with name node--3.latency
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:319 ] - [ DEBUG ]  Completed connection to node -3
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:338 ] - [ DEBUG ]  Sending metadata request {topics=[testRealTime071003]} to node -3
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:357 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null), 192.168.0.222:9092 (id: 2 rack: null)], partitions = [Partition(topic = testRealTime071003, partition = 0, leader = 4, replicas = [4,], isr = [4,]])
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:370 ] - [ DEBUG ]  Initiating connection to node 4 at 192.168.0.221:9092.
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:371 ] - [ DEBUG ]  Added sensor with name node-4.bytes-sent
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:372 ] - [ DEBUG ]  Added sensor with name node-4.bytes-received
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:373 ] - [ DEBUG ]  Added sensor with name node-4.latency
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:373 ] - [ DEBUG ]  Completed connection to node 4
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:373 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.records-per-batch
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:373 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.bytes
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:440 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.compression-rate
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:440 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-retries
2017-07-10 15:00:28  [ kafka-producer-network-thread | DemoProducer1:440 ] - [ DEBUG ]  Added sensor with name topic.testRealTime071003.record-errors
