2017-06-27 09:06:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:06:26  [ main:149 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:06:26  [ main:153 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:06:26  [ main:155 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 09:06:26  [ main:163 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:06:26  [ main:164 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:06:26  [ main:164 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:06:26  [ main:164 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:06:26  [ main:165 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:06:26  [ main:166 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:06:26  [ main:166 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:06:26  [ main:169 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:06:26  [ main:170 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:06:26  [ main:170 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:06:26  [ main:171 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:06:26  [ main:171 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:06:26  [ main:172 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:06:26  [ main:173 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:06:26  [ main:173 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:06:26  [ main:173 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:06:26  [ kafka-producer-network-thread | DemoProducer1:175 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:06:26  [ main:175 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:06:26  [ main:176 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:06:26  [ main:176 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:06:26  [ main:178 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:06:26  [ main:178 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:06:26  [ main:179 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:25:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:25:31  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:25:31  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:25:31  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 09:25:31  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:25:31  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:25:31  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:25:31  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:25:31  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:25:31  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:25:31  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:25:31  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:25:31  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:25:31  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:25:31  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:25:31  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:25:31  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:25:31  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:25:31  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:25:31  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:25:31  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:25:31  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:25:31  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:25:31  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:25:31  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:25:31  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:25:31  [ main:98 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:28:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:28:07  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:28:07  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:28:07  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 09:28:07  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:28:07  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:28:07  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:28:07  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:28:07  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:28:07  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:28:07  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:28:07  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:28:07  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:28:07  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:28:07  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:28:07  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:28:07  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:28:07  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:28:07  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:28:07  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:28:07  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:28:07  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:28:07  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:28:07  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:28:07  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:28:07  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:28:07  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:28:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:28:15  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:28:15  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:28:15  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 09:28:15  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:28:15  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:28:15  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:28:15  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:28:15  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:28:15  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:28:15  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:28:15  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:28:15  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:28:15  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:28:15  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:28:15  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:28:15  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:28:15  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:28:15  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:28:15  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:28:15  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:28:15  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:28:15  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:28:15  [ kafka-producer-network-thread | DemoProducer1:131 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:28:15  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:28:15  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:28:15  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:30:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:30:07  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:30:07  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:30:07  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 09:30:07  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:30:07  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:30:07  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:30:07  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:30:07  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:30:07  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:30:07  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:30:07  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:30:07  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:30:07  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:30:07  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:30:07  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:30:07  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:30:07  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:30:07  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:30:07  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:30:07  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:30:07  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:30:07  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:30:07  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:30:07  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:30:07  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:30:07  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:30:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:30:55  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:30:55  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:30:55  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 09:30:55  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:30:55  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:30:55  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:30:55  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:30:55  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:30:55  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:30:55  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:30:55  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:30:55  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:30:55  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:30:55  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:30:55  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:30:55  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:30:55  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:30:55  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:30:55  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:30:55  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:30:55  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:30:55  [ main:97 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:30:55  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:30:55  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:30:55  [ main:100 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:30:55  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:31:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:31:27  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:31:27  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:31:27  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 09:31:27  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:31:27  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:31:27  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:31:27  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:31:27  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:31:27  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:31:27  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:31:27  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:31:27  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:31:27  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:31:27  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:31:27  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:31:27  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:31:27  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:31:27  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:31:27  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:31:27  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:31:27  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:31:27  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:31:27  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:31:27  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:31:27  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:31:27  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:32:25  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:32:25  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:32:25  [ main:86 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:32:25  [ main:90 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 09:32:25  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:32:25  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:32:25  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:32:25  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:32:25  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:32:25  [ main:102 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:32:25  [ main:102 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:32:25  [ main:106 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:32:25  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:32:25  [ main:107 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:32:25  [ main:107 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:32:25  [ main:107 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:32:25  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:32:25  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:32:25  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:32:25  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:32:25  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:32:25  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:32:25  [ main:127 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:32:25  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:32:25  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:32:25  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:32:25  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:33:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:33:02  [ main:89 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:33:02  [ main:93 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:33:02  [ main:97 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 09:33:02  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:33:02  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:33:02  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:33:02  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:33:02  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:33:02  [ main:108 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:33:02  [ main:109 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:33:02  [ main:112 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:33:02  [ main:113 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:33:02  [ main:113 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:33:02  [ main:114 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:33:02  [ main:114 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:33:02  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:33:02  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:33:02  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:33:02  [ main:116 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:33:02  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:33:02  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:33:02  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:33:02  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:33:02  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:33:02  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:33:02  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:38:45  [ kafka-producer-network-thread | DemoProducer1:342907 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-06-27 09:38:45  [ kafka-producer-network-thread | DemoProducer1:342908 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-06-27 09:39:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:39:50  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:39:50  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:39:50  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 09:39:50  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:39:50  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:39:50  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:39:50  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:39:50  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:39:50  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:39:50  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:39:50  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:39:50  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:39:50  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:39:50  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:39:50  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:39:50  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:39:50  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:39:50  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:39:50  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:39:50  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:39:50  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:39:50  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:39:50  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:39:50  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:39:50  [ main:87 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:39:50  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:40:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:40:24  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:40:24  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:40:24  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 09:40:24  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:40:24  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:40:24  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:40:24  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:40:24  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:40:24  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:40:24  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:40:24  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:40:24  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:40:24  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:40:24  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:40:24  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:40:24  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:40:24  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:40:24  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:40:24  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:40:24  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:40:24  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:40:24  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:40:24  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:40:24  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:40:24  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:40:24  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:41:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:41:50  [ main:86 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:41:50  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:41:50  [ main:95 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 09:41:50  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:41:50  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:41:50  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:41:50  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:41:50  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:41:50  [ main:106 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:41:50  [ main:107 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:41:50  [ main:111 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:41:50  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:41:50  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:41:50  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:41:50  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:41:50  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:41:50  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:41:50  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:41:50  [ main:114 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:41:50  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:41:50  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:41:50  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:41:50  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:41:50  [ main:128 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:41:50  [ main:128 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:41:50  [ main:129 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:43:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:43:09  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 09:43:09  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 09:43:09  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 09:43:09  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 09:43:09  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 09:43:09  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 09:43:09  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 09:43:09  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 09:43:09  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 09:43:09  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 09:43:09  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 09:43:09  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 09:43:09  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 09:43:09  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 09:43:09  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 09:43:09  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 09:43:09  [ main:114 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 09:43:09  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 09:43:09  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 09:43:09  [ kafka-producer-network-thread | DemoProducer1:128 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 09:43:09  [ main:128 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 09:43:09  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 09:43:09  [ main:129 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 09:43:09  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 09:43:09  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 09:43:09  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-27 09:52:24  [ kafka-producer-network-thread | DemoProducer1:555197 ] - [ DEBUG ]  Initialize connection to node -3 for sending metadata request
2017-06-27 09:52:24  [ kafka-producer-network-thread | DemoProducer1:555197 ] - [ DEBUG ]  Initiating connection to node -3 at 192.168.0.222:9092.
2017-06-27 10:14:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:14:52  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:14:52  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:14:52  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 10:14:52  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:14:52  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:14:52  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:14:52  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:14:52  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:14:52  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:14:52  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:14:52  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:14:52  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:14:52  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:14:52  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:14:52  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:14:52  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:14:52  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:14:52  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:14:52  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:14:52  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:14:52  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:14:52  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:14:52  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:14:52  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:14:52  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:14:52  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:15:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:15:02  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:15:02  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:15:02  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 10:15:02  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:15:02  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:15:02  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:15:02  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:15:02  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:15:02  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:15:02  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:15:02  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:15:02  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:15:02  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:15:02  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:15:02  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:15:02  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:15:02  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:15:02  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:15:02  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:15:02  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:15:02  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:15:02  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:15:02  [ kafka-producer-network-thread | DemoProducer1:117 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:15:02  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:15:02  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:15:02  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:17:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:17:46  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:17:46  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:17:46  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 10:17:46  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:17:46  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:17:46  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:17:46  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:17:46  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:17:46  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:17:46  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:17:46  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:17:46  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:17:46  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:17:46  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:17:46  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:17:46  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:17:46  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:17:46  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:17:46  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:17:46  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:17:46  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:17:46  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:17:46  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:17:46  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:17:46  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:17:46  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:22:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:22:44  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:22:44  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:22:44  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 10:22:44  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:22:44  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:22:44  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:22:44  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:22:44  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:22:44  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:22:44  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:22:44  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:22:44  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:22:44  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:22:44  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:22:44  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:22:44  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:22:44  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:22:44  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:22:44  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:22:44  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:22:44  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:22:44  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:22:44  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:22:44  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:22:44  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:22:44  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:24:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:24:17  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:24:17  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:24:17  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 10:24:17  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:24:17  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:24:17  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:24:17  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:24:17  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:24:17  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:24:17  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:24:17  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:24:17  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:24:17  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:24:17  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:24:17  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:24:17  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:24:17  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:24:17  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:24:17  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:24:17  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:24:17  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:24:17  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:24:17  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:24:17  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:24:17  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:24:17  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:25:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:25:00  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:25:00  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:25:00  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 10:25:00  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:25:00  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:25:00  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:25:00  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:25:00  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:25:00  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:25:00  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:25:00  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:25:00  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:25:00  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:25:00  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:25:00  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:25:00  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:25:00  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:25:00  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:25:00  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:25:00  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:25:00  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:25:00  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:25:00  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:25:00  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:25:00  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:25:00  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:25:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:25:04  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:25:04  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:25:04  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 10:25:04  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:25:04  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:25:04  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:25:04  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:25:04  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:25:04  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:25:04  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:25:04  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:25:04  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:25:04  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:25:04  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:25:04  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:25:04  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:25:04  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:25:04  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:25:04  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:25:04  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:25:04  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:25:04  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:25:04  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:25:04  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:25:04  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:25:04  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:28:51  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:28:51  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:28:51  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:28:51  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 10:28:51  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:28:51  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:28:51  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:28:51  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:28:51  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:28:51  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:28:51  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:28:51  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:28:51  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:28:51  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:28:51  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:28:51  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:28:51  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:28:51  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:28:51  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:28:51  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:28:51  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:28:51  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:28:51  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:28:51  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:28:51  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:28:51  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:28:51  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:34:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:34:45  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:34:45  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:34:45  [ main:55 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 10:34:45  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:34:45  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:34:45  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:34:45  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:34:45  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:34:45  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:34:45  [ main:65 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:34:45  [ main:68 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:34:45  [ main:69 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:34:45  [ main:69 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:34:45  [ main:69 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:34:45  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:34:45  [ main:71 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:34:45  [ main:71 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:34:45  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:34:45  [ main:72 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:34:45  [ main:74 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:34:45  [ kafka-producer-network-thread | DemoProducer1:75 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:34:45  [ main:75 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:34:45  [ main:75 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:34:45  [ main:78 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:34:45  [ main:78 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:34:45  [ main:79 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:35:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:35:06  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:35:06  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:35:06  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 10:35:06  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:35:06  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:35:06  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:35:06  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:35:06  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:35:06  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:35:06  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:35:06  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:35:06  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:35:06  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:35:06  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:35:06  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:35:06  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:35:06  [ kafka-producer-network-thread | DemoProducer1:75 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:35:06  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:35:06  [ main:76 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:35:06  [ main:76 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:35:06  [ main:78 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:35:06  [ main:79 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:35:06  [ main:79 ] - [ DEBUG ]  Kafka producer started
2017-06-27 10:35:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:35:29  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 10:35:29  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 10:35:29  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 10:35:29  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 10:35:29  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 10:35:29  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 10:35:29  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 10:35:29  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 10:35:29  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 10:35:29  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 10:35:29  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 10:35:29  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 10:35:29  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 10:35:29  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 10:35:29  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 10:35:29  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 10:35:29  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 10:35:29  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 10:35:29  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 10:35:29  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 10:35:29  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 10:35:29  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 10:35:29  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 10:35:29  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 10:35:29  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 10:35:29  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:03:01  [ kafka-producer-network-thread | DemoProducer1:1652952 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-27 11:03:02  [ kafka-producer-network-thread | DemoProducer1:1652953 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-27 11:14:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:14:55  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:14:55  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:14:55  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:14:55  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:14:55  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:14:55  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:14:55  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:14:55  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:14:55  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:14:55  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:14:55  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:14:55  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:14:55  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:14:55  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:14:55  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:14:55  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:14:55  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:14:55  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:14:55  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:14:55  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:14:55  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:14:55  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:14:55  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:14:55  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:14:55  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:14:55  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:15:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:09  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:15:09  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:15:09  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:15:09  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:15:09  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:15:09  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:15:09  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:15:09  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:15:09  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:15:09  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:15:09  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:15:09  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:15:09  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:15:09  [ main:93 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:15:09  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:15:09  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:15:09  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:15:09  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:15:09  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:15:09  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:09  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:15:09  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:15:09  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:15:09  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:15:09  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:15:09  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:15:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:16  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:15:16  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:15:16  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:15:16  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:15:16  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:15:16  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:15:16  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:15:16  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:15:16  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:15:16  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:15:16  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:15:16  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:15:16  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:15:16  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:15:16  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:15:16  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:15:16  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:15:16  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:15:16  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:15:16  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:15:16  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:16  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:15:16  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:15:16  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:15:16  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:15:16  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:15:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:26  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:15:26  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:15:26  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:15:26  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:15:26  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:15:26  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:15:26  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:15:26  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:15:26  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:15:26  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:15:26  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:15:26  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:15:26  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:15:26  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:15:26  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:15:26  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:15:26  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:15:26  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:15:26  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:15:26  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:15:26  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:15:26  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:15:26  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:15:26  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:15:26  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:15:26  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:16:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:16:00  [ main:101 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:16:00  [ main:106 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:16:00  [ main:110 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:16:00  [ main:120 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:16:00  [ main:121 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:16:00  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:16:00  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:16:00  [ main:123 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:16:00  [ main:123 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:16:00  [ main:123 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:16:00  [ main:128 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:16:00  [ main:128 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:16:00  [ main:129 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:16:00  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:16:00  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:16:00  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:16:00  [ main:131 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:16:00  [ main:132 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:16:00  [ main:132 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:16:00  [ main:134 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:16:00  [ main:135 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:16:00  [ main:135 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:16:00  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:16:00  [ main:138 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:16:00  [ kafka-producer-network-thread | DemoProducer1:138 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:16:00  [ main:139 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:20:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:20:03  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:20:03  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:20:03  [ main:89 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:20:03  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:20:03  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:20:03  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:20:03  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:20:03  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:20:03  [ main:105 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:20:03  [ main:106 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:20:03  [ main:111 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:20:03  [ main:112 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:20:03  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:20:03  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:20:03  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:20:03  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:20:03  [ main:115 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:20:03  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:20:03  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:20:03  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:20:03  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:20:03  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:20:03  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:20:03  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:20:03  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:20:03  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:21:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:21:04  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:21:04  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:21:04  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:21:04  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:21:04  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:21:04  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:21:04  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:21:04  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:21:04  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:21:04  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:21:04  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:21:04  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:21:04  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:21:04  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:21:04  [ main:103 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:21:04  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:21:04  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:21:04  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:21:04  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:21:04  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:21:04  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:21:04  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:21:04  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:21:04  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:21:04  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:21:04  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:26:05  [ kafka-producer-network-thread | DemoProducer1:300212 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-27 11:26:05  [ kafka-producer-network-thread | DemoProducer1:300217 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-27 11:27:09  [ kafka-producer-network-thread | DemoProducer1:364433 ] - [ DEBUG ]  Added sensor with name node--2.bytes-sent
2017-06-27 11:27:12  [ kafka-producer-network-thread | DemoProducer1:367931 ] - [ DEBUG ]  Added sensor with name node--2.bytes-received
2017-06-27 11:27:14  [ kafka-producer-network-thread | DemoProducer1:369655 ] - [ DEBUG ]  Added sensor with name node--2.latency
2017-06-27 11:27:16  [ kafka-producer-network-thread | DemoProducer1:371356 ] - [ DEBUG ]  Completed connection to node -2
2017-06-27 11:27:36  [ kafka-producer-network-thread | DemoProducer1:391793 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -2
2017-06-27 11:27:40  [ kafka-producer-network-thread | DemoProducer1:395749 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-27 11:29:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:44  [ main:77 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:29:44  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:29:44  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:29:44  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:29:44  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:29:44  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:29:44  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:29:44  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:29:44  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:29:44  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:29:44  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:29:44  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:29:44  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:29:44  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:29:44  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:29:44  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:29:44  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:29:44  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:29:44  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:29:44  [ kafka-producer-network-thread | DemoProducer1:124 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:29:44  [ main:125 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:44  [ main:126 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:29:44  [ main:126 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:29:44  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:29:44  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:29:44  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:29:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:50  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:29:50  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:29:50  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:29:50  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:29:50  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:29:50  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:29:50  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:29:50  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:29:50  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:29:50  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:29:50  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:29:50  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:29:50  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:29:50  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:29:50  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:29:50  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:29:50  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:29:50  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:29:50  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:29:50  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:29:50  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:50  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:29:50  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:29:50  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:29:50  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:29:50  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:29:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:53  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:29:53  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:29:53  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:29:53  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:29:53  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:29:53  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:29:53  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:29:53  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:29:53  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:29:53  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:29:53  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:29:53  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:29:53  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:29:53  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:29:53  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:29:53  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:29:53  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:29:53  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:29:53  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:29:53  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:53  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:29:53  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:29:53  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:29:53  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:29:53  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:29:53  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:29:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:57  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:29:57  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:29:57  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:29:57  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:29:57  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:29:57  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:29:57  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:29:57  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:29:57  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:29:57  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:29:57  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:29:57  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:29:57  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:29:57  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:29:57  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:29:57  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:29:57  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:29:57  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:29:57  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:29:57  [ kafka-producer-network-thread | DemoProducer1:121 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:29:57  [ main:121 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:29:57  [ main:122 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:29:57  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:29:57  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:29:57  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:29:57  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:02  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:02  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:02  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:30:02  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:02  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:02  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:02  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:02  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:02  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:02  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:02  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:02  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:02  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:02  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:02  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:02  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:02  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:02  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:02  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:02  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:02  [ main:106 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:02  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:02  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:02  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:02  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:02  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:20  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:20  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:20  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:30:20  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:20  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:20  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:20  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:20  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:20  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:20  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:20  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:20  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:20  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:20  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:20  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:20  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:20  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:20  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:20  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:20  [ main:94 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:20  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:20  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:20  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:20  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:20  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:20  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:24  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:24  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:24  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:30:24  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:24  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:24  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:24  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:24  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:24  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:24  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:24  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:24  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:24  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:24  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:24  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:24  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:24  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:24  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:24  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:24  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:24  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:24  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:24  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:24  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:24  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:24  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:28  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:28  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:28  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:30:28  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:28  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:28  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:28  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:28  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:28  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:28  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:28  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:28  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:28  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:28  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:28  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:28  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:28  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:28  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:28  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:28  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:28  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:28  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:28  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:28  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:28  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:28  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:31  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:31  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:31  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:30:31  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:31  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:31  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:31  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:31  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:31  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:31  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:31  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:31  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:31  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:31  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:31  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:31  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:31  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:31  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:31  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:31  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:31  [ main:82 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:31  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:31  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:31  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:31  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:31  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:41  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:41  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:41  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:30:41  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:41  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:41  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:41  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:41  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:41  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:41  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:41  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:41  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:41  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:41  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:41  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:41  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:41  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:41  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:41  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:41  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:41  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:41  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:41  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:41  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:41  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:41  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:47  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:47  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:47  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:30:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:47  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:47  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:47  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:47  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:47  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:47  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:47  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:47  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:47  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:47  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:47  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:47  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:47  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:47  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:47  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:47  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:47  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:47  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:47  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:30:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:59  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:30:59  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:30:59  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:30:59  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:30:59  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:30:59  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:30:59  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:30:59  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:30:59  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:30:59  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:30:59  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:30:59  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:30:59  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:30:59  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:30:59  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:30:59  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:30:59  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:30:59  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:30:59  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:30:59  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:30:59  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:30:59  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:30:59  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:30:59  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:30:59  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:30:59  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:32:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:29  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:32:29  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:32:29  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:32:29  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:32:29  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:32:29  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:32:29  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:32:29  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:32:29  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:32:29  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:32:29  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:32:29  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:32:29  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:32:29  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:32:29  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:32:29  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:32:29  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:32:29  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:32:29  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:32:29  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:32:29  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:29  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:32:29  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:32:29  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:32:29  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:32:29  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:32:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:37  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:32:37  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:32:37  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:32:37  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:32:37  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:32:37  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:32:37  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:32:37  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:32:37  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:32:37  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:32:37  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:32:37  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:32:37  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:32:37  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:32:37  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:32:37  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:32:37  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:32:37  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:32:37  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:32:37  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:32:37  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:37  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:32:37  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:32:37  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:32:37  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:32:37  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:32:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:47  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:32:47  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:32:47  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:32:47  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:32:47  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:32:47  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:32:47  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:32:47  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:32:47  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:32:47  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:32:47  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:32:47  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:32:47  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:32:47  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:32:47  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:32:47  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:32:47  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:32:47  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:32:47  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:32:47  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:32:47  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:47  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:32:47  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:32:47  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:32:47  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:32:47  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:32:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:58  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:32:58  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:32:58  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:32:58  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:32:58  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:32:58  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:32:58  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:32:58  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:32:58  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:32:58  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:32:58  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:32:58  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:32:58  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:32:58  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:32:58  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:32:58  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:32:58  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:32:58  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:32:58  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:32:58  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:32:58  [ main:94 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:32:58  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:32:58  [ main:95 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:32:58  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:32:58  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:32:58  [ main:98 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:04  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:04  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:04  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:33:04  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:04  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:04  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:04  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:04  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:04  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:04  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:04  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:04  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:04  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:04  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:04  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:04  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:04  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:04  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:04  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:04  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:04  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:04  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:04  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:04  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:04  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:04  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:07  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:07  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:07  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:33:07  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:07  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:07  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:07  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:07  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:07  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:07  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:07  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:07  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:07  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:07  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:07  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:07  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:07  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:07  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:07  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:07  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:07  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:07  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:07  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:07  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:07  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:07  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:25  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:25  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:25  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:33:25  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:25  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:25  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:25  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:25  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:25  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:25  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:25  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:25  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:25  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:25  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:25  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:25  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:25  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:25  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:25  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:25  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:25  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:25  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:25  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:25  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:25  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:25  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:29  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:29  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:29  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:33:29  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:29  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:29  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:29  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:29  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:29  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:29  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:29  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:29  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:29  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:29  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:29  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:29  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:29  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:29  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:29  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:29  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:29  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:29  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:29  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:29  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:29  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:29  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:33  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:33  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:33  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:33:33  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:33  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:33  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:33  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:33  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:33  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:33  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:33  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:33  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:33  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:33  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:33  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:33  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:33  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:33  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:33  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:33  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:33  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:33  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:33  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:33  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:33  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:33  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:35  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:35  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:35  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:33:35  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:35  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:35  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:35  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:35  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:35  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:35  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:35  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:35  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:35  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:35  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:35  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:35  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:35  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:35  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:35  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:35  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:35  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:35  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:35  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:35  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:35  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:35  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:37  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:37  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:37  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:33:37  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:37  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:37  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:37  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:37  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:37  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:37  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:37  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:37  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:37  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:37  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:37  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:37  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:37  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:37  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:37  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:37  [ main:122 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:37  [ main:122 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:37  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:37  [ kafka-producer-network-thread | DemoProducer1:124 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:37  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:37  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:37  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:33:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:47  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:33:47  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:33:47  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:33:47  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:33:47  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:33:47  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:33:47  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:33:47  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:33:47  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:33:47  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:33:47  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:33:47  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:33:47  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:33:47  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:33:47  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:33:47  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:33:47  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:33:47  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:33:47  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:33:47  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:33:47  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:33:47  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:33:47  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:33:47  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:33:47  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:33:47  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:43:52  [ kafka-producer-network-thread | DemoProducer1:605061 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-27 11:43:52  [ kafka-producer-network-thread | DemoProducer1:605061 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-27 11:44:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:02  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:02  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:02  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:44:02  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:02  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:02  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:02  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:02  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:02  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:02  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:02  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:02  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:02  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:02  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:02  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:02  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:02  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:02  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:02  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:02  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:02  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:02  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:02  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:02  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:02  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:02  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:07  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:07  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:07  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:44:07  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:07  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:07  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:07  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:07  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:07  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:07  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:07  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:07  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:07  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:07  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:07  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:07  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:07  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:07  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:07  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:07  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:07  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:07  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:07  [ kafka-producer-network-thread | DemoProducer1:93 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:07  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:07  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:07  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:09  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:09  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:09  [ main:89 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:44:09  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:09  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:09  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:09  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:09  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:09  [ main:108 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:09  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:09  [ main:112 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:09  [ main:112 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:09  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:09  [ main:113 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:09  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:09  [ main:115 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:09  [ main:115 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:09  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:09  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:09  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:09  [ main:121 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:09  [ main:121 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:09  [ main:121 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:09  [ main:124 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:09  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:09  [ main:125 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:18  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:18  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:18  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:44:18  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:18  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:18  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:18  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:18  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:18  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:18  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:18  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:18  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:18  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:18  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:18  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:18  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:18  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:18  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:18  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:18  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:18  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:18  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:18  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:18  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:18  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:18  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:24  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:24  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:24  [ main:55 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:44:24  [ main:62 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:24  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:24  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:24  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:24  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:24  [ main:64 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:24  [ main:65 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:24  [ main:68 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:24  [ main:69 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:24  [ main:69 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:24  [ main:69 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:24  [ main:69 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:24  [ main:71 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:24  [ main:72 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:24  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:24  [ main:72 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:24  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:24  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:24  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:24  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:24  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:24  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:24  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:28  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:28  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:28  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:44:28  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:28  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:28  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:28  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:28  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:28  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:28  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:28  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:28  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:28  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:28  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:28  [ main:71 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:28  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:28  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:28  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:28  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:28  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:28  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:28  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:28  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:28  [ main:81 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:28  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:28  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:32  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:32  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:32  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:44:32  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:32  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:32  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:32  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:32  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:32  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:32  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:32  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:32  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:32  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:32  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:32  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:32  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:32  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:32  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:32  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:32  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:32  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:32  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:32  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:32  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:32  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:32  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:44:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:37  [ main:99 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:44:37  [ main:105 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:44:37  [ main:110 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:44:37  [ main:119 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:44:37  [ main:120 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:44:37  [ main:120 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:44:37  [ main:120 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:44:37  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:44:37  [ main:122 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:44:37  [ main:123 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:44:37  [ main:128 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:44:37  [ main:128 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:44:37  [ main:129 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:44:37  [ main:129 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:44:37  [ main:133 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:44:37  [ main:135 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:44:37  [ main:135 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:44:37  [ main:135 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:44:37  [ main:135 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:44:37  [ main:138 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:44:37  [ main:139 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:44:37  [ main:139 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:44:37  [ kafka-producer-network-thread | DemoProducer1:140 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:44:37  [ main:141 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:44:37  [ main:141 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:44:37  [ main:142 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:45:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:45:41  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:45:41  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:45:41  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:45:41  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:45:41  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:45:41  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:45:41  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:45:41  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:45:41  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:45:41  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:45:41  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:45:41  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:45:41  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:45:41  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:45:41  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:45:41  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:45:41  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:45:41  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:45:41  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:45:41  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:45:41  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:45:41  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:45:41  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:45:41  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:45:41  [ main:120 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:45:42  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:46:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:46:11  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:46:11  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:46:11  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:46:11  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:46:11  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:46:11  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:46:11  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:46:11  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:46:11  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:46:11  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:46:11  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:46:11  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:46:11  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:46:11  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:46:11  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:46:11  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:46:11  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:46:11  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:46:11  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:46:11  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:46:11  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:46:11  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:46:11  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:46:11  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:46:11  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:46:11  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:46:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:46:57  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:46:57  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:46:57  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:46:57  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:46:57  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:46:57  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:46:57  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:46:57  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:46:57  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:46:57  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:46:57  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:46:57  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:46:57  [ main:87 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:46:57  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:46:57  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:46:57  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:46:57  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:46:57  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:46:57  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:46:57  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:46:57  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:46:57  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:46:57  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:46:57  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:46:57  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:46:57  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:47:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:47:40  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:47:40  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:47:40  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:47:40  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:47:40  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:47:40  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:47:40  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:47:40  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:47:40  [ main:87 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:47:40  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:47:40  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:47:40  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:47:40  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:47:40  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:47:40  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:47:40  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:47:40  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:47:40  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:47:40  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:47:40  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:47:40  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:47:40  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:47:40  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:47:41  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:47:41  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:47:41  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:48:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:48:41  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:48:41  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:48:41  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:48:41  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:48:41  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:48:41  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:48:41  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:48:41  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:48:41  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:48:41  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:48:41  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:48:41  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:48:41  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:48:41  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:48:41  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:48:41  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:48:41  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:48:41  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:48:41  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:48:41  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:48:41  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:48:41  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:48:41  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:48:41  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:48:41  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:48:41  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:48:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:48:44  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:48:44  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:48:44  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:48:44  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:48:44  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:48:44  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:48:44  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:48:44  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:48:44  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:48:44  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:48:44  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:48:44  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:48:44  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:48:44  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:48:44  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:48:44  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:48:44  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:48:44  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:48:44  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:48:44  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:48:44  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:48:44  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:48:44  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:48:44  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:48:44  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:48:44  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:50:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:50:23  [ main:108 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:50:23  [ main:113 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:50:23  [ main:117 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:50:23  [ main:127 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:50:23  [ main:127 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:50:23  [ main:128 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:50:23  [ main:128 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:50:23  [ main:129 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:50:23  [ main:129 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:50:23  [ main:130 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:50:23  [ main:134 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:50:23  [ main:134 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:50:23  [ main:134 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:50:23  [ main:135 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:50:23  [ main:135 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:50:23  [ main:137 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:50:23  [ main:137 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:50:23  [ main:138 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:50:23  [ main:138 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:50:23  [ kafka-producer-network-thread | DemoProducer1:158 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:50:23  [ main:158 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:50:23  [ main:159 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:50:23  [ main:160 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:50:23  [ main:162 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:50:23  [ main:162 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:50:23  [ main:163 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:50:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:50:36  [ main:83 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:50:36  [ main:91 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:50:36  [ main:95 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:50:36  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:50:36  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:50:36  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:50:36  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:50:36  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:50:36  [ main:111 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:50:36  [ main:113 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:50:36  [ main:117 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:50:36  [ main:118 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:50:36  [ main:119 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:50:36  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:50:36  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:50:36  [ main:133 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:50:36  [ main:134 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:50:36  [ main:134 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:50:36  [ main:135 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:50:36  [ main:137 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:50:36  [ main:138 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:50:36  [ main:138 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:50:36  [ main:150 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:50:36  [ main:150 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:50:36  [ main:151 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:50:36  [ kafka-producer-network-thread | DemoProducer1:157 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:51:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:20  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:51:20  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:51:20  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:51:20  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:51:20  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:51:20  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:51:20  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:51:20  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:51:20  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:51:20  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:51:20  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:51:20  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:51:20  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:51:20  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:51:20  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:51:20  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:51:20  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:51:20  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:51:20  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:51:20  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:20  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:51:20  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:51:20  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:51:20  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:51:20  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:51:20  [ main:100 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:51:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:47  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:51:47  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:51:47  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:51:47  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:51:47  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:51:47  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:51:47  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:51:47  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:51:47  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:51:47  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:51:47  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:51:47  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:51:47  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:51:47  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:51:47  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:51:47  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:51:47  [ main:72 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:51:47  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:51:47  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:51:47  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:51:47  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:47  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:51:47  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:51:47  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:51:47  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:51:47  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:51:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:59  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:51:59  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:51:59  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:51:59  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:51:59  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:51:59  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:51:59  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:51:59  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:51:59  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:51:59  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:51:59  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:51:59  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:51:59  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:51:59  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:51:59  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:51:59  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:51:59  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:51:59  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:51:59  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:51:59  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:51:59  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:51:59  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:51:59  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:51:59  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:51:59  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:51:59  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:07  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:07  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:07  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:07  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:07  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:07  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:07  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:07  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:07  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:07  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:07  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:07  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:07  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:07  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:07  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:07  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:07  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:07  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:07  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:07  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:07  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:07  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:07  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:07  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:07  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:07  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:14  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:14  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:14  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:14  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:52:14  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:14  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:14  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:14  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:14  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:14  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:14  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:14  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:14  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:14  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:14  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:14  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:14  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:14  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:14  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:14  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:14  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:14  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:14  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:14  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:14  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:14  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:14  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:19  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:19  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:19  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:52:19  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:19  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:19  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:19  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:19  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:19  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:19  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:19  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:19  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:19  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:19  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:19  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:19  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:19  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:19  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:19  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:19  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:19  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:19  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:19  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:19  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:19  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:19  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:23  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:23  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:23  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:52:23  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:23  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:23  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:23  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:23  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:23  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:23  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:23  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:23  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:23  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:23  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:23  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:23  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:23  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:23  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:23  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:23  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:23  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:23  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:23  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:23  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:23  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:23  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:25  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:25  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:25  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:52:25  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:25  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:25  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:25  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:25  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:25  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:25  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:25  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:25  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:25  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:25  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:25  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:25  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:25  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:25  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:25  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:25  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:25  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:25  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:25  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:25  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:25  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:25  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:28  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:28  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:28  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:28  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:28  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:28  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:28  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:28  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:28  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:28  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:28  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:28  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:28  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:28  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:28  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:28  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:28  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:28  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:28  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:28  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:28  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:28  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:28  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:28  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:28  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:28  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:31  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:31  [ main:53 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:31  [ main:55 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:31  [ main:62 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:31  [ main:62 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:31  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:31  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:31  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:31  [ main:64 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:31  [ main:65 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:31  [ main:68 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:31  [ main:69 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:31  [ main:69 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:31  [ main:69 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:31  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:31  [ main:71 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:31  [ main:71 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:31  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:31  [ main:72 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:31  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:31  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:31  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:31  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:31  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:31  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:31  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:41  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:41  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:41  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:52:41  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:41  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:41  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:41  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:41  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:41  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:41  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:41  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:41  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:41  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:41  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:41  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:41  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:41  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:41  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:41  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:41  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:41  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:41  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:41  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:41  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:41  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:41  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:47  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:47  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:47  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:52:47  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:47  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:47  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:47  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:47  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:47  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:47  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:47  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:47  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:47  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:47  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:47  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:47  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:47  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:47  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:47  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:47  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:47  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:47  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:47  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:47  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:47  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:47  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:52  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:52  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:52  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:52  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:52  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:52  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:52  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:52  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:52  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:52  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:52  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:52  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:52  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:52  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:52  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:52  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:52  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:52  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:52  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:52  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:52  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:52  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:52  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:52  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:52  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:52  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:54  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:54  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:54  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:54  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:54  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:54  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:54  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:54  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:54  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:54  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:54  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:54  [ main:91 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:54  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:54  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:54  [ main:92 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:54  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:54  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:54  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:54  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:54  [ main:106 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:54  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:54  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:54  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:54  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:54  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:54  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:57  [ main:80 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:57  [ main:86 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:57  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:57  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:57  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:57  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:57  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:57  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:57  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:57  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:57  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:57  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:57  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:57  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:57  [ main:103 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:57  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:57  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:57  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:57  [ main:106 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:57  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:57  [ main:112 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:57  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:57  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:57  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:57  [ main:126 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:57  [ main:127 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:52:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:58  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:52:58  [ main:87 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:52:58  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:52:58  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:52:58  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:52:58  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:52:58  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:52:59  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:52:59  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:52:59  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:52:59  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:52:59  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:52:59  [ main:108 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:52:59  [ main:108 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:52:59  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:52:59  [ main:117 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:52:59  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:52:59  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:52:59  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:52:59  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:52:59  [ main:122 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:52:59  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:52:59  [ main:123 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:52:59  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:52:59  [ main:126 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:52:59  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:00  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:00  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:00  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:53:00  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:00  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:00  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:00  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:00  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:00  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:00  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:00  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:00  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:00  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:00  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:00  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:00  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:00  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:00  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:00  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:00  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:00  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:00  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:00  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:01  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:01  [ main:125 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:01  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:03  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:03  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:03  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:53:03  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:03  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:03  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:03  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:03  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:03  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:03  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:03  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:03  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:03  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:03  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:03  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:03  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:03  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:03  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:03  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:03  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:03  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:03  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:03  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:03  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:03  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:03  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:11  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:11  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:11  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:53:11  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:11  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:11  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:11  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:11  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:11  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:11  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:11  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:11  [ main:91 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:11  [ main:92 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:11  [ main:92 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:11  [ main:92 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:11  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:11  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:11  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:11  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:11  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:11  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:11  [ main:97 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:11  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:11  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:11  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:11  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:13  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:13  [ main:83 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:13  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 11:53:13  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:13  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:13  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:13  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:13  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:13  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:13  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:13  [ main:109 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:13  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:13  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:13  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:13  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:13  [ main:122 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:13  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:13  [ main:124 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:13  [ main:124 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:13  [ main:128 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:13  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:13  [ main:129 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:13  [ main:138 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:13  [ main:138 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:13  [ main:139 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:13  [ kafka-producer-network-thread | DemoProducer1:152 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:18  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:19  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:19  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 11:53:19  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:19  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:19  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:19  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:19  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:19  [ main:87 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:19  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:19  [ main:91 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:19  [ main:92 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:19  [ main:92 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:19  [ main:93 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:19  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:19  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:19  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:19  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:19  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:19  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:19  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:19  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:19  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:19  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:19  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:19  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:53:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:48  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 11:53:48  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 11:53:48  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 11:53:48  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 11:53:48  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 11:53:48  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 11:53:48  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 11:53:48  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 11:53:48  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 11:53:48  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 11:53:48  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 11:53:48  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 11:53:48  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 11:53:48  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 11:53:48  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 11:53:48  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 11:53:48  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 11:53:48  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 11:53:48  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 11:53:48  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 11:53:48  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 11:53:48  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 11:53:48  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 11:53:48  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 11:53:48  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 11:53:48  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-27 11:58:49  [ kafka-producer-network-thread | DemoProducer1:300609 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-27 11:58:49  [ kafka-producer-network-thread | DemoProducer1:300610 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-27 12:01:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:01:44  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:01:44  [ main:81 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:01:44  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:01:44  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:01:44  [ main:97 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:01:44  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:01:44  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:01:44  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:01:44  [ main:101 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:01:44  [ main:102 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:01:44  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:01:44  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:01:44  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:01:44  [ main:110 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:01:44  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:01:44  [ main:120 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:01:44  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:01:44  [ main:121 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:01:44  [ main:121 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:01:44  [ kafka-producer-network-thread | DemoProducer1:139 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:01:44  [ main:139 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:01:44  [ main:140 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:01:44  [ main:140 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:01:44  [ main:143 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:01:44  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:01:44  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:01:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:01:55  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:01:55  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:01:55  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:01:55  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:01:55  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:01:55  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:01:55  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:01:55  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:01:55  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:01:55  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:01:55  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:01:55  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:01:55  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:01:55  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:01:55  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:01:55  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:01:55  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:01:55  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:01:55  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:01:55  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:01:55  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:01:55  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:01:55  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:01:55  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:01:55  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:01:55  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:05:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:05:08  [ main:95 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:05:08  [ main:101 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:05:08  [ main:105 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:05:08  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:05:08  [ main:116 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:05:08  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:05:08  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:05:08  [ main:118 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:05:08  [ main:118 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:05:08  [ main:119 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:05:08  [ main:123 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:05:08  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:05:08  [ main:124 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:05:08  [ main:124 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:05:08  [ main:125 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:05:08  [ main:127 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:05:08  [ main:127 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:05:08  [ main:127 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:05:08  [ main:128 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:05:08  [ main:135 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:05:08  [ main:135 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:05:08  [ main:136 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:05:08  [ kafka-producer-network-thread | DemoProducer1:136 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:05:08  [ main:142 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:05:08  [ main:142 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:05:08  [ main:143 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:06:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:06:15  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:06:15  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:06:15  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:06:15  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:06:15  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:06:15  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:06:15  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:06:15  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:06:15  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:06:15  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:06:15  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:06:15  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:06:15  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:06:15  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:06:15  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:06:15  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:06:15  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:06:15  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:06:15  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:06:15  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:06:15  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:06:15  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:06:15  [ main:97 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:06:15  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:06:15  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:06:15  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:06:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:06:44  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:06:44  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:06:44  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:06:44  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:06:44  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:06:44  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:06:44  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:06:44  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:06:44  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:06:44  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:06:44  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:06:44  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:06:44  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:06:44  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:06:44  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:06:44  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:06:44  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:06:44  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:06:44  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:06:44  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:06:44  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:06:44  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:06:44  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:06:44  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:06:44  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:06:44  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:41  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:41  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:41  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:07:41  [ main:97 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:41  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:41  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:41  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:41  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:41  [ main:100 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:41  [ main:101 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:41  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:41  [ main:105 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:41  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:41  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:41  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:41  [ main:108 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:41  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:41  [ main:108 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:41  [ main:109 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:41  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:41  [ main:114 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:41  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:41  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:41  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:41  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:41  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:43  [ main:84 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:43  [ main:91 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:43  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:07:43  [ main:103 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:43  [ main:103 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:43  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:43  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:43  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:43  [ main:105 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:43  [ main:106 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:43  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:43  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:43  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:43  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:43  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:43  [ main:120 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:43  [ main:120 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:43  [ main:120 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:43  [ main:121 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:43  [ kafka-producer-network-thread | DemoProducer1:122 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:43  [ main:123 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:43  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:43  [ main:124 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:43  [ main:139 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:43  [ main:139 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:43  [ main:143 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:51  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:51  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:51  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:51  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:07:51  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:51  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:51  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:51  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:51  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:51  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:51  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:51  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:51  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:51  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:51  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:51  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:51  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:51  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:51  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:51  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:51  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:51  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:51  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:51  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:51  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:51  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:51  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:53  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:53  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:53  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:07:53  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:53  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:53  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:53  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:53  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:53  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:53  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:53  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:53  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:53  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:53  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:53  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:53  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:53  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:53  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:53  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:53  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:53  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:53  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:53  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:53  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:53  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:53  [ main:90 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:55  [ main:80 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:55  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:55  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:07:55  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:55  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:55  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:55  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:55  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:55  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:55  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:55  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:55  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:55  [ main:106 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:55  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:55  [ main:107 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:55  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:55  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:55  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:55  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:55  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:55  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:55  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:55  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:55  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:55  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:55  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:57  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:57  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:57  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:07:57  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:57  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:57  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:57  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:57  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:57  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:57  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:57  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:57  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:57  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:57  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:57  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:57  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:57  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:57  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:57  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:57  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:57  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:57  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:57  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:57  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:57  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:57  [ main:90 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:07:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:59  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:07:59  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:07:59  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:07:59  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:07:59  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:07:59  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:07:59  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:07:59  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:07:59  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:07:59  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:07:59  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:07:59  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:07:59  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:07:59  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:07:59  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:07:59  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:07:59  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:07:59  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:07:59  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:07:59  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:07:59  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:07:59  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:07:59  [ main:138 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:08:01  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:01  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:08:01  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:08:01  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:08:01  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:08:01  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:08:01  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:08:01  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:08:01  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:08:01  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:08:01  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:08:01  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:08:01  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:08:01  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:08:01  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:08:01  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:08:01  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:08:01  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:08:01  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:08:01  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:08:01  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:01  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:08:01  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:08:01  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:08:01  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:08:01  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:08:01  [ main:126 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:08:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:27  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:08:27  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:08:27  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:08:27  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:08:27  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:08:27  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:08:27  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:08:27  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:08:27  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:08:27  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:08:27  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:08:27  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:08:27  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:08:27  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:08:27  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:08:27  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:08:27  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:08:27  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:08:27  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:08:27  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:27  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:08:27  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:08:27  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:08:27  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:08:27  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:08:27  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:08:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:40  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:08:40  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:08:40  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:08:40  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:08:40  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:08:40  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:08:40  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:08:40  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:08:40  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:08:40  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:08:40  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:08:40  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:08:40  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:08:40  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:08:40  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:08:40  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:08:40  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:08:40  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:08:40  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:08:40  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:08:40  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:40  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:08:40  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:08:40  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:08:40  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:08:40  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:08:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:54  [ main:109 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:08:54  [ main:114 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:08:54  [ main:119 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:08:54  [ main:129 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:08:54  [ main:129 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:08:54  [ main:130 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:08:54  [ main:131 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:08:54  [ main:133 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:08:54  [ main:134 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:08:54  [ main:135 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:08:54  [ main:140 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:08:54  [ main:141 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:08:54  [ main:142 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:08:54  [ main:143 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:08:54  [ main:143 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:08:54  [ main:152 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:08:54  [ main:153 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:08:54  [ main:153 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:08:54  [ main:153 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:08:54  [ kafka-producer-network-thread | DemoProducer1:162 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:08:54  [ main:162 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:08:54  [ main:163 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:08:54  [ main:163 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:08:54  [ main:169 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:08:54  [ main:169 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:08:54  [ main:170 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:09:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:09:30  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:09:30  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:09:30  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:09:30  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:09:30  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:09:30  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:09:30  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:09:30  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:09:30  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:09:30  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:09:30  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:09:30  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:09:30  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:09:30  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:09:30  [ main:103 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:09:30  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:09:30  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:09:30  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:09:30  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:09:30  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:09:30  [ kafka-producer-network-thread | DemoProducer1:128 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:09:30  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:09:30  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:09:30  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:09:30  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:09:30  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:10  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:10  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:10  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:10  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:13:10  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:10  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:10  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:10  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:10  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:10  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:10  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:10  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:10  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:10  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:10  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:10  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:10  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:10  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:10  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:10  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:10  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:10  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:10  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:10  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:10  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:10  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:10  [ main:90 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:20  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:20  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:20  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:13:20  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:20  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:20  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:20  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:20  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:20  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:20  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:20  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:20  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:20  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:20  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:20  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:20  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:20  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:20  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:20  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:20  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:20  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:20  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:20  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:20  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:20  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:20  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:23  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:23  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:23  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:13:23  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:23  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:23  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:23  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:23  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:23  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:23  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:23  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:23  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:23  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:23  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:23  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:23  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:23  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:23  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:23  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:23  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:23  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:23  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:23  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:23  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:23  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:23  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:25  [ main:119 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:25  [ main:129 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:25  [ main:131 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:25  [ main:141 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:25  [ main:141 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:25  [ main:141 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:25  [ main:142 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:25  [ main:143 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:25  [ main:144 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:25  [ main:144 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:25  [ main:148 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:25  [ main:148 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:25  [ main:149 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:25  [ main:149 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:25  [ main:149 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:25  [ main:152 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:25  [ main:152 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:25  [ main:153 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:25  [ main:153 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:25  [ main:162 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:25  [ main:162 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:25  [ main:163 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:25  [ main:166 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:25  [ main:166 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:25  [ main:167 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:25  [ kafka-producer-network-thread | DemoProducer1:172 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:27  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:27  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:27  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:13:27  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:27  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:27  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:27  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:27  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:27  [ main:110 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:27  [ main:111 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:27  [ main:121 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:27  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:27  [ main:122 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:27  [ main:122 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:27  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:27  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:27  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:27  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:27  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:27  [ main:137 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:27  [ main:138 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:27  [ main:138 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:27  [ kafka-producer-network-thread | DemoProducer1:141 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:27  [ main:154 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:27  [ main:154 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:27  [ main:155 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:29  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:29  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:29  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:29  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:29  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:29  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:29  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:29  [ main:110 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:29  [ main:110 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:29  [ main:111 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:29  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:29  [ main:115 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:29  [ main:115 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:29  [ main:115 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:29  [ main:116 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:29  [ main:119 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:29  [ main:119 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:29  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:29  [ main:120 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:29  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:29  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:29  [ main:133 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:29  [ kafka-producer-network-thread | DemoProducer1:130 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:29  [ main:151 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:29  [ main:151 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:29  [ main:161 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:31  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:31  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:31  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:31  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:31  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:31  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:31  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:31  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:31  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:31  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:31  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:31  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:31  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:31  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:31  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:31  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:31  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:31  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:31  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:31  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:31  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:31  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:31  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:31  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:31  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:31  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:33  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:33  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:33  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:33  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:33  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:33  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:33  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:33  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:33  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:33  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:33  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:33  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:33  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:33  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:33  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:33  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:33  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:33  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:33  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:33  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:33  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:33  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:33  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:33  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:33  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:35  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:35  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:35  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:13:35  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:35  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:35  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:35  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:35  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:35  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:35  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:35  [ main:91 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:35  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:35  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:35  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:35  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:35  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:35  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:35  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:35  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:35  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:35  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:35  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:35  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:35  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:35  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:35  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:37  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:37  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:37  [ main:87 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:37  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:37  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:37  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:37  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:37  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:37  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:37  [ main:99 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:37  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:37  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:37  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:37  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:37  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:37  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:37  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:37  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:37  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:37  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:37  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:37  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:37  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:37  [ main:125 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:37  [ main:126 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:37  [ main:129 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:38  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:38  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:38  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:38  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:38  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:38  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:38  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:38  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:38  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:38  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:38  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:38  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:38  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:38  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:38  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:38  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:38  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:38  [ main:113 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:38  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:38  [ main:114 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:38  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:38  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:38  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:38  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:38  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:38  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:38  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:13:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:40  [ main:113 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:13:40  [ main:120 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:13:40  [ main:122 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:13:40  [ main:132 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:13:40  [ main:132 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:13:40  [ main:132 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:13:40  [ main:133 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:13:40  [ main:134 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:13:40  [ main:134 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:13:40  [ main:135 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:13:40  [ main:138 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:13:40  [ main:140 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:13:40  [ main:140 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:13:40  [ main:141 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:13:40  [ main:141 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:13:40  [ main:148 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:13:40  [ main:148 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:13:40  [ main:149 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:13:40  [ main:149 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:13:40  [ kafka-producer-network-thread | DemoProducer1:150 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:13:40  [ main:151 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:13:40  [ main:152 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:13:40  [ main:152 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:13:40  [ main:167 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:13:40  [ main:167 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:13:40  [ main:168 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:14:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:00  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:00  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:00  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:15:00  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:00  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:00  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:00  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:00  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:00  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:00  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:00  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:00  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:00  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:00  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:00  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:00  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:00  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:00  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:00  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:00  [ main:82 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:00  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:00  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:00  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:00  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:00  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:00  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:12  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:12  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:12  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:12  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:15:12  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:12  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:12  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:12  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:12  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:12  [ main:66 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:12  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:12  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:12  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:12  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:12  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:12  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:12  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:12  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:12  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:12  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:12  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:12  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:12  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:12  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:12  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:12  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:12  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:15  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:15  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:15  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:15:15  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:15  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:15  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:15  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:15  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:15  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:15  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:15  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:15  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:15  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:15  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:15  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:15  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:15  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:15  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:15  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:15  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:15  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:15  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:15  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:15  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:15  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:15  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:17  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:17  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:17  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:15:17  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:17  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:17  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:17  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:17  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:17  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:17  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:17  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:17  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:17  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:17  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:17  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:17  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:17  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:17  [ main:108 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:17  [ main:108 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:17  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:17  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:17  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:17  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:17  [ main:128 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:17  [ main:128 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:17  [ main:134 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:19  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:19  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:19  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:15:19  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:19  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:19  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:19  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:19  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:19  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:19  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:19  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:19  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:19  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:19  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:19  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:19  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:19  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:19  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:19  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:19  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:19  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:19  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:19  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:19  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:19  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:19  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:21  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:21  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:21  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:15:21  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:21  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:21  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:21  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:21  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:21  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:21  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:21  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:21  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:21  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:21  [ main:104 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:21  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:21  [ main:112 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:21  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:21  [ main:113 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:21  [ main:113 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:21  [ main:128 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:21  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:21  [ main:129 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:21  [ main:130 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:21  [ main:154 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:21  [ main:154 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:21  [ main:156 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:39  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:39  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:39  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 12:15:39  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:39  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:39  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:39  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:39  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:39  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:39  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:39  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:39  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:39  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:39  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:39  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:39  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:39  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:39  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:39  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:39  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:39  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:39  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:39  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:39  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:39  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:39  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:42  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:42  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:42  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:15:42  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:42  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:42  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:42  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:42  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:42  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:42  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:42  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:42  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:42  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:42  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:42  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:42  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:42  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:42  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:42  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:42  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:42  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:42  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:42  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:42  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:42  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:42  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:44  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:44  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:44  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 12:15:44  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:44  [ main:97 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:44  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:44  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:44  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:44  [ main:99 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:44  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:44  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:44  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:44  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:44  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:44  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:44  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:44  [ main:113 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:44  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:44  [ main:114 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:44  [ main:116 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:44  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:44  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:44  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:44  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:44  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:44  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-27 12:15:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:45  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 12:15:45  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 12:15:45  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 12:15:45  [ main:103 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 12:15:45  [ main:103 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 12:15:45  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 12:15:45  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 12:15:45  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 12:15:45  [ main:106 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 12:15:45  [ main:106 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 12:15:45  [ main:111 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 12:15:45  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 12:15:45  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 12:15:45  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 12:15:45  [ main:112 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 12:15:45  [ main:114 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 12:15:45  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 12:15:45  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 12:15:45  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 12:15:45  [ kafka-producer-network-thread | DemoProducer1:139 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 12:15:45  [ main:140 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 12:15:45  [ main:141 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 12:15:45  [ main:142 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 12:15:45  [ main:144 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 12:15:45  [ main:144 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 12:15:45  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:03:22  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:22  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:03:22  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:03:22  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:03:22  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:03:22  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:03:22  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:03:22  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:03:22  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:03:22  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:03:22  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:03:22  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:03:22  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:03:22  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:03:22  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:03:22  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:03:22  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:03:22  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:03:22  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:03:22  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:03:22  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:03:22  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:22  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:03:22  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:03:22  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:03:22  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:03:22  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:03:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:27  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:03:27  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:03:27  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:03:27  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:03:27  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:03:27  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:03:27  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:03:27  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:03:27  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:03:27  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:03:27  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:03:27  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:03:27  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:03:27  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:03:27  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:03:27  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:03:27  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:03:27  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:03:27  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:03:27  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:03:27  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:27  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:03:27  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:03:27  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:03:27  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:03:27  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:03:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:44  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:03:44  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:03:44  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:03:44  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:03:44  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:03:44  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:03:44  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:03:44  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:03:44  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:03:44  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:03:44  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:03:44  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:03:44  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:03:44  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:03:44  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:03:44  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:03:44  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:03:44  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:03:44  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:03:44  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:03:44  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:44  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:03:44  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:03:44  [ main:80 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:03:44  [ main:80 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:03:44  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:03:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:46  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:03:46  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:03:46  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:03:46  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:03:46  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:03:46  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:03:46  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:03:46  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:03:46  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:03:46  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:03:46  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:03:46  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:03:46  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:03:46  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:03:46  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:03:46  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:03:46  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:03:46  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:03:46  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:03:46  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:03:46  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:46  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:03:46  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:03:46  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:03:46  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:03:46  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:03:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:55  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:03:55  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:03:55  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:03:55  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:03:55  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:03:55  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:03:55  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:03:55  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:03:55  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:03:55  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:03:55  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:03:55  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:03:55  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:03:55  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:03:55  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:03:55  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:03:55  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:03:55  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:03:55  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:03:55  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:03:55  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:03:55  [ main:77 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:03:55  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:03:55  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:03:55  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:03:55  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:04:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:06  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:04:06  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:04:06  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:04:06  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:04:06  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:04:06  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:04:06  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:04:06  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:04:06  [ main:66 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:04:06  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:04:06  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:04:06  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:04:06  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:04:06  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:04:06  [ main:71 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:04:06  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:04:06  [ main:72 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:04:06  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:04:06  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:04:06  [ kafka-producer-network-thread | DemoProducer1:76 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:04:06  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:06  [ main:77 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:04:06  [ main:77 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:04:06  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:04:06  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:04:06  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:04:12  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:13  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:04:13  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:04:13  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:04:13  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:04:13  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:04:13  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:04:13  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:04:13  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:04:13  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:04:13  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:04:13  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:04:13  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:04:13  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:04:13  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:04:13  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:04:13  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:04:13  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:04:13  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:04:13  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:04:13  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:04:13  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:13  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:04:13  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:04:13  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:04:13  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:04:13  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:04:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:21  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:04:21  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:04:21  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:04:21  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:04:21  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:04:21  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:04:21  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:04:21  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:04:21  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:04:21  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:04:21  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:04:21  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:04:21  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:04:21  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:04:21  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:04:21  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:04:21  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:04:21  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:04:21  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:04:21  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:21  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:04:21  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:04:21  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:04:21  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:04:21  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:04:21  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:04:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:54  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:04:54  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:04:54  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:04:54  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:04:54  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:04:54  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:04:54  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:04:54  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:04:54  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:04:54  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:04:54  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:04:54  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:04:54  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:04:54  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:04:54  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:04:54  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:04:54  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:04:54  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:04:54  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:04:54  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:04:54  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:04:54  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:04:54  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:04:54  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:04:54  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:04:54  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:05:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:05:06  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:05:06  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:05:06  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:05:06  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:05:06  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:05:06  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:05:06  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:05:06  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:05:06  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:05:06  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:05:06  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:05:06  [ main:91 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:05:06  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:05:06  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:05:06  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:05:06  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:05:06  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:05:06  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:05:06  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:05:06  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:05:06  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:05:06  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:05:06  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:05:06  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:05:06  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:05:06  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:06:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:13  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:06:13  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:06:13  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:06:13  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:06:13  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:06:13  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:06:13  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:06:13  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:06:13  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:06:13  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:06:13  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:06:13  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:06:13  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:06:13  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:06:13  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:06:13  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:06:13  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:06:13  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:06:13  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:06:13  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:06:13  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:13  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:06:13  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:06:13  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:06:13  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:06:13  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:06:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:26  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:06:26  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:06:26  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:06:26  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:06:26  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:06:26  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:06:26  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:06:26  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:06:26  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:06:26  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:06:26  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:06:26  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:06:26  [ main:87 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:06:26  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:06:26  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:06:26  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:06:26  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:06:26  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:06:26  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:06:26  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:06:26  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:26  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:06:26  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:06:26  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:06:26  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:06:26  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:06:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:27  [ main:108 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:06:27  [ main:114 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:06:27  [ main:119 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:06:27  [ main:136 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:06:27  [ main:136 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:06:27  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:06:27  [ main:139 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:06:27  [ main:141 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:06:27  [ main:142 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:06:27  [ main:143 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:06:27  [ main:148 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:06:27  [ main:149 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:06:27  [ main:151 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:06:27  [ main:151 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:06:27  [ main:152 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:06:27  [ main:162 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:06:27  [ main:163 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:06:27  [ main:163 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:06:27  [ main:163 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:06:27  [ main:181 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:06:27  [ main:182 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:06:27  [ main:183 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:06:27  [ kafka-producer-network-thread | DemoProducer1:184 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:06:27  [ main:189 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:06:27  [ main:189 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:06:27  [ main:190 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:09:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:09:50  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:09:50  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:09:50  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:09:50  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:09:50  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:09:50  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:09:50  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:09:50  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:09:50  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:09:50  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:09:50  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:09:50  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:09:50  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:09:50  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:09:50  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:09:50  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:09:50  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:09:50  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:09:50  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:09:50  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:09:50  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:09:50  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:09:50  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:09:50  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:09:50  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:09:50  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:29  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:29  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:29  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:10:29  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:29  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:29  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:29  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:29  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:29  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:29  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:29  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:29  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:29  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:29  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:29  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:29  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:29  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:29  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:29  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:29  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:29  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:29  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:29  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:29  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:29  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:29  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:38  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:38  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:38  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:10:38  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:38  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:38  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:38  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:38  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:38  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:38  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:38  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:38  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:38  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:38  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:38  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:38  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:38  [ main:72 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:38  [ main:72 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:38  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:38  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:38  [ main:76 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:38  [ main:77 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:38  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:38  [ main:79 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:38  [ main:80 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:38  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:41  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:41  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:41  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:10:41  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:41  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:41  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:41  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:41  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:41  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:41  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:41  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:41  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:41  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:41  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:41  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:41  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:41  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:41  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:41  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:41  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:41  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:41  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:41  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:41  [ main:81 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:41  [ main:81 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:41  [ main:82 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:43  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:43  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:43  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:10:43  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:43  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:43  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:43  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:43  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:43  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:43  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:43  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:43  [ main:111 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:43  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:43  [ main:112 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:43  [ main:114 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:43  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:43  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:43  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:43  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:43  [ kafka-producer-network-thread | DemoProducer1:121 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:43  [ main:124 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:43  [ main:124 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:43  [ main:125 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:43  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:43  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:43  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:45  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:45  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:45  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:10:45  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:45  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:45  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:45  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:45  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:45  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:45  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:45  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:45  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:45  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:45  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:45  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:45  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:45  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:45  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:45  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:45  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:45  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:45  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:45  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:45  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:45  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:45  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:55  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:55  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:55  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:10:55  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:55  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:55  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:55  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:55  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:55  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:55  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:55  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:55  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:55  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:55  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:55  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:55  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:55  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:55  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:55  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:55  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:55  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:55  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:55  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:55  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:55  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:55  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:10:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:57  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:10:57  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:10:57  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:10:57  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:10:57  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:10:57  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:10:57  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:10:57  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:10:57  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:10:57  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:10:57  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:10:57  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:10:57  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:10:57  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:10:57  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:10:57  [ main:108 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:10:57  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:10:57  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:10:57  [ main:109 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:10:57  [ main:116 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:10:57  [ kafka-producer-network-thread | DemoProducer1:117 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:10:57  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:10:57  [ main:121 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:10:57  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:10:57  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:10:57  [ main:134 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:11:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:04  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:11:04  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:11:04  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:11:04  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:11:04  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:11:04  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:11:04  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:11:04  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:11:04  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:11:04  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:11:04  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:11:04  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:11:04  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:11:04  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:11:04  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:11:04  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:11:04  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:11:04  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:11:04  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:11:04  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:11:04  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:04  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:11:04  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:11:04  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:11:04  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:11:04  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:11:06  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:06  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:11:06  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:11:06  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:11:06  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:11:06  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:11:06  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:11:06  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:11:06  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:11:06  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:11:06  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:11:06  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:11:06  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:11:06  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:11:06  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:11:06  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:11:06  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:11:06  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:11:06  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:11:06  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:11:06  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:11:06  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:06  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:11:06  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:11:06  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:11:06  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:11:06  [ main:98 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:11:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:09  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:11:09  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:11:09  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:11:09  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:11:09  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:11:09  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:11:09  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:11:09  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:11:09  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:11:09  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:11:09  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:11:09  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:11:09  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:11:09  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:11:09  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:11:09  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:11:09  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:11:09  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:11:09  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:11:09  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:09  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:11:09  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:11:09  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:11:09  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:11:09  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:11:09  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:11:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:11  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:11:11  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:11:11  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:11:11  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:11:11  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:11:11  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:11:11  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:11:11  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:11:11  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:11:11  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:11:11  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:11:11  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:11:11  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:11:11  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:11:11  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:11:11  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:11:11  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:11:11  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:11:11  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:11:11  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:11:11  [ main:114 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:11  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:11:11  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:11:11  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:11:11  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:11:11  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:11:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:59  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:11:59  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:11:59  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:11:59  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:11:59  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:11:59  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:11:59  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:11:59  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:11:59  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:11:59  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:11:59  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:11:59  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:11:59  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:11:59  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:11:59  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:11:59  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:11:59  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:11:59  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:11:59  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:11:59  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:11:59  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:11:59  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:11:59  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:11:59  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:11:59  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:11:59  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:15:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:06  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:15:06  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:15:06  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:15:06  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:15:06  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:15:06  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:15:06  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:15:06  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:15:06  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:15:06  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:15:06  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:15:06  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:15:06  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:15:06  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:15:06  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:15:06  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:15:06  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:15:06  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:15:06  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:15:06  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:15:06  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:06  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:15:06  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:15:06  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:15:06  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:15:06  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:15:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:16  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:15:16  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:15:16  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:15:16  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:15:16  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:15:16  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:15:16  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:15:16  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:15:16  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:15:16  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:15:16  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:15:16  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:15:16  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:15:16  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:15:16  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:15:16  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:15:16  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:15:16  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:15:16  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:15:16  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:15:16  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:16  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:15:16  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:15:16  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:15:16  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:15:16  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:15:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:17  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:15:17  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:15:17  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:15:17  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:15:17  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:15:17  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:15:17  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:15:17  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:15:17  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:15:17  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:15:17  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:15:17  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:15:17  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:15:17  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:15:17  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:15:17  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:15:17  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:15:17  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:15:17  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:15:17  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:15:17  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:15:17  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:15:17  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:15:17  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:15:17  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:15:17  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:19:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:36  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:19:36  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:19:36  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:19:36  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:19:36  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:19:36  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:19:36  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:19:36  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:19:36  [ main:87 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:19:36  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:19:36  [ main:91 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:19:36  [ main:92 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:19:36  [ main:92 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:19:36  [ main:92 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:19:36  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:19:36  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:19:36  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:19:36  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:19:36  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:19:36  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:19:36  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:36  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:19:36  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:19:36  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:19:36  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:19:36  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:19:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:43  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:19:43  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:19:43  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:19:43  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:19:43  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:19:43  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:19:43  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:19:43  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:19:43  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:19:43  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:19:43  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:19:43  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:19:43  [ main:87 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:19:43  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:19:43  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:19:43  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:19:43  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:19:43  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:19:43  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:19:43  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:19:43  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:43  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:19:43  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:19:43  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:19:43  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:19:43  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:19:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:47  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:19:47  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:19:47  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:19:47  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:19:47  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:19:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:19:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:19:47  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:19:47  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:19:47  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:19:47  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:19:47  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:19:47  [ main:87 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:19:47  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:19:47  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:19:47  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:19:47  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:19:47  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:19:47  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:19:47  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:19:47  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:19:47  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:19:47  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:19:47  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:19:47  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:19:47  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:23:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:23:26  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:23:26  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:23:26  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:23:26  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:23:26  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:23:26  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:23:26  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:23:26  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:23:26  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:23:26  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:23:26  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:23:26  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:23:26  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:23:26  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:23:26  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:23:26  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:23:26  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:23:26  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:23:26  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:23:26  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:23:26  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:23:26  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:23:26  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:23:26  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:23:26  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:23:26  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:27:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:27:17  [ main:105 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:27:17  [ main:110 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:27:17  [ main:114 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:27:17  [ main:124 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:27:17  [ main:125 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:27:17  [ main:126 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:27:17  [ main:126 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:27:17  [ main:127 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:27:17  [ main:128 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:27:17  [ main:128 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:27:17  [ main:136 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:27:17  [ main:137 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:27:17  [ main:152 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:27:17  [ main:153 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:27:17  [ main:153 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:27:17  [ main:155 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:27:17  [ main:155 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:27:17  [ main:155 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:27:17  [ main:156 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:27:17  [ kafka-producer-network-thread | DemoProducer1:158 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:27:17  [ main:158 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:27:17  [ main:159 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:27:17  [ main:159 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:27:17  [ main:161 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:27:17  [ main:162 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:27:17  [ main:162 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:32:18  [ kafka-producer-network-thread | DemoProducer1:300843 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-06-27 14:32:18  [ kafka-producer-network-thread | DemoProducer1:300868 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-06-27 14:33:03  [ kafka-producer-network-thread | DemoProducer1:345535 ] - [ DEBUG ]  Added sensor with name node--1.bytes-sent
2017-06-27 14:33:03  [ kafka-producer-network-thread | DemoProducer1:346167 ] - [ DEBUG ]  Added sensor with name node--1.bytes-received
2017-06-27 14:33:03  [ kafka-producer-network-thread | DemoProducer1:346202 ] - [ DEBUG ]  Added sensor with name node--1.latency
2017-06-27 14:33:04  [ kafka-producer-network-thread | DemoProducer1:347332 ] - [ DEBUG ]  Completed connection to node -1
2017-06-27 14:33:11  [ kafka-producer-network-thread | DemoProducer1:354197 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -1
2017-06-27 14:33:11  [ kafka-producer-network-thread | DemoProducer1:354210 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.220:9092 (id: 3 rack: null), 192.168.0.222:9092 (id: 2 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-27 14:40:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:40:43  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:40:43  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:40:43  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:40:43  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:40:43  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:40:43  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:40:43  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:40:43  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:40:43  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:40:43  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:40:43  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:40:43  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:40:43  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:40:43  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:40:43  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:40:43  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:40:43  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:40:43  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:40:43  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:40:43  [ main:90 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:40:43  [ main:91 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:40:43  [ main:91 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:40:43  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:40:43  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:40:43  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:40:43  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:40:44  [ main:495 ] - [ INFO ]  user number : 1214  , send message count : 5838
2017-06-27 14:41:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:21  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:41:21  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:41:21  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:41:21  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:41:21  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:41:21  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:41:21  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:41:21  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:41:21  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:41:21  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:41:21  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:41:21  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:41:21  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:41:21  [ main:80 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:41:21  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:41:21  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:41:21  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:41:21  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:41:21  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:41:21  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:21  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:41:21  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:41:21  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:41:21  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:41:21  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:41:21  [ kafka-producer-network-thread | DemoProducer1:93 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:41:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:34  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:41:34  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:41:34  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:41:34  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:41:34  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:41:34  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:41:34  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:41:34  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:41:34  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:41:34  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:41:34  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:41:34  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:41:34  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:41:34  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:41:34  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:41:34  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:41:34  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:41:34  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:41:34  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:41:34  [ kafka-producer-network-thread | DemoProducer1:135 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:41:34  [ main:135 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:34  [ main:137 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:41:34  [ main:137 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:41:34  [ main:140 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:41:34  [ main:140 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:41:34  [ main:141 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:41:56  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:56  [ main:93 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:41:56  [ main:98 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:41:57  [ main:104 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:41:57  [ main:117 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:41:57  [ main:117 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:41:57  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:41:57  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:41:57  [ main:119 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:41:57  [ main:119 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:41:57  [ main:120 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:41:57  [ main:124 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:41:57  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:41:57  [ main:125 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:41:57  [ main:125 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:41:57  [ main:125 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:41:57  [ main:127 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:41:57  [ main:127 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:41:57  [ main:127 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:41:57  [ main:127 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:41:57  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:41:57  [ main:130 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:41:57  [ main:130 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:41:57  [ main:130 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:41:57  [ main:143 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:41:57  [ main:143 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:41:57  [ main:144 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:42:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:50  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:42:50  [ main:83 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:42:50  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:42:50  [ main:103 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:42:50  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:42:50  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:42:50  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:42:50  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:42:50  [ main:107 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:42:50  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:42:50  [ main:111 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:42:50  [ main:112 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:42:50  [ main:112 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:42:50  [ main:113 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:42:50  [ main:113 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:42:50  [ main:115 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:42:50  [ main:115 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:42:50  [ main:115 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:42:50  [ main:115 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:42:50  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:50  [ main:118 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:42:50  [ main:118 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:42:50  [ kafka-producer-network-thread | DemoProducer1:126 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:42:50  [ main:135 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:42:50  [ main:135 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:42:50  [ main:136 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:42:55  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:55  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:42:55  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:42:55  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:42:55  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:42:55  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:42:55  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:42:55  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:42:55  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:42:55  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:42:55  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:42:55  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:42:55  [ main:110 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:42:55  [ main:111 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:42:55  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:42:55  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:42:55  [ main:113 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:42:55  [ main:113 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:42:55  [ main:113 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:42:55  [ main:113 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:42:55  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:42:55  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:55  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:42:55  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:42:55  [ main:129 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:42:55  [ main:129 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:42:55  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:42:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:57  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:42:57  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:42:57  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:42:57  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:42:57  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:42:57  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:42:57  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:42:57  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:42:57  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:42:57  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:42:57  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:42:57  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:42:57  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:42:57  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:42:57  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:42:57  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:42:57  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:42:57  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:42:57  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:42:57  [ kafka-producer-network-thread | DemoProducer1:110 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:42:57  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:57  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:42:57  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:42:57  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:42:57  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:42:57  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:42:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:59  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:42:59  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:42:59  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:42:59  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:42:59  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:42:59  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:42:59  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:42:59  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:42:59  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:42:59  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:42:59  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:42:59  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:42:59  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:42:59  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:42:59  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:42:59  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:42:59  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:42:59  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:42:59  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:42:59  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:42:59  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:42:59  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:42:59  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:42:59  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:42:59  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:42:59  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:43:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:00  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:43:00  [ main:86 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:43:00  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:43:00  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:43:00  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:43:00  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:43:00  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:43:00  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:43:00  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:43:00  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:43:00  [ main:122 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:43:00  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:43:00  [ main:122 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:43:00  [ main:123 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:43:00  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:43:00  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:43:00  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:43:00  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:43:00  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:43:00  [ main:129 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:00  [ main:130 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:43:00  [ main:130 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:43:00  [ kafka-producer-network-thread | DemoProducer1:131 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:43:00  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:43:00  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:43:00  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:43:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:02  [ main:96 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:43:02  [ main:102 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:43:02  [ main:104 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:43:02  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:43:02  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:43:02  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:43:02  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:43:02  [ main:118 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:43:02  [ main:119 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:43:02  [ main:120 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:43:02  [ main:131 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:43:02  [ main:132 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:43:02  [ main:132 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:43:02  [ main:133 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:43:02  [ main:133 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:43:02  [ main:142 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:43:02  [ main:144 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:43:02  [ main:144 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:43:02  [ main:144 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:43:02  [ main:155 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:02  [ main:156 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:43:02  [ main:156 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:43:02  [ kafka-producer-network-thread | DemoProducer1:160 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:43:02  [ main:175 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:43:02  [ main:175 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:43:02  [ main:175 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:43:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:03  [ main:97 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:43:03  [ main:105 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:43:03  [ main:107 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:43:03  [ main:118 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:43:03  [ main:119 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:43:03  [ main:119 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:43:03  [ main:120 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:43:03  [ main:122 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:43:03  [ main:122 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:43:03  [ main:124 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:43:03  [ main:140 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:43:03  [ main:141 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:43:03  [ main:142 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:43:03  [ main:143 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:43:03  [ main:146 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:43:03  [ main:159 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:43:03  [ main:160 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:43:03  [ main:160 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:43:03  [ main:161 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:43:03  [ kafka-producer-network-thread | DemoProducer1:168 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:43:03  [ main:169 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:03  [ main:169 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:43:03  [ main:169 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:43:03  [ main:175 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:43:03  [ main:176 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:43:03  [ main:176 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:43:14  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:14  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:43:14  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:43:14  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:43:14  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:43:14  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:43:14  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:43:14  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:43:14  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:43:14  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:43:14  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:43:14  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:43:14  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:43:14  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:43:14  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:43:14  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:43:14  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:43:14  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:43:14  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:43:14  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:43:14  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:43:14  [ main:106 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:14  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:43:14  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:43:14  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:43:14  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:43:14  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:43:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:21  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:43:21  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:43:21  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:43:21  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:43:21  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:43:21  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:43:21  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:43:21  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:43:21  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:43:21  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:43:21  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:43:21  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:43:21  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:43:21  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:43:21  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:43:21  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:43:21  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:43:21  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:43:21  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:43:21  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:43:21  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:43:21  [ main:105 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:43:21  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:43:21  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:43:21  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:43:21  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:50:42  [ kafka-producer-network-thread | DemoProducer1:440762 ] - [ DEBUG ]  Initialize connection to node -3 for sending metadata request
2017-06-27 14:50:42  [ kafka-producer-network-thread | DemoProducer1:440762 ] - [ DEBUG ]  Initiating connection to node -3 at 192.168.0.222:9092.
2017-06-27 14:50:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:50:43  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:50:43  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:50:43  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:50:43  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:50:43  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:50:43  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:50:43  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:50:43  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:50:43  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:50:43  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:50:43  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:50:43  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:50:43  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:50:43  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:50:43  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:50:43  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:50:43  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:50:43  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:50:43  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:50:43  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:50:43  [ main:123 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:50:43  [ main:124 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:50:43  [ main:124 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:50:43  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:50:43  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:50:43  [ main:128 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:52:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:52:42  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:52:42  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:52:42  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:52:42  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:52:42  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:52:42  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:52:42  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:52:42  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:52:42  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:52:42  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:52:42  [ main:113 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:52:42  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:52:42  [ main:115 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:52:42  [ main:115 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:52:42  [ main:115 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:52:42  [ main:117 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:52:42  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:52:42  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:52:42  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:52:42  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:52:42  [ main:120 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:52:42  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:52:42  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:52:42  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:52:42  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:52:42  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:54:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:54:26  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:54:26  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:54:26  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:54:26  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:54:26  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:54:26  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:54:26  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:54:26  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:54:26  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:54:26  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:54:26  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:54:26  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:54:26  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:54:26  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:54:26  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:54:26  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:54:26  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:54:26  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:54:26  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:54:26  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:54:26  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:54:26  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:54:26  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:54:26  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:54:26  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:54:26  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:56:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:56:21  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:56:21  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:56:21  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:56:21  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:56:21  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:56:21  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:56:21  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:56:21  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:56:21  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:56:21  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:56:21  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:56:21  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:56:21  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:56:21  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:56:21  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:56:21  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:56:21  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:56:21  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:56:21  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:56:21  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:56:21  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:56:21  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:56:21  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:56:21  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:56:21  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:56:21  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:57:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:57:07  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:57:07  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:57:07  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:57:07  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:57:07  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:57:07  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:57:07  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:57:07  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:57:07  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:57:07  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:57:07  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:57:07  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:57:07  [ main:87 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:57:07  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:57:07  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:57:07  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:57:07  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:57:07  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:57:07  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:57:07  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:57:07  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:57:07  [ main:95 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:57:07  [ main:95 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:57:07  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:57:07  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:57:07  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:08  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:08  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:08  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:59:08  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:08  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:08  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:08  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:08  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:08  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:08  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:08  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:08  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:08  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:08  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:08  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:08  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:08  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:08  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:08  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:08  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:08  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:08  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:08  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:08  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:08  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:08  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:26  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:26  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:26  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:59:26  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:26  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:26  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:26  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:26  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:26  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:26  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:26  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:26  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:26  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:26  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:26  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:26  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:26  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:26  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:26  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:26  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:26  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:26  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:26  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:26  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:26  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:26  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:30  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:30  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:30  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:59:30  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:30  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:30  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:30  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:30  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:30  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:30  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:30  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:30  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:30  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:30  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:30  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:30  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:30  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:30  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:30  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:30  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:30  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:30  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:30  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:30  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:30  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:30  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:35  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:35  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:35  [ main:55 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 14:59:35  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:35  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:35  [ main:63 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:35  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:35  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:35  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:35  [ main:65 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:35  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:35  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:35  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:35  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:35  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:35  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:35  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:35  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:35  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:35  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:35  [ main:89 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:35  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:35  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:35  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:35  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:35  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:43  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:43  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:43  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:59:43  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:43  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:43  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:43  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:43  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:43  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:43  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:43  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:43  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:43  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:43  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:43  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:43  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:43  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:43  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:43  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:43  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:43  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:43  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:43  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:43  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:43  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:43  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:50  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:50  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:50  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 14:59:50  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:50  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:50  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:50  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:50  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:50  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:50  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:50  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:50  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:50  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:50  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:50  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:50  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:50  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:50  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:50  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:50  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:50  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:50  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:50  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:50  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:50  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:50  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:56  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:56  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:56  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:59:56  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:56  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:56  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:56  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:56  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:56  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:56  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:56  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:56  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:56  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:56  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:56  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:56  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:56  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:56  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:56  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:56  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:56  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:56  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:56  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:56  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:56  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:56  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 14:59:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:58  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 14:59:58  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 14:59:58  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 14:59:58  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 14:59:58  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 14:59:58  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 14:59:58  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 14:59:58  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 14:59:58  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 14:59:58  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 14:59:58  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 14:59:58  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 14:59:58  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 14:59:58  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 14:59:58  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 14:59:58  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 14:59:58  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 14:59:58  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 14:59:58  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 14:59:58  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 14:59:58  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 14:59:58  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 14:59:58  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 14:59:58  [ main:100 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 14:59:58  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 14:59:58  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:00  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:00  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:00  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 15:00:00  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:00  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:00  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:00  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:00  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:00  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:00  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:00  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:00  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:00  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:00  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:00  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:00  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:00  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:00  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:00  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:00  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:00  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:00  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:00  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:00  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:00  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:00  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:03  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:03  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:03  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 15:00:03  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:03  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:03  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:03  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:03  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:03  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:03  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:03  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:03  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:03  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:03  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:03  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:03  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:03  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:03  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:03  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:03  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:03  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:03  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:03  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:03  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:03  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:03  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:05  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:05  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:05  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 15:00:05  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:05  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:05  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:05  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:05  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:05  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:05  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:05  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:05  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:05  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:05  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:05  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:05  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:05  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:05  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:05  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:05  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:05  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:05  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:05  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:05  [ main:81 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:05  [ main:81 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:05  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:12  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:12  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:12  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:12  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 15:00:12  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:12  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:12  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:12  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:12  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:12  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:12  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:12  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:12  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:12  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:12  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:12  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:12  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:12  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:12  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:12  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:12  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:12  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:12  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:12  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:12  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:12  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:12  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:15  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:15  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:15  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 15:00:15  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:15  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:15  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:15  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:15  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:15  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:15  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:15  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:15  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:15  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:15  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:15  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:15  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:15  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:15  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:15  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:15  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:15  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:15  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:15  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:15  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:15  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:15  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:00:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:25  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:00:25  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:00:25  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 15:00:25  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:00:25  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:00:25  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:00:25  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:00:25  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:00:25  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:00:25  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:00:25  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:00:25  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:00:25  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:00:25  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:00:25  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:00:25  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:00:25  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:00:25  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:00:25  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:00:25  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:00:25  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:00:25  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:00:25  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:00:25  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:00:25  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:00:25  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:01:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:01:05  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:01:05  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:01:05  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 15:01:05  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:01:05  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:01:05  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:01:05  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:01:05  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:01:05  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:01:05  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:01:05  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:01:05  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:01:05  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:01:05  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:01:05  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:01:05  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:01:05  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:01:05  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:01:05  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:01:05  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:01:05  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:01:05  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:01:05  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:01:05  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:01:05  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:01:05  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 15:06:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:06:03  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 15:06:03  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 15:06:03  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 15:06:03  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 15:06:03  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 15:06:03  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 15:06:03  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 15:06:03  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 15:06:03  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 15:06:03  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 15:06:03  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 15:06:03  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 15:06:03  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 15:06:03  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 15:06:03  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 15:06:03  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 15:06:03  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 15:06:03  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 15:06:03  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 15:06:03  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 15:06:03  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 15:06:03  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 15:06:03  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 15:06:03  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 15:06:03  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 15:06:03  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:47:09  [ kafka-producer-network-thread | DemoProducer1:9666379 ] - [ DEBUG ]  Initialize connection to node -2 for sending metadata request
2017-06-27 17:47:11  [ kafka-producer-network-thread | DemoProducer1:9668601 ] - [ DEBUG ]  Initiating connection to node -2 at 192.168.0.221:9092.
2017-06-27 17:47:15  [ kafka-producer-network-thread | DemoProducer1:9671765 ] - [ DEBUG ]  Added sensor with name node--2.bytes-sent
2017-06-27 17:47:15  [ kafka-producer-network-thread | DemoProducer1:9671765 ] - [ DEBUG ]  Added sensor with name node--2.bytes-received
2017-06-27 17:47:15  [ kafka-producer-network-thread | DemoProducer1:9671766 ] - [ DEBUG ]  Added sensor with name node--2.latency
2017-06-27 17:47:15  [ kafka-producer-network-thread | DemoProducer1:9671766 ] - [ DEBUG ]  Completed connection to node -2
2017-06-27 17:47:17  [ kafka-producer-network-thread | DemoProducer1:9674059 ] - [ DEBUG ]  Sending metadata request {topics=[]} to node -2
2017-06-27 17:47:17  [ kafka-producer-network-thread | DemoProducer1:9674063 ] - [ DEBUG ]  Updated cluster metadata version 2 to Cluster(nodes = [192.168.0.222:9092 (id: 2 rack: null), 192.168.0.220:9092 (id: 3 rack: null), 192.168.0.221:9092 (id: 4 rack: null)], partitions = [])
2017-06-27 17:48:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:48:04  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:48:04  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:48:04  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:48:04  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:48:04  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:48:04  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:48:04  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:48:04  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:48:04  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:48:04  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:48:04  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:48:04  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:48:04  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:48:04  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:48:04  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:48:04  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:48:04  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:48:04  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:48:04  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:48:04  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:48:04  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:48:04  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:48:04  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:48:04  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:48:04  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:48:04  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:50:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:50:26  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:50:26  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:50:26  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:50:26  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:50:26  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:50:26  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:50:26  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:50:26  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:50:26  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:50:26  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:50:26  [ main:81 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:50:26  [ main:82 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:50:26  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:50:26  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:50:26  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:50:26  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:50:26  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:50:26  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:50:26  [ main:85 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:50:26  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:50:26  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:50:26  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:50:26  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:50:26  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:50:26  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:50:26  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:50:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:50:29  [ main:77 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:50:29  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:50:29  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:50:29  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:50:29  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:50:29  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:50:29  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:50:29  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:50:29  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:50:29  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:50:29  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:50:29  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:50:29  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:50:29  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:50:29  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:50:29  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:50:29  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:50:29  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:50:29  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:50:29  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:50:29  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:50:29  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:50:29  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:50:29  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:50:29  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:50:29  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:35  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:35  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:35  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:53:35  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:35  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:35  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:35  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:35  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:35  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:35  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:35  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:35  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:35  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:35  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:35  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:35  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:35  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:35  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:35  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:35  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:35  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:35  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:35  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:35  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:35  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:35  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:42  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:42  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:42  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:53:42  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:42  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:42  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:42  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:42  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:42  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:42  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:42  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:42  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:42  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:42  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:42  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:42  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:42  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:42  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:42  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:42  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:42  [ main:96 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:42  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:42  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:42  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:42  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:42  [ main:99 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:44  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:44  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:44  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:53:44  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:44  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:44  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:44  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:44  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:44  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:44  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:44  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:44  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:44  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:44  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:44  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:44  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:44  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:44  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:44  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:44  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:44  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:44  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:44  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:44  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:44  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:44  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:45  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:45  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:45  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:53:45  [ main:99 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:45  [ main:100 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:45  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:45  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:45  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:45  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:45  [ main:104 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:45  [ main:123 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:45  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:45  [ main:124 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:45  [ main:124 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:45  [ main:124 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:45  [ main:126 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:45  [ main:126 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:45  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:45  [ main:126 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:45  [ main:145 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:45  [ main:145 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:45  [ main:146 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:45  [ kafka-producer-network-thread | DemoProducer1:146 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:45  [ main:150 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:45  [ main:150 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:45  [ main:151 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:47  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:47  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:47  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:53:47  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:47  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:47  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:47  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:47  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:47  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:47  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:47  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:47  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:47  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:47  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:47  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:47  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:47  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:47  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:47  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:47  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:47  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:47  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:47  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:48  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:48  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:48  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:50  [ main:47 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:50  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:50  [ main:55 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:53:50  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:50  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:50  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:50  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:50  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:50  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:50  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:50  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:50  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:50  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:50  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:50  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:50  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:50  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:50  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:50  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:50  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:50  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:50  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:50  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:50  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:50  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:50  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:51  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:51  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:51  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:51  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:53:51  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:51  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:51  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:51  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:51  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:51  [ main:78 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:51  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:51  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:51  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:51  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:51  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:51  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:51  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:51  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:51  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:51  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:51  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:51  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:51  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:51  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:51  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:51  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:51  [ kafka-producer-network-thread | DemoProducer1:117 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:53  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:53  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:53  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:53:53  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:53  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:53  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:53  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:53  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:53  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:53  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:53  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:53  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:53  [ main:103 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:53  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:53  [ main:104 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:53  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:53  [ main:118 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:53  [ main:118 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:53  [ main:119 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:53  [ main:123 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:53  [ main:123 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:53  [ main:123 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:53  [ kafka-producer-network-thread | DemoProducer1:124 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:53  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:53  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:53  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:55  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:55  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:55  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:53:55  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:55  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:55  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:55  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:55  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:55  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:55  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:55  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:55  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:55  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:55  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:55  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:55  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:55  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:55  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:55  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:55  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:55  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:55  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:55  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:55  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:55  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:55  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:57  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:57  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:57  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:53:57  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:57  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:57  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:57  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:57  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:57  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:57  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:57  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:57  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:57  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:57  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:57  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:57  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:57  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:57  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:57  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:57  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:57  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:57  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:57  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:57  [ main:111 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:57  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:57  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:53:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:59  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:53:59  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:53:59  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:53:59  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:53:59  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:53:59  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:53:59  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:53:59  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:53:59  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:53:59  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:53:59  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:53:59  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:53:59  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:53:59  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:53:59  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:53:59  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:53:59  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:53:59  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:53:59  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:53:59  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:53:59  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:53:59  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:53:59  [ kafka-producer-network-thread | DemoProducer1:110 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:53:59  [ main:121 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:53:59  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:53:59  [ main:125 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:54:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:00  [ main:79 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:54:00  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:54:00  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:54:01  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:54:01  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:54:01  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:54:01  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:54:01  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:54:01  [ main:101 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:54:01  [ main:102 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:54:01  [ main:122 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:54:01  [ main:122 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:54:01  [ main:123 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:54:01  [ main:123 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:54:01  [ main:123 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:54:01  [ main:125 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:54:01  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:54:01  [ main:126 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:54:01  [ main:126 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:54:01  [ kafka-producer-network-thread | DemoProducer1:137 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:54:01  [ main:138 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:01  [ main:139 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:54:01  [ main:139 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:54:01  [ main:142 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:54:01  [ main:142 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:54:01  [ main:150 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:54:22  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:22  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:54:22  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:54:22  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:54:22  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:54:22  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:54:22  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:54:22  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:54:22  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:54:22  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:54:22  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:54:22  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:54:22  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:54:22  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:54:22  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:54:22  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:54:22  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:54:22  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:54:22  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:54:22  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:54:22  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:54:22  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:22  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:54:22  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:54:22  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:54:22  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:54:22  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:54:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:25  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:54:25  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:54:25  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 17:54:25  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:54:25  [ main:64 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:54:25  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:54:25  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:54:25  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:54:25  [ main:66 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:54:25  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:54:25  [ main:70 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:54:25  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:54:25  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:54:25  [ main:71 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:54:25  [ main:71 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:54:25  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:54:25  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:54:25  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:54:25  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:54:25  [ kafka-producer-network-thread | DemoProducer1:74 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:54:25  [ main:75 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:25  [ main:76 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:54:25  [ main:76 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:54:25  [ main:78 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:54:25  [ main:78 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:54:25  [ main:79 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:54:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:28  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:54:28  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:54:28  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:54:28  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:54:28  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:54:28  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:54:28  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:54:28  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:54:28  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:54:28  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:54:28  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:54:28  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:54:28  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:54:28  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:54:28  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:54:28  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:54:28  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:54:28  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:54:28  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:54:28  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:54:28  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:54:28  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:54:28  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:54:28  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:54:28  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:54:28  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:56:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:56:18  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:56:18  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:56:18  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 17:56:18  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:56:18  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:56:18  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:56:18  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:56:18  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:56:18  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:56:18  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:56:18  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:56:18  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:56:18  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:56:18  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:56:18  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:56:18  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:56:18  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:56:18  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:56:18  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:56:18  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:56:18  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:56:18  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:56:18  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:56:18  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:56:18  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:56:18  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 17:56:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:56:23  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 17:56:23  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 17:56:23  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 17:56:23  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 17:56:23  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 17:56:23  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 17:56:23  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 17:56:23  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 17:56:23  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 17:56:23  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 17:56:23  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 17:56:23  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 17:56:23  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 17:56:23  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 17:56:23  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 17:56:23  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 17:56:23  [ main:104 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 17:56:23  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 17:56:23  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 17:56:23  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 17:56:23  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 17:56:23  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 17:56:23  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 17:56:23  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 17:56:23  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 17:56:23  [ main:122 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:17  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:06:17  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:06:17  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:06:17  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:06:17  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:06:17  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:06:17  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:06:17  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:06:17  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:06:17  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:06:17  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:06:17  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:06:17  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:06:17  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:06:17  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:06:17  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:06:17  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:06:17  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:06:17  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:06:17  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:17  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:06:17  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:06:17  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:06:17  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:06:17  [ main:93 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:06:17  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:17  [ main:741 ] - [ INFO ]  user number : 1292  , send message count : 19382
2017-06-27 18:06:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:24  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:06:24  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:06:24  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:06:24  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:06:24  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:06:24  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:06:24  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:06:24  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:06:24  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:06:24  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:06:24  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:06:24  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:06:24  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:06:24  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:06:24  [ main:103 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:06:24  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:06:24  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:06:24  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:06:24  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:06:24  [ kafka-producer-network-thread | DemoProducer1:125 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:06:24  [ main:125 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:24  [ main:126 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:06:24  [ main:126 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:06:24  [ main:141 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:06:24  [ main:142 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:06:24  [ main:146 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:24  [ main:818 ] - [ INFO ]  user number : 1265  , send message count : 19096
2017-06-27 18:06:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:27  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:06:27  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:06:27  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:06:27  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:06:27  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:06:27  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:06:27  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:06:27  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:06:27  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:06:27  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:06:27  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:06:27  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:06:27  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:06:27  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:06:27  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:06:27  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:06:27  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:06:27  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:06:27  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:06:27  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:06:27  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:27  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:06:27  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:06:27  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:06:27  [ main:105 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:06:27  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:28  [ main:749 ] - [ INFO ]  user number : 1239  , send message count : 19572
2017-06-27 18:06:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:30  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:06:30  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:06:30  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:06:30  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:06:30  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:06:30  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:06:30  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:06:30  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:06:30  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:06:30  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:06:30  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:06:30  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:06:30  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:06:30  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:06:30  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:06:30  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:06:30  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:06:30  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:06:30  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:06:30  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:06:30  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:30  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:06:30  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:06:30  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:06:30  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:06:30  [ main:90 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:30  [ main:773 ] - [ INFO ]  user number : 1288  , send message count : 19410
2017-06-27 18:06:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:33  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:06:33  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:06:33  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:06:33  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:06:33  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:06:33  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:06:33  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:06:33  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:06:33  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:06:33  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:06:33  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:06:33  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:06:33  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:06:33  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:06:33  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:06:33  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:06:33  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:06:33  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:06:33  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:06:33  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:06:33  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:06:33  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:06:33  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:06:33  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:06:33  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:06:33  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:06:33  [ main:775 ] - [ INFO ]  user number : 1248  , send message count : 18836
2017-06-27 18:06:35  [ main:11839 ] - [ INFO ]  user number : 1265  , send message count : 19098
2017-06-27 18:06:36  [ main:9227 ] - [ INFO ]  user number : 1240  , send message count : 19577
2017-06-27 18:06:36  [ main:9427 ] - [ INFO ]  user number : 1240  , send message count : 19588
2017-06-27 18:06:36  [ main:19705 ] - [ INFO ]  user number : 1292  , send message count : 19384
2017-06-27 18:06:39  [ main:22144 ] - [ INFO ]  user number : 1293  , send message count : 19392
2017-06-27 18:06:39  [ main:15897 ] - [ INFO ]  user number : 1265  , send message count : 19100
2017-06-27 18:06:45  [ main:21803 ] - [ INFO ]  user number : 1266  , send message count : 19102
2017-06-27 18:06:47  [ main:14636 ] - [ INFO ]  user number : 1248  , send message count : 18841
2017-06-27 18:06:47  [ main:30588 ] - [ INFO ]  user number : 1293  , send message count : 19403
2017-06-27 18:06:53  [ main:22996 ] - [ INFO ]  user number : 1288  , send message count : 19412
2017-06-27 18:07:00  [ main:37013 ] - [ INFO ]  user number : 1266  , send message count : 19104
2017-06-27 18:07:10  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:10  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:07:10  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:07:10  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:07:10  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:07:10  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:07:10  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:07:10  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:07:10  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:07:10  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:07:10  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:07:10  [ main:82 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:07:10  [ main:83 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:07:10  [ main:83 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:07:10  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:07:10  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:07:10  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:07:10  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:07:10  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:07:10  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:07:10  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:10  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:07:10  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:07:10  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:07:10  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:07:10  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:07:10  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:07:11  [ main:818 ] - [ INFO ]  user number : 1296  , send message count : 17172
2017-06-27 18:07:14  [ main:3797 ] - [ INFO ]  user number : 1296  , send message count : 17174
2017-06-27 18:07:17  [ main:7352 ] - [ INFO ]  user number : 1297  , send message count : 17186
2017-06-27 18:07:22  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:22  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:07:22  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:07:22  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:07:22  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:07:22  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:07:22  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:07:22  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:07:22  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:07:22  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:07:22  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:07:22  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:07:22  [ main:91 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:07:22  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:07:22  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:07:22  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:07:22  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:07:22  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:07:22  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:07:22  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:07:22  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:07:22  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:22  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:07:22  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:07:22  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:07:22  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:07:22  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:07:23  [ main:791 ] - [ INFO ]  user number : 1262  , send message count : 16969
2017-06-27 18:07:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:27  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:07:27  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:07:27  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:07:27  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:07:27  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:07:27  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:07:27  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:07:27  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:07:27  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:07:27  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:07:27  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:07:27  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:07:27  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:07:27  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:07:27  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:07:27  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:07:27  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:07:27  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:07:27  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:07:27  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:27  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:07:27  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:07:27  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:07:27  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:07:27  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:07:27  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:07:28  [ main:850 ] - [ INFO ]  user number : 1251  , send message count : 17226
2017-06-27 18:07:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:50  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:07:50  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:07:50  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:07:50  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:07:50  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:07:50  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:07:50  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:07:50  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:07:50  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:07:50  [ main:66 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:07:50  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:07:50  [ main:70 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:07:50  [ main:70 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:07:50  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:07:50  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:07:50  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:07:50  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:07:50  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:07:50  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:07:50  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:50  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:07:50  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:07:50  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:07:50  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:07:50  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:07:50  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:07:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:54  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:07:54  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:07:54  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:07:54  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:07:54  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:07:54  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:07:54  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:07:54  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:07:54  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:07:54  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:07:54  [ main:91 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:07:54  [ main:92 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:07:54  [ main:92 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:07:54  [ main:92 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:07:54  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:07:54  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:07:54  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:07:54  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:07:54  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:07:54  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:07:54  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:07:54  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:07:54  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:07:54  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:07:54  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:07:54  [ main:110 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:08:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:03  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:08:03  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:08:03  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:08:03  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:08:03  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:08:03  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:08:03  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:08:03  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:08:03  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:08:03  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:08:03  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:08:03  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:08:03  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:08:03  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:08:03  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:08:03  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:08:03  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:08:03  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:08:03  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:08:03  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:08:03  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:03  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:08:03  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:08:03  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:08:03  [ main:85 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:08:03  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:08:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:05  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:08:05  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:08:05  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:08:05  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:08:05  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:08:05  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:08:05  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:08:05  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:08:05  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:08:05  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:08:05  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:08:05  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:08:05  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:08:05  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:08:05  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:08:05  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:08:05  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:08:05  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:08:05  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:08:05  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:08:05  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:05  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:08:05  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:08:05  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:08:05  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:08:05  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:08:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:11  [ main:48 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:08:11  [ main:52 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:08:11  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:08:11  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:08:11  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:08:11  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:08:11  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:08:11  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:08:11  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:08:11  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:08:11  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:08:11  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:08:11  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:08:11  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:08:11  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:08:11  [ main:84 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:08:11  [ main:84 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:08:11  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:08:11  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:08:11  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:08:11  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:11  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:08:11  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:08:11  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:08:11  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:08:11  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:08:14  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:14  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:08:14  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:08:14  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:08:14  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:08:14  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:08:14  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:08:14  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:08:14  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:08:14  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:08:14  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:08:14  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:08:14  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:08:14  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:08:14  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:08:14  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:08:14  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:08:14  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:08:14  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:08:14  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:08:14  [ main:82 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:08:14  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:08:14  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:08:14  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:08:14  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:08:14  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:08:14  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:03  [ main:78 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:03  [ main:85 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:03  [ main:87 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:03  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:03  [ main:94 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:03  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:03  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:03  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:03  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:03  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:03  [ main:100 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:03  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:03  [ main:101 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:03  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:03  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:03  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:03  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:03  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:03  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:03  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:03  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:03  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:03  [ main:107 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:03  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:03  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:03  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:04  [ main:840 ] - [ INFO ]  user number : 1252  , send message count : 17385
2017-06-27 18:09:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:04  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:04  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:04  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:04  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:04  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:04  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:04  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:04  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:04  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:04  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:04  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:04  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:04  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:04  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:04  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:04  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:04  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:04  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:04  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:04  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:04  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:04  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:04  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:04  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:04  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:04  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:05  [ main:753 ] - [ INFO ]  user number : 1231  , send message count : 16840
2017-06-27 18:09:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:06  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:06  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:06  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:09:06  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:06  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:06  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:06  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:06  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:06  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:06  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:06  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:06  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:06  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:06  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:06  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:06  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:06  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:06  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:06  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:06  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:06  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:06  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:06  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:06  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:06  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:06  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:07  [ main:730 ] - [ INFO ]  user number : 1254  , send message count : 17292
2017-06-27 18:09:08  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:08  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:08  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:08  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:08  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:08  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:08  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:08  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:08  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:08  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:08  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:08  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:08  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:08  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:08  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:08  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:08  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:08  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:08  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:08  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:08  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:08  [ main:82 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:08  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:08  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:08  [ main:85 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:08  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:08  [ main:86 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:09  [ main:784 ] - [ INFO ]  user number : 1200  , send message count : 16526
2017-06-27 18:09:12  [ main:3849 ] - [ INFO ]  user number : 1201  , send message count : 16537
2017-06-27 18:09:14  [ main:8079 ] - [ INFO ]  user number : 1255  , send message count : 17304
2017-06-27 18:09:22  [ main:19682 ] - [ INFO ]  user number : 1252  , send message count : 17387
2017-06-27 18:09:23  [ main:14952 ] - [ INFO ]  user number : 1201  , send message count : 16539
2017-06-27 18:09:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:29  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:29  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:29  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:09:29  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:29  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:29  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:29  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:29  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:29  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:29  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:29  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:29  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:29  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:29  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:29  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:29  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:29  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:29  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:29  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:29  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:29  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:29  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:29  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:29  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:29  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:29  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:32  [ main:50 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:32  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:32  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:09:32  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:32  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:32  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:32  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:32  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:32  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:32  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:32  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:32  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:32  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:32  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:32  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:32  [ main:74 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:32  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:32  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:32  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:32  [ kafka-producer-network-thread | DemoProducer1:76 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:32  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:32  [ main:77 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:32  [ main:77 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:32  [ main:80 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:32  [ main:80 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:32  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:36  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:36  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:36  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:36  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:36  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:36  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:36  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:36  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:36  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:36  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:36  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:36  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:36  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:36  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:36  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:36  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:36  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:36  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:36  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:36  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:36  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:36  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:36  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:36  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:36  [ main:87 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:36  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:37  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:37  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:37  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:09:37  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:37  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:37  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:37  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:37  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:37  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:37  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:37  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:37  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:37  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:37  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:37  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:37  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:37  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:37  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:37  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:37  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:37  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:37  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:37  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:37  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:37  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:37  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:39  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:39  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:39  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:39  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:39  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:39  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:39  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:39  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:39  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:39  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:39  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:39  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:39  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:39  [ main:92 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:39  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:39  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:39  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:39  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:39  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:39  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:39  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:39  [ main:116 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:39  [ main:116 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:39  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:39  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:39  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:41  [ main:82 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:41  [ main:88 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:41  [ main:89 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:41  [ main:111 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:41  [ main:111 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:41  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:41  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:41  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:41  [ main:113 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:41  [ main:115 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:41  [ main:118 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:41  [ main:119 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:41  [ main:119 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:41  [ main:119 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:41  [ main:120 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:41  [ main:121 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:41  [ main:121 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:41  [ main:122 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:41  [ main:122 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:41  [ kafka-producer-network-thread | DemoProducer1:143 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:41  [ main:143 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:41  [ main:144 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:41  [ main:144 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:41  [ main:148 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:41  [ main:148 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:41  [ main:149 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:43  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:43  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:43  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:09:43  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:43  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:43  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:43  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:43  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:43  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:43  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:43  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:43  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:43  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:43  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:43  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:43  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:43  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:43  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:43  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:43  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:43  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:43  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:43  [ kafka-producer-network-thread | DemoProducer1:103 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:43  [ main:116 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:43  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:43  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:52  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:52  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:52  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:09:52  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:52  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:52  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:52  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:52  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:52  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:52  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:52  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:52  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:52  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:52  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:52  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:52  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:52  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:52  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:52  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:52  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:52  [ main:97 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:52  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:52  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:52  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:52  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:52  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:09:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:58  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:09:58  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:09:58  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:09:58  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:09:58  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:09:58  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:09:58  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:09:58  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:09:58  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:09:58  [ main:78 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:09:58  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:09:58  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:09:58  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:09:58  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:09:58  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:09:58  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:09:58  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:09:58  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:09:58  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:09:58  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:09:58  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:09:58  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:09:58  [ main:98 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:09:58  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:09:58  [ main:98 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:09:58  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:01  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:02  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:02  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:02  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:10:02  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:02  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:02  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:02  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:02  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:02  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:02  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:02  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:02  [ main:87 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:02  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:02  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:02  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:02  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:02  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:02  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:02  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:02  [ kafka-producer-network-thread | DemoProducer1:94 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:02  [ main:95 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:02  [ main:96 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:02  [ main:96 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:02  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:02  [ main:99 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:02  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:04  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:04  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:04  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:04  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:10:04  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:04  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:04  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:04  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:04  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:04  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:04  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:04  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:04  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:04  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:04  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:04  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:04  [ main:82 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:04  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:04  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:04  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:04  [ main:86 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:05  [ main:87 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:05  [ main:87 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:05  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:05  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:05  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:05  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:07  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:07  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:07  [ main:85 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:10:07  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:07  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:07  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:07  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:07  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:07  [ main:97 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:07  [ main:97 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:07  [ main:101 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:07  [ main:101 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:07  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:07  [ main:102 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:07  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:07  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:07  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:07  [ main:106 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:07  [ main:106 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:07  [ main:123 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:07  [ main:124 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:07  [ main:124 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:07  [ main:137 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:07  [ main:137 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:07  [ main:138 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:07  [ kafka-producer-network-thread | DemoProducer1:152 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:15  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:15  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:15  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:10:15  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:15  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:15  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:15  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:15  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:15  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:15  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:15  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:15  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:15  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:15  [ main:83 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:15  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:15  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:15  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:15  [ main:93 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:15  [ main:93 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:15  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:15  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:15  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:15  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:15  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:15  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:15  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:18  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:18  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:18  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:10:18  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:18  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:18  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:18  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:18  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:18  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:18  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:18  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:18  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:18  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:18  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:18  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:18  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:18  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:18  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:18  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:18  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:18  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:18  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:18  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:18  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:18  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:18  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:20  [ main:97 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:20  [ main:103 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:20  [ main:105 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:10:20  [ main:114 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:20  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:20  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:20  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:20  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:20  [ main:116 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:20  [ main:117 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:20  [ main:120 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:20  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:20  [ main:121 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:20  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:20  [ main:121 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:20  [ main:123 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:20  [ main:123 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:20  [ main:123 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:20  [ main:124 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:20  [ kafka-producer-network-thread | DemoProducer1:153 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:20  [ main:155 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:20  [ main:155 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:20  [ main:155 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:20  [ main:158 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:20  [ main:158 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:20  [ main:159 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:47  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:47  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:47  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:10:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:47  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:47  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:47  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:47  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:47  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:47  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:47  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:47  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:47  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:47  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:47  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:47  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:47  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:47  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:47  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:47  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:47  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:47  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:47  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:10:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:56  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:10:56  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:10:56  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:10:56  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:10:56  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:10:56  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:10:56  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:10:56  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:10:56  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:10:56  [ main:93 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:10:56  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:10:56  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:10:56  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:10:56  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:10:56  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:10:56  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:10:56  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:10:56  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:10:56  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:10:56  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:10:56  [ main:104 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:10:56  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:10:56  [ main:105 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:10:56  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:10:56  [ main:122 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:10:56  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:12:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:12:10  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:12:10  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:12:10  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:12:10  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:12:10  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:12:10  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:12:10  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:12:10  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:12:10  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:12:10  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:12:10  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:12:10  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:12:10  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:12:10  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:12:10  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:12:10  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:12:10  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:12:10  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:12:10  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:12:10  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:12:10  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:12:10  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:12:10  [ kafka-producer-network-thread | DemoProducer1:116 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:12:10  [ main:116 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:12:10  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:12:10  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:15:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:15:47  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:15:47  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:15:47  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:15:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:15:47  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:15:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:15:47  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:15:47  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:15:47  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:15:47  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:15:47  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:15:47  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:15:47  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:15:47  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:15:47  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:15:47  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:15:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:15:47  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:15:47  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:15:47  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:15:47  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:15:47  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:15:47  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:15:47  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:15:47  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:15:47  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:15:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:15:50  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:15:50  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:15:50  [ main:56 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:15:50  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:15:50  [ main:63 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:15:50  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:15:50  [ main:64 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:15:50  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:15:50  [ main:65 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:15:50  [ main:65 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:15:50  [ main:69 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:15:50  [ main:70 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:15:50  [ main:70 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:15:50  [ main:72 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:15:50  [ main:73 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:15:50  [ main:73 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:15:50  [ main:73 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:15:50  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:15:50  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:15:50  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:15:50  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:15:50  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:15:50  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:15:50  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:16:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:16:55  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:16:55  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:16:55  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:16:55  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:16:55  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:16:55  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:16:55  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:16:55  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:16:55  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:16:55  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:16:55  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:16:55  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:16:55  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:16:55  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:16:55  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:16:55  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:16:55  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:16:55  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:16:55  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:16:55  [ kafka-producer-network-thread | DemoProducer1:100 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:16:55  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:16:55  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:16:55  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:16:55  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:16:55  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:16:55  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:26:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:26:27  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:26:27  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:26:27  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:26:27  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:26:27  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:26:27  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:26:27  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:26:27  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:26:27  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:26:27  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:26:27  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:26:27  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:26:27  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:26:27  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:26:27  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:26:27  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:26:27  [ main:102 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:26:27  [ main:102 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:26:27  [ main:102 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:26:27  [ kafka-producer-network-thread | DemoProducer1:110 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:26:27  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:26:27  [ main:112 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:26:27  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:26:27  [ main:115 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:26:27  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:26:27  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:28:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:28:42  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:28:42  [ main:89 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:28:42  [ main:93 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:28:42  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:28:42  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:28:42  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:28:42  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:28:42  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:28:42  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:28:42  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:28:42  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:28:42  [ main:109 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:28:42  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:28:42  [ main:110 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:28:42  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:28:42  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:28:42  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:28:42  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:28:42  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:28:42  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:28:42  [ main:114 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:28:42  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:28:42  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:28:42  [ main:119 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:28:42  [ main:119 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:28:42  [ main:120 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:32:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:49  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:32:49  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:32:49  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:32:49  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:32:49  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:32:49  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:32:49  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:32:49  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:32:49  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:32:49  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:32:49  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:32:49  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:32:49  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:32:49  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:32:49  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:32:49  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:32:49  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:32:49  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:32:49  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:32:49  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:49  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:32:49  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:32:49  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:32:49  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:32:49  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:32:49  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:32:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:55  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:32:55  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:32:55  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:32:55  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:32:55  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:32:55  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:32:55  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:32:55  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:32:55  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:32:55  [ main:79 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:32:55  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:32:55  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:32:55  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:32:55  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:32:55  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:32:55  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:32:55  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:32:55  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:32:55  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:32:55  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:55  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:32:55  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:32:55  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:32:55  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:32:55  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:32:55  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:32:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:57  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:32:57  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:32:57  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:32:57  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:32:57  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:32:57  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:32:57  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:32:57  [ main:104 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:32:57  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:32:57  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:32:57  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:32:57  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:32:57  [ main:108 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:32:57  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:32:57  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:32:57  [ main:110 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:32:57  [ main:111 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:32:57  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:32:57  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:32:57  [ kafka-producer-network-thread | DemoProducer1:114 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:32:57  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:57  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:32:57  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:32:57  [ main:126 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:32:57  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:32:57  [ main:127 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:32:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:59  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:32:59  [ main:79 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:32:59  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:32:59  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:32:59  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:32:59  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:32:59  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:32:59  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:32:59  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:32:59  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:32:59  [ main:113 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:32:59  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:32:59  [ main:115 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:32:59  [ main:116 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:32:59  [ main:116 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:32:59  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:32:59  [ main:119 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:32:59  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:32:59  [ main:119 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:32:59  [ kafka-producer-network-thread | DemoProducer1:124 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:32:59  [ main:124 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:32:59  [ main:133 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:32:59  [ main:133 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:32:59  [ main:147 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:32:59  [ main:147 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:32:59  [ main:148 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:34:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:00  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:34:00  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:34:00  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:34:00  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:34:00  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:34:00  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:34:00  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:34:00  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:34:00  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:34:00  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:34:00  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:34:00  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:34:00  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:34:00  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:34:00  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:34:00  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:34:00  [ main:82 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:34:00  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:34:00  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:34:00  [ kafka-producer-network-thread | DemoProducer1:84 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:34:00  [ main:85 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:00  [ main:86 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:34:00  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:34:00  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:34:00  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:34:00  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:34:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:03  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:34:03  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:34:03  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:34:03  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:34:03  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:34:03  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:34:03  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:34:03  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:34:03  [ main:82 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:34:03  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:34:03  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:34:03  [ main:102 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:34:03  [ main:102 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:34:03  [ main:103 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:34:03  [ main:103 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:34:03  [ main:104 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:34:03  [ main:105 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:34:03  [ main:105 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:34:03  [ main:105 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:34:03  [ kafka-producer-network-thread | DemoProducer1:107 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:34:03  [ main:108 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:03  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:34:03  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:34:03  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:34:03  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:34:03  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:34:11  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:11  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:34:11  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:34:11  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:34:11  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:34:11  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:34:11  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:34:11  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:34:11  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:34:11  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:34:11  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:34:11  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:34:11  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:34:11  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:34:11  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:34:11  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:34:11  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:34:11  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:34:11  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:34:11  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:34:11  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:34:11  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:11  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:34:11  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:34:11  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:34:11  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:34:11  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:34:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:27  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:34:27  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:34:27  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:34:27  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:34:27  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:34:27  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:34:27  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:34:27  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:34:27  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:34:27  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:34:27  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:34:27  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:34:27  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:34:27  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:34:27  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:34:27  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:34:27  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:34:27  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:34:27  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:34:27  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:34:27  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:34:27  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:34:27  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:34:27  [ main:99 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:34:27  [ main:100 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:34:27  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:38:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:38:56  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:38:56  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:38:56  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:38:56  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:38:56  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:38:56  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:38:56  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:38:56  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:38:56  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:38:56  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:38:56  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:38:56  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:38:56  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:38:56  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:38:56  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:38:56  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:38:56  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:38:56  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:38:56  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:38:56  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:38:56  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:38:56  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:38:56  [ kafka-producer-network-thread | DemoProducer1:85 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:38:56  [ main:87 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:38:56  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:38:56  [ main:88 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:38:59  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:38:59  [ main:51 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:38:59  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:38:59  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:38:59  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:38:59  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:38:59  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:38:59  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:38:59  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:38:59  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:38:59  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:38:59  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:38:59  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:38:59  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:38:59  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:38:59  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:38:59  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:38:59  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:38:59  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:38:59  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:38:59  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:38:59  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:38:59  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:38:59  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:38:59  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:38:59  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:38:59  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:39:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:39:13  [ main:67 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:39:13  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:39:13  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:39:13  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:39:13  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:39:13  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:39:13  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:39:13  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:39:13  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:39:13  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:39:13  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:39:13  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:39:13  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:39:13  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:39:13  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:39:13  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:39:13  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:39:13  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:39:13  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:39:13  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:39:13  [ main:115 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:39:13  [ main:117 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:39:13  [ main:117 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:39:13  [ main:120 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:39:13  [ main:120 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:39:13  [ main:121 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:40:10  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:40:10  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:40:10  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:40:10  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:40:10  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:40:10  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:40:10  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:40:10  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:40:10  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:40:10  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:40:10  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:40:10  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:40:10  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:40:10  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:40:10  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:40:10  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:40:10  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:40:10  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:40:10  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:40:10  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:40:10  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:40:10  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:40:10  [ main:114 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:40:10  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:40:10  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:40:10  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:40:10  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:40  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:40  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:40  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:40  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:40  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:40  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:40  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:40  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:40  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:40  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:40  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:40  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:40  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:40  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:40  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:40  [ main:79 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:40  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:40  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:40  [ main:81 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:40  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:40  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:40  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:40  [ main:84 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:40  [ main:84 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:40  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:40  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:40  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:42  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:42  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:42  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:42  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:42  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:42  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:42  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:42  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:42  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:42  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:42  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:42  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:42  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:42  [ main:89 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:42  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:42  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:42  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:42  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:42  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:42  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:42  [ main:100 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:42  [ main:101 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:42  [ main:101 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:42  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:42  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:42  [ main:114 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:42  [ main:115 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:44  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:44  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:44  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:42:44  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:44  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:44  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:44  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:44  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:44  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:44  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:44  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:44  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:44  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:44  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:44  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:44  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:44  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:44  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:44  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:44  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:44  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:44  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:44  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:44  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:44  [ main:90 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:44  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:46  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:46  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:46  [ main:89 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:46  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:42:46  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:46  [ main:102 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:46  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:46  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:46  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:46  [ main:104 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:46  [ main:105 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:46  [ main:108 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:46  [ main:109 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:46  [ main:109 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:46  [ main:110 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:46  [ main:110 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:46  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:46  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:46  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:46  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:46  [ main:114 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:46  [ main:115 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:46  [ main:115 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:46  [ main:118 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:46  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:46  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:46  [ kafka-producer-network-thread | DemoProducer1:137 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:48  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:48  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:48  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:48  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:42:48  [ main:106 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:48  [ main:109 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:48  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:48  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:48  [ main:111 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:48  [ main:111 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:48  [ main:111 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:48  [ main:115 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:48  [ main:116 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:48  [ main:117 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:48  [ main:118 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:48  [ main:120 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:48  [ main:129 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:48  [ main:130 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:48  [ main:131 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:48  [ main:131 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:48  [ kafka-producer-network-thread | DemoProducer1:146 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:48  [ main:148 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:48  [ main:148 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:48  [ main:148 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:48  [ main:172 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:48  [ main:173 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:48  [ main:174 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:50  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:50  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:50  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:50  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:50  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:50  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:50  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:50  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:50  [ main:87 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:50  [ main:88 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:50  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:50  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:50  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:50  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:50  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:50  [ main:103 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:50  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:50  [ main:104 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:50  [ main:104 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:50  [ kafka-producer-network-thread | DemoProducer1:108 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:50  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:50  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:50  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:50  [ main:113 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:50  [ main:113 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:50  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:52  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:52  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:52  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:52  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:52  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:52  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:52  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:52  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:52  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:52  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:52  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:52  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:52  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:52  [ main:93 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:52  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:52  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:52  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:52  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:52  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:52  [ kafka-producer-network-thread | DemoProducer1:109 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:52  [ main:109 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:52  [ main:110 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:52  [ main:110 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:52  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:52  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:52  [ main:125 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:54  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:54  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:54  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:54  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:54  [ main:93 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:54  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:54  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:54  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:54  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:54  [ main:96 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:54  [ main:99 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:54  [ main:100 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:54  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:54  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:54  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:54  [ main:102 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:54  [ main:103 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:54  [ main:103 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:54  [ main:103 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:54  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:54  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:54  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:54  [ kafka-producer-network-thread | DemoProducer1:129 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:54  [ main:130 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:54  [ main:130 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:54  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:56  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:56  [ main:94 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:56  [ main:96 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:56  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:56  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:56  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:56  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:56  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:56  [ main:107 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:56  [ main:108 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:56  [ main:123 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:56  [ main:124 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:56  [ main:125 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:56  [ main:128 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:56  [ main:129 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:56  [ main:139 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:56  [ main:141 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:56  [ main:142 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:56  [ main:142 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:56  [ main:154 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:56  [ kafka-producer-network-thread | DemoProducer1:154 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:56  [ main:155 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:56  [ main:155 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:56  [ main:157 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:56  [ main:158 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:56  [ main:158 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:42:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:58  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:42:58  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:42:58  [ main:64 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:42:58  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:42:58  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:42:58  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:42:58  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:42:58  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:42:58  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:42:58  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:42:58  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:42:58  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:42:58  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:42:58  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:42:58  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:42:58  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:42:58  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:42:58  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:42:58  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:42:58  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:42:58  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:42:58  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:42:58  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:42:58  [ main:103 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:42:58  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:42:58  [ main:104 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:43:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:00  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:43:00  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:43:00  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:43:00  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:43:00  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:43:00  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:43:00  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:43:00  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:43:00  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:43:00  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:43:00  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:43:00  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:43:00  [ main:97 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:43:00  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:43:00  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:43:00  [ main:99 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:43:00  [ main:99 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:43:00  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:43:00  [ main:100 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:43:00  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:00  [ main:108 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:43:00  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:43:00  [ kafka-producer-network-thread | DemoProducer1:115 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:43:00  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:43:00  [ main:117 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:43:00  [ main:118 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:43:02  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:02  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:43:02  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:43:02  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:43:02  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:43:02  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:43:02  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:43:02  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:43:02  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:43:02  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:43:02  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:43:02  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:43:02  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:43:02  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:43:02  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:43:02  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:43:02  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:43:02  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:43:02  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:43:02  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:43:02  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:43:02  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:02  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:43:02  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:43:02  [ main:81 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:43:02  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:43:02  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:43:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:06  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:43:06  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:43:06  [ main:80 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:43:06  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:43:06  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:43:06  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:43:06  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:43:06  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:43:06  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:43:06  [ main:91 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:43:06  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:43:06  [ main:95 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:43:06  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:43:06  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:43:06  [ main:96 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:43:06  [ main:97 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:43:06  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:43:06  [ main:98 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:43:06  [ main:98 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:43:06  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:43:06  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:43:06  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:43:06  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:43:06  [ main:104 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:43:06  [ main:104 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:43:06  [ main:105 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:10  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:10  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:10  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:10  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:44:10  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:10  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:10  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:10  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:10  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:10  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:10  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:10  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:10  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:10  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:10  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:10  [ main:84 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:10  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:10  [ main:86 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:10  [ main:86 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:10  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:10  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:10  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:10  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:10  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:10  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:10  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:10  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:13  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:13  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:13  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:13  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:13  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:13  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:13  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:13  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:13  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:13  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:13  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:13  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:13  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:13  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:13  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:13  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:13  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:13  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:13  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:13  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:13  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:13  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:13  [ main:98 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:13  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:13  [ main:111 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:13  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:15  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:15  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:15  [ main:66 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:15  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:15  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:15  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:15  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:15  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:15  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:15  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:15  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:15  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:15  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:15  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:15  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:15  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:15  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:15  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:15  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:15  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:15  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:15  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:15  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:15  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:15  [ main:95 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:15  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:17  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:17  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:17  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:17  [ main:75 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:17  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:17  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:17  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:17  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:17  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:17  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:17  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:17  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:17  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:17  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:17  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:17  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:17  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:17  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:17  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:17  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:17  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:17  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:17  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:17  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:17  [ main:108 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:17  [ main:108 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:19  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:19  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:19  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:19  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:19  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:19  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:19  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:19  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:19  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:19  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:19  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:19  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:19  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:19  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:19  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:19  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:19  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:19  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:19  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:19  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:19  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:19  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:19  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:19  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:19  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:19  [ main:114 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:37  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:37  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:37  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:37  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:37  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:37  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:37  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:37  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:37  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:37  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:37  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:37  [ main:72 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:37  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:37  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:37  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:37  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:37  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:37  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:37  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:37  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:37  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:37  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:37  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:37  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:37  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:37  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:39  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:39  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:39  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:39  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:39  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:39  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:39  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:39  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:39  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:39  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:39  [ main:109 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:39  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:39  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:39  [ main:114 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:39  [ main:114 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:39  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:39  [ main:118 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:39  [ main:118 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:39  [ main:120 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:39  [ main:132 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:39  [ main:133 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:39  [ main:133 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:39  [ kafka-producer-network-thread | DemoProducer1:133 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:39  [ main:155 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:39  [ main:156 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:39  [ main:156 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:41  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:41  [ main:78 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:41  [ main:81 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:41  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:41  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:41  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:41  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:41  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:41  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:41  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:41  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:41  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:41  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:41  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:41  [ main:102 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:42  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:42  [ main:112 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:42  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:42  [ main:113 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:42  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:42  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:42  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:42  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:42  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:42  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:42  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:43  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:43  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:43  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:43  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:43  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:43  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:43  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:43  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:43  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:43  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:43  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:43  [ main:97 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:43  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:43  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:43  [ main:100 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:43  [ main:100 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:43  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:43  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:43  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:43  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:43  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:43  [ main:120 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:43  [ main:121 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:43  [ main:121 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:43  [ main:132 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:43  [ main:132 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:43  [ main:133 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:45  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:45  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:45  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:45  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:45  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:45  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:45  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:45  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:45  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:45  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:45  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:45  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:45  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:45  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:45  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:45  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:45  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:45  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:45  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:45  [ kafka-producer-network-thread | DemoProducer1:77 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:45  [ main:77 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:45  [ main:78 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:45  [ main:78 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:45  [ main:80 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:45  [ main:80 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:45  [ main:81 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:47  [ main:90 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:47  [ main:97 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:47  [ main:99 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:44:47  [ main:135 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:47  [ main:136 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:47  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:47  [ main:136 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:47  [ main:137 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:47  [ main:137 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:47  [ main:138 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:47  [ main:149 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:47  [ main:150 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:47  [ main:150 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:47  [ main:151 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:47  [ main:151 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:47  [ main:152 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:47  [ main:153 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:47  [ main:153 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:47  [ main:153 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:47  [ kafka-producer-network-thread | DemoProducer1:167 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:47  [ main:167 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:47  [ main:168 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:47  [ main:168 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:48  [ main:177 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:48  [ main:178 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:48  [ main:178 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:50  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:50  [ main:89 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:50  [ main:91 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:50  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:50  [ main:105 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:50  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:50  [ main:107 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:50  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:50  [ main:109 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:50  [ main:110 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:50  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:50  [ main:115 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:50  [ main:116 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:50  [ main:117 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:50  [ main:117 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:50  [ main:124 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:50  [ main:125 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:50  [ main:125 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:50  [ main:125 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:50  [ kafka-producer-network-thread | DemoProducer1:126 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:50  [ main:127 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:50  [ main:128 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:50  [ main:128 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:50  [ main:140 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:50  [ main:140 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:50  [ main:145 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:52  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:52  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:52  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:52  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:44:52  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:52  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:52  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:52  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:52  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:52  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:52  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:52  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:52  [ main:77 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:52  [ main:77 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:52  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:52  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:52  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:52  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:52  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:52  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:52  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:52  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:52  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:52  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:52  [ main:97 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:52  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:52  [ main:98 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:53  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:53  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:53  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:53  [ main:73 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:44:53  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:53  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:53  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:53  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:53  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:53  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:53  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:53  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:53  [ main:105 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:53  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:53  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:53  [ main:108 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:53  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:53  [ main:110 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:53  [ main:110 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:53  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:53  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:53  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:53  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:53  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:53  [ main:122 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:53  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:53  [ main:123 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:55  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:55  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:55  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:55  [ main:95 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:44:55  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:55  [ main:115 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:55  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:55  [ main:116 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:55  [ main:121 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:55  [ main:121 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:55  [ main:122 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:55  [ main:125 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:55  [ main:125 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:55  [ main:125 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:55  [ main:126 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:55  [ main:127 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:55  [ main:135 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:55  [ main:136 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:55  [ main:137 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:55  [ main:138 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:55  [ main:148 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:55  [ main:162 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:55  [ main:162 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:55  [ kafka-producer-network-thread | DemoProducer1:170 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:55  [ main:193 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:55  [ main:196 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:55  [ main:197 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:44:57  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:57  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:44:57  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:44:57  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:44:57  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:44:57  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:44:57  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:44:57  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:44:57  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:44:57  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:44:57  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:44:57  [ main:79 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:44:57  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:44:57  [ main:82 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:44:57  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:44:57  [ main:83 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:44:57  [ main:93 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:44:57  [ main:93 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:44:57  [ main:94 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:44:57  [ main:94 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:44:57  [ main:113 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:44:57  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:44:57  [ main:114 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:44:57  [ kafka-producer-network-thread | DemoProducer1:116 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:44:57  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:44:57  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:44:57  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:17  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:18  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:18  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:18  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:46:18  [ main:83 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:18  [ main:84 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:18  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:18  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:18  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:18  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:18  [ main:86 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:18  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:18  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:18  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:18  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:18  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:18  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:18  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:18  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:18  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:18  [ kafka-producer-network-thread | DemoProducer1:105 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:18  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:18  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:18  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:18  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:18  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:18  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:20  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:20  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:20  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:46:20  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:20  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:20  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:20  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:20  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:20  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:20  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:20  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:20  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:20  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:20  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:20  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:20  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:20  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:20  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:20  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:20  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:20  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:20  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:20  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:20  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:20  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:20  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:22  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:22  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:22  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:22  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:46:22  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:22  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:22  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:22  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:22  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:22  [ main:90 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:22  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:22  [ main:94 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:22  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:22  [ main:95 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:22  [ main:95 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:22  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:22  [ main:100 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:22  [ main:100 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:22  [ main:100 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:22  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:22  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:22  [ main:105 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:22  [ main:106 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:22  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:22  [ main:120 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:22  [ main:121 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:22  [ main:130 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:24  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:24  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:24  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:24  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:46:24  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:24  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:24  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:24  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:24  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:24  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:24  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:24  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:24  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:24  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:24  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:24  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:24  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:24  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:24  [ main:84 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:24  [ main:84 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:24  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:24  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:24  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:24  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:24  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:24  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:24  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:26  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:26  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:26  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:46:26  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:26  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:26  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:26  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:26  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:26  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:26  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:26  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:26  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:26  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:26  [ main:97 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:26  [ main:98 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:26  [ main:105 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:26  [ main:107 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:26  [ main:107 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:26  [ main:107 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:26  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:26  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:26  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:26  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:26  [ main:136 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:26  [ main:136 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:26  [ main:137 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:32  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:32  [ main:66 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:32  [ main:68 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:46:32  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:32  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:32  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:32  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:32  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:32  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:32  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:32  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:32  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:32  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:32  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:32  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:32  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:32  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:32  [ kafka-producer-network-thread | DemoProducer1:90 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:32  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:32  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:32  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:32  [ main:94 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:32  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:32  [ main:95 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:34  [ main:77 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:34  [ main:82 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:34  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:46:34  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:34  [ main:91 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:34  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:34  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:34  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:34  [ main:94 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:34  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:34  [ main:114 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:34  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:34  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:34  [ main:115 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:34  [ main:115 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:34  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:34  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:34  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:34  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:34  [ main:121 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:34  [ main:122 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:34  [ main:122 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:34  [ kafka-producer-network-thread | DemoProducer1:130 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:34  [ main:131 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:34  [ main:131 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:34  [ main:131 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:35  [ main:76 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:35  [ main:84 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:35  [ main:86 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:46:35  [ main:97 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:35  [ main:98 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:35  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:35  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:35  [ main:99 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:35  [ main:100 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:35  [ main:100 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:35  [ main:104 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:35  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:35  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:35  [ main:105 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:35  [ main:105 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:35  [ main:107 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:35  [ main:108 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:35  [ main:108 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:35  [ main:108 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:35  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:35  [ main:119 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:35  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:35  [ main:120 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:35  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:35  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:35  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:37  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:37  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:37  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:37  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:46:37  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:37  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:37  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:37  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:37  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:37  [ main:93 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:37  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:37  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:37  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:37  [ main:100 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:37  [ main:101 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:37  [ main:101 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:37  [ main:110 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:37  [ main:111 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:38  [ main:112 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:38  [ main:112 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:38  [ main:148 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:38  [ main:149 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:38  [ main:149 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:38  [ kafka-producer-network-thread | DemoProducer1:150 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:38  [ main:152 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:38  [ main:152 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:38  [ main:162 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:39  [ main:81 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:39  [ main:86 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:39  [ main:88 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 18:46:39  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:39  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:39  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:39  [ main:96 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:39  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:39  [ main:98 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:39  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:39  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:39  [ main:104 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:39  [ main:105 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:39  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:39  [ main:108 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:39  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:39  [ main:116 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:39  [ main:116 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:39  [ main:118 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:39  [ kafka-producer-network-thread | DemoProducer1:128 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:39  [ main:129 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:39  [ main:131 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:39  [ main:132 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:39  [ main:148 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:39  [ main:149 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:39  [ main:150 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:46:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:50  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:46:50  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:46:50  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:46:50  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:46:50  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:46:50  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:46:50  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:46:50  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:46:50  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:46:50  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:46:50  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:46:50  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:46:50  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:46:50  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:46:50  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:46:50  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:46:50  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:46:50  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:46:50  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:46:50  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:46:50  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:46:50  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:46:50  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:46:50  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:46:50  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:46:50  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:49:14  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:49:14  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:49:14  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:49:14  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 18:49:14  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:49:14  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:49:14  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:49:14  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:49:14  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:49:14  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:49:14  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:49:14  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:49:14  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:49:14  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:49:14  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:49:14  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:49:14  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:49:14  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:49:14  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:49:14  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:49:14  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:49:14  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 18:49:14  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:49:14  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:49:14  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:49:14  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:49:14  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:49:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:49:47  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 18:49:47  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 18:49:47  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 18:49:47  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 18:49:47  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 18:49:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 18:49:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 18:49:47  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 18:49:47  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 18:49:47  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 18:49:47  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 18:49:47  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 18:49:47  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 18:49:47  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 18:49:47  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 18:49:47  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 18:49:47  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 18:49:47  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 18:49:47  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 18:49:47  [ main:103 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 18:49:47  [ main:104 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 18:49:47  [ main:104 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 18:49:47  [ main:117 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 18:49:47  [ main:118 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 18:49:47  [ main:119 ] - [ DEBUG ]  Kafka producer started
2017-06-27 18:49:47  [ kafka-producer-network-thread | DemoProducer1:126 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:34:55  [ kafka-producer-network-thread | DemoProducer1:2707844 ] - [ DEBUG ]  Initialize connection to node -1 for sending metadata request
2017-06-27 19:34:55  [ kafka-producer-network-thread | DemoProducer1:2707845 ] - [ DEBUG ]  Initiating connection to node -1 at 192.168.0.220:9092.
2017-06-27 19:35:06  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:35:06  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:35:06  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:35:06  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:35:06  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:35:06  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:35:06  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:35:06  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:35:06  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:35:06  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:35:06  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:35:06  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:35:06  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:35:06  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:35:06  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:35:06  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:35:06  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:35:06  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:35:06  [ kafka-producer-network-thread | DemoProducer1:80 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:35:06  [ main:80 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:35:06  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:35:06  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:35:06  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:35:06  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:35:06  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:35:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:35:23  [ main:70 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:35:23  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:35:23  [ main:79 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:35:23  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:35:23  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:35:23  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:35:23  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:35:23  [ main:89 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:35:23  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:35:23  [ main:90 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:35:23  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:35:23  [ main:94 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:35:23  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:35:23  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:35:23  [ main:95 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:35:23  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:35:23  [ main:97 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:35:23  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:35:23  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:35:23  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:35:23  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:35:23  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:35:23  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:35:23  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:35:23  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:35:23  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:37:50  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:37:50  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:37:50  [ main:73 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:37:50  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:37:50  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:37:50  [ main:85 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:37:50  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:37:50  [ main:86 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:37:50  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:37:50  [ main:87 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:37:50  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:37:50  [ main:91 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:37:50  [ main:92 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:37:50  [ main:92 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:37:50  [ main:92 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:37:50  [ main:93 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:37:50  [ main:94 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:37:50  [ main:94 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:37:50  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:37:50  [ main:95 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:37:50  [ kafka-producer-network-thread | DemoProducer1:97 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:37:50  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:37:50  [ main:99 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:37:50  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:37:50  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:37:50  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:37:50  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:37:57  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:37:57  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:37:57  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:37:57  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:37:57  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:37:57  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:37:57  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:37:57  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:37:57  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:37:57  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:37:57  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:37:57  [ main:86 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:37:57  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:37:57  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:37:57  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:37:57  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:37:57  [ main:88 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:37:57  [ main:89 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:37:57  [ main:89 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:37:57  [ main:89 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:37:57  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:37:57  [ main:91 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:37:57  [ main:92 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:37:57  [ main:92 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:37:57  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:37:57  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:37:57  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:41:39  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:39  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:41:39  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:41:39  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:41:39  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:41:39  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:41:39  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:41:39  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:41:39  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:41:39  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:41:39  [ main:73 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:41:39  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:41:39  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:41:39  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:41:39  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:41:39  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:41:39  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:41:39  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:41:39  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:41:39  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:41:39  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:41:39  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:39  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:41:39  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:41:39  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:41:39  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:41:39  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:41:45  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:45  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:41:45  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:41:45  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:41:45  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:41:45  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:41:45  [ main:65 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:41:45  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:41:45  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:41:45  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:41:45  [ main:67 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:41:45  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:41:45  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:41:45  [ main:71 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:41:45  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:41:45  [ main:72 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:41:45  [ main:73 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:41:45  [ main:74 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:41:45  [ main:74 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:41:45  [ main:74 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:41:45  [ kafka-producer-network-thread | DemoProducer1:75 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:41:45  [ main:76 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:45  [ main:76 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:41:45  [ main:76 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:41:45  [ main:79 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:41:45  [ main:79 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:41:45  [ main:79 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:41:49  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:49  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:41:49  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:41:49  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:41:49  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:41:49  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:41:49  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:41:49  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:41:49  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:41:49  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:41:49  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:41:49  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:41:49  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:41:49  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:41:49  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:41:49  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:41:49  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:41:49  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:41:49  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:41:49  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:41:49  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:41:49  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:49  [ main:82 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:41:49  [ main:82 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:41:49  [ main:84 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:41:49  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:41:49  [ main:85 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:41:54  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:54  [ main:56 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:41:54  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:41:54  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:41:54  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:41:54  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:41:54  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:41:54  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:41:54  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:41:54  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:41:54  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:41:54  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:41:54  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:41:54  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:41:54  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:41:54  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:41:54  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:41:54  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:41:54  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:41:54  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:41:54  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:54  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:41:54  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:41:54  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:41:54  [ main:93 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:41:54  [ main:94 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:41:54  [ main:94 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:41:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:58  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:41:58  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:41:58  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:41:58  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:41:58  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:41:58  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:41:58  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:41:58  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:41:58  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:41:58  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:41:58  [ main:76 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:41:58  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:41:58  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:41:58  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:41:58  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:41:58  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:41:58  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:41:58  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:41:58  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:41:58  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:41:58  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:41:58  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:41:58  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:41:58  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:41:58  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:41:58  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:42:03  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:03  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:42:03  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:42:03  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:42:03  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:42:03  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:42:03  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:42:03  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:42:03  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:42:03  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:42:03  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:42:03  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:42:03  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:42:03  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:42:03  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:42:03  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:42:03  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:42:03  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:42:03  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:42:03  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:42:03  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:42:03  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:03  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:42:03  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:42:03  [ main:96 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:42:03  [ main:97 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:42:03  [ main:97 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:42:05  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:05  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:42:05  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:42:05  [ main:72 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:42:05  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:42:05  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:42:05  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:42:05  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:42:05  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:42:05  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:42:05  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:42:05  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:42:05  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:42:05  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:42:05  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:42:05  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:42:05  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:42:05  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:42:05  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:42:05  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:42:05  [ kafka-producer-network-thread | DemoProducer1:102 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:42:05  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:05  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:42:05  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:42:05  [ main:105 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:42:05  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:42:05  [ main:106 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:42:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:07  [ main:61 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:42:07  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:42:07  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:42:07  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:42:07  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:42:07  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:42:07  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:42:07  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:42:07  [ main:85 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:42:07  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:42:07  [ main:106 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:42:07  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:42:07  [ main:106 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:42:07  [ main:107 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:42:07  [ main:107 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:42:07  [ main:108 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:42:07  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:42:07  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:42:07  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:42:07  [ kafka-producer-network-thread | DemoProducer1:117 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:42:07  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:07  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:42:07  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:42:07  [ main:139 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:42:07  [ main:139 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:42:07  [ main:140 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:42:09  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:09  [ main:63 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:42:09  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:42:09  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:42:09  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:42:09  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:42:09  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:42:09  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:42:09  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:42:09  [ main:81 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:42:09  [ main:82 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:42:09  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:42:09  [ main:85 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:42:09  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:42:09  [ main:86 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:42:09  [ main:86 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:42:09  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:42:09  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:42:09  [ main:90 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:42:09  [ main:90 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:42:09  [ kafka-producer-network-thread | DemoProducer1:92 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:42:09  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:42:09  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:42:09  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:42:09  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:42:09  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:42:09  [ main:113 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:43:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:43:28  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:43:28  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:43:28  [ main:76 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:43:28  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:43:28  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:43:28  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:43:28  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:43:28  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:43:28  [ main:88 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:43:28  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:43:28  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:43:28  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:43:28  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:43:28  [ main:93 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:43:28  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:43:28  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:43:28  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:43:28  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:43:28  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:43:28  [ kafka-producer-network-thread | DemoProducer1:98 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:43:28  [ main:98 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:43:28  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:43:28  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:43:28  [ main:101 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:43:28  [ main:101 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:43:28  [ main:102 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:48:19  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:19  [ main:71 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:48:19  [ main:75 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:48:19  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:48:19  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:48:19  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:48:19  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:48:19  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:48:19  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:48:19  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:48:19  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:48:19  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:48:19  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:48:19  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:48:19  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:48:19  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:48:19  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:48:19  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:48:19  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:48:19  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:48:19  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:19  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:48:19  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:48:19  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:48:19  [ main:116 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:48:19  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:48:19  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:48:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:31  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:48:31  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:48:31  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:48:31  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:48:31  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:48:31  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:48:31  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:48:31  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:48:31  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:48:31  [ main:85 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:48:31  [ main:90 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:48:31  [ main:90 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:48:31  [ main:91 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:48:31  [ main:91 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:48:31  [ main:91 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:48:31  [ main:95 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:48:31  [ main:95 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:48:31  [ main:95 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:48:31  [ main:96 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:48:31  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:31  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:48:31  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:48:31  [ main:114 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:48:31  [ main:115 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:48:31  [ main:116 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:48:31  [ kafka-producer-network-thread | DemoProducer1:116 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:48:44  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:44  [ main:57 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:48:44  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:48:44  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:48:44  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:48:44  [ main:71 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:48:44  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:48:44  [ main:72 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:48:44  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:48:44  [ main:73 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:48:44  [ main:74 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:48:44  [ main:77 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:48:44  [ main:78 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:48:44  [ main:78 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:48:44  [ main:78 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:48:44  [ main:78 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:48:44  [ main:80 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:48:44  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:48:44  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:48:44  [ main:81 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:48:44  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:44  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:48:44  [ main:86 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:48:44  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:48:44  [ main:88 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:48:44  [ main:88 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:48:44  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:48:47  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:47  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:48:47  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:48:47  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:48:47  [ main:80 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:48:47  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:48:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:48:47  [ main:81 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:48:47  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:48:47  [ main:83 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:48:47  [ main:83 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:48:47  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:48:47  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:48:47  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:48:47  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:48:47  [ main:88 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:48:47  [ main:91 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:48:47  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:48:47  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:48:47  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:48:47  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:48:47  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:48:47  [ main:109 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:48:47  [ main:109 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:48:47  [ main:112 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:48:47  [ main:112 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:48:47  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:49:10  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:49:10  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:49:10  [ main:71 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:49:10  [ main:75 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:49:10  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:49:10  [ main:86 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:49:10  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:49:10  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:49:10  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:49:10  [ main:89 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:49:10  [ main:89 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:49:10  [ main:93 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:49:10  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:49:10  [ main:94 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:49:10  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:49:10  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:49:10  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:49:10  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:49:10  [ main:96 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:49:10  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:49:10  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:49:10  [ main:100 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:49:10  [ main:100 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:49:10  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:49:10  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:49:10  [ main:103 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:49:10  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:49:26  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:49:26  [ main:68 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:49:26  [ main:74 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:49:26  [ main:77 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:49:26  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:49:26  [ main:88 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:49:26  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:49:26  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:49:26  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:49:26  [ main:92 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:49:26  [ main:94 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:49:26  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:49:26  [ main:98 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:49:26  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:49:26  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:49:26  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:49:26  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:49:26  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:49:26  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:49:26  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:49:26  [ kafka-producer-network-thread | DemoProducer1:118 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:49:26  [ main:118 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:49:26  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:49:26  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:49:26  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:49:26  [ main:123 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:49:26  [ main:127 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:52:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:52:17  [ main:72 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:52:17  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:52:17  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:52:17  [ main:95 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:52:17  [ main:96 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:52:17  [ main:97 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:52:17  [ main:98 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:52:17  [ main:100 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:52:17  [ main:101 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:52:17  [ main:101 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:52:17  [ main:105 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:52:17  [ main:106 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:52:17  [ main:106 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:52:17  [ main:107 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:52:17  [ main:107 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:52:17  [ main:109 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:52:17  [ main:109 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:52:17  [ main:109 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:52:17  [ main:110 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:52:17  [ kafka-producer-network-thread | DemoProducer1:120 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:52:17  [ main:120 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:52:17  [ main:124 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:52:17  [ main:124 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:52:17  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:52:17  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:52:17  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:52:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:52:56  [ main:59 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:52:56  [ main:65 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:52:56  [ main:67 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:52:56  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:52:56  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:52:56  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:52:56  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:52:56  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:52:56  [ main:76 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:52:56  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:52:56  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:52:56  [ main:80 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:52:56  [ main:80 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:52:56  [ main:81 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:52:56  [ main:81 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:52:56  [ main:83 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:52:56  [ main:83 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:52:56  [ main:83 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:52:56  [ main:83 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:52:56  [ kafka-producer-network-thread | DemoProducer1:87 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:52:56  [ main:87 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:52:56  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:52:56  [ main:88 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:52:56  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:52:56  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:52:56  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:07  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:07  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:07  [ main:54 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:07  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:53:07  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:07  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:07  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:07  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:07  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:07  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:07  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:07  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:07  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:07  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:07  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:07  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:07  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:07  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:07  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:07  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:07  [ main:88 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:07  [ main:88 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:07  [ main:89 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:07  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:07  [ main:91 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:07  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:07  [ main:92 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:13  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:13  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:13  [ main:64 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:13  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:53:13  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:13  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:13  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:13  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:13  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:13  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:13  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:13  [ main:78 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:13  [ main:79 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:13  [ main:79 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:13  [ main:79 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:13  [ main:80 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:13  [ main:81 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:13  [ main:81 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:13  [ main:82 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:13  [ main:82 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:13  [ main:94 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:13  [ main:95 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:13  [ main:95 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:13  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:13  [ main:107 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:13  [ main:107 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:13  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:15  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:15  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:15  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:53:15  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:15  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:15  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:15  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:15  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:15  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:15  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:15  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:15  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:15  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:15  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:15  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:15  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:15  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:15  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:15  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:15  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:15  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:15  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:15  [ kafka-producer-network-thread | DemoProducer1:88 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:15  [ main:89 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:15  [ main:89 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:15  [ main:89 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:18  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:18  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:18  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:53:18  [ main:81 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:18  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:18  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:18  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:18  [ main:85 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:18  [ main:86 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:18  [ main:87 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:18  [ main:92 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:18  [ main:93 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:18  [ main:93 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:18  [ main:94 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:18  [ main:94 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:18  [ main:96 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:18  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:18  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:18  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:18  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:18  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:18  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:18  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:18  [ main:116 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:18  [ main:116 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:18  [ main:117 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:20  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:20  [ main:65 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:20  [ main:69 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:20  [ main:71 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:53:20  [ main:78 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:20  [ main:79 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:20  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:20  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:20  [ main:80 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:20  [ main:80 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:20  [ main:81 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:20  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:20  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:20  [ main:85 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:20  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:20  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:20  [ main:87 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:20  [ main:88 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:20  [ main:88 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:20  [ main:88 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:20  [ main:99 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:20  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:20  [ main:102 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:20  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:20  [ main:108 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:20  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:20  [ main:109 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:23  [ main:64 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:23  [ main:70 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:23  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:53:23  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:23  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:23  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:23  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:23  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:23  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:23  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:23  [ main:87 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:23  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:23  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:23  [ main:88 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:23  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:23  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:23  [ main:90 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:23  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:23  [ main:91 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:23  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:23  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:23  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:23  [ kafka-producer-network-thread | DemoProducer1:95 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:23  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:23  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:23  [ main:96 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:25  [ main:86 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:25  [ main:92 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:25  [ main:94 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:53:25  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:25  [ main:104 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:25  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:25  [ main:105 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:25  [ main:106 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:25  [ main:106 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:25  [ main:106 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:25  [ main:110 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:25  [ main:110 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:25  [ main:110 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:25  [ main:111 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:25  [ main:111 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:25  [ main:112 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:25  [ main:113 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:25  [ main:114 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:25  [ main:114 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:25  [ main:133 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:25  [ main:136 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:25  [ main:136 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:25  [ main:139 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:25  [ main:139 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:25  [ main:141 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:25  [ kafka-producer-network-thread | DemoProducer1:150 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:27  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:27  [ main:58 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:27  [ main:63 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:27  [ main:65 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:53:27  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:27  [ main:74 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:27  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:27  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:27  [ main:76 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:27  [ main:77 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:27  [ main:77 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:27  [ main:80 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:27  [ main:81 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:27  [ main:81 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:27  [ main:82 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:27  [ main:82 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:27  [ main:85 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:27  [ main:85 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:27  [ main:85 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:27  [ main:86 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:27  [ main:97 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:27  [ main:98 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:27  [ main:99 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:27  [ kafka-producer-network-thread | DemoProducer1:99 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:27  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:27  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:27  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:29  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:29  [ main:69 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:29  [ main:76 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:29  [ main:78 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:53:29  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:29  [ main:87 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:29  [ main:87 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:29  [ main:88 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:29  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:29  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:29  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:29  [ main:96 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:29  [ main:97 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:29  [ main:98 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:29  [ main:98 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:29  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:29  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:29  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:29  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:29  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:29  [ main:110 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:29  [ main:111 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:29  [ main:111 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:29  [ kafka-producer-network-thread | DemoProducer1:113 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:29  [ main:123 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:29  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:29  [ main:124 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:31  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:31  [ main:75 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:31  [ main:81 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:31  [ main:83 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:53:31  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:31  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:31  [ main:92 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:31  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:31  [ main:94 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:31  [ main:95 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:31  [ main:95 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:31  [ main:98 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:31  [ main:99 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:31  [ main:99 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:31  [ main:99 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:31  [ main:99 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:31  [ main:101 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:31  [ main:101 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:31  [ main:101 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:31  [ main:101 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:31  [ main:111 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:31  [ main:112 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:31  [ kafka-producer-network-thread | DemoProducer1:112 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:31  [ main:112 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:31  [ main:121 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:31  [ main:121 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:31  [ main:122 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:33  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:33  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:33  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:33  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:53:33  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:33  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:33  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:33  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:33  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:33  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:33  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:33  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:33  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:33  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:33  [ main:77 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:33  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:33  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:33  [ main:80 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:33  [ main:80 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:33  [ main:80 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:33  [ main:93 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:33  [ main:94 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:33  [ main:94 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:33  [ kafka-producer-network-thread | DemoProducer1:96 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:33  [ main:102 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:33  [ main:102 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:33  [ main:103 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:53:35  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:35  [ main:73 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:53:35  [ main:77 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:53:35  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:53:35  [ main:89 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:53:35  [ main:90 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:53:35  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:53:35  [ main:90 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:53:35  [ main:91 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:53:35  [ main:91 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:53:35  [ main:92 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:53:35  [ main:95 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:53:35  [ main:96 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:53:35  [ main:96 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:53:35  [ main:96 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:53:35  [ main:97 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:53:35  [ main:98 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:53:35  [ main:98 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:53:35  [ main:99 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:53:35  [ main:99 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:53:35  [ kafka-producer-network-thread | DemoProducer1:101 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:53:35  [ main:101 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:53:35  [ main:102 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:53:35  [ main:106 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:53:35  [ main:109 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:53:35  [ main:109 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:53:35  [ main:112 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:54:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:54:38  [ main:49 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:54:38  [ main:55 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:54:38  [ main:57 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:54:38  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:54:38  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:54:38  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:54:38  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:54:38  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:54:38  [ main:68 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:54:38  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:54:38  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:54:38  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:54:38  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:54:38  [ main:73 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:54:38  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:54:38  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:54:38  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:54:38  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:54:38  [ main:75 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:54:38  [ kafka-producer-network-thread | DemoProducer1:78 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:54:38  [ main:78 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:54:38  [ main:79 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:54:38  [ main:79 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:54:38  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:54:38  [ main:82 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:54:38  [ main:82 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:10  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:10  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:10  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:10  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:10  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:10  [ main:73 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:10  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:10  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:10  [ main:75 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:10  [ main:75 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:10  [ main:76 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:10  [ main:89 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:10  [ main:89 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:10  [ main:90 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:10  [ main:90 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:10  [ main:90 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:10  [ main:92 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:10  [ main:92 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:10  [ main:92 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:10  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:10  [ main:102 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:10  [ main:103 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:10  [ main:103 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:10  [ kafka-producer-network-thread | DemoProducer1:104 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:10  [ main:106 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:10  [ main:106 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:10  [ main:107 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:16  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:16  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:16  [ main:58 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:16  [ main:60 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:16  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:16  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:16  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:16  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:16  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:16  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:16  [ main:70 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:16  [ main:73 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:16  [ main:74 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:16  [ main:74 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:16  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:16  [ main:75 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:16  [ main:76 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:16  [ main:77 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:16  [ main:77 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:16  [ main:77 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:16  [ kafka-producer-network-thread | DemoProducer1:82 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:16  [ main:83 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:16  [ main:83 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:16  [ main:83 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:16  [ main:86 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:16  [ main:86 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:16  [ main:87 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:18  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:19  [ main:89 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:19  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:19  [ main:97 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:19  [ main:107 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:19  [ main:108 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:19  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:19  [ main:108 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:19  [ main:109 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:19  [ main:110 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:19  [ main:110 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:19  [ main:113 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:19  [ main:114 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:19  [ main:114 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:19  [ main:114 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:19  [ main:115 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:19  [ main:118 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:19  [ main:118 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:19  [ main:119 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:19  [ main:119 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:19  [ kafka-producer-network-thread | DemoProducer1:133 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:19  [ main:134 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:19  [ main:135 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:19  [ main:135 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:19  [ main:156 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:19  [ main:156 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:19  [ main:162 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:21  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:21  [ main:89 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:21  [ main:97 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:21  [ main:101 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:21  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:21  [ main:114 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:21  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:21  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:21  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:21  [ main:116 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:21  [ main:116 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:21  [ main:119 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:21  [ main:120 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:21  [ main:121 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:21  [ main:121 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:21  [ main:122 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:21  [ main:131 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:21  [ main:133 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:21  [ main:133 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:21  [ main:133 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:21  [ kafka-producer-network-thread | DemoProducer1:148 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:21  [ main:149 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:21  [ main:149 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:21  [ main:149 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:21  [ main:152 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:21  [ main:152 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:21  [ main:153 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:23  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:23  [ main:85 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:23  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:23  [ main:100 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:23  [ main:111 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:23  [ main:112 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:23  [ main:112 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:23  [ main:113 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:23  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:23  [ main:116 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:23  [ main:117 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:23  [ main:136 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:23  [ main:136 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:23  [ main:137 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:23  [ main:137 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:23  [ main:138 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:23  [ main:146 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:23  [ main:146 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:23  [ main:146 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:23  [ main:146 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:23  [ kafka-producer-network-thread | DemoProducer1:151 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:23  [ main:151 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:23  [ main:153 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:23  [ main:153 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:23  [ main:155 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:23  [ main:155 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:23  [ main:156 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:25  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:25  [ main:66 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:25  [ main:72 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:25  [ main:74 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:25  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:25  [ main:82 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:25  [ main:82 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:25  [ main:83 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:25  [ main:84 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:25  [ main:84 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:25  [ main:84 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:25  [ main:88 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:25  [ main:88 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:25  [ main:88 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:25  [ main:89 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:25  [ main:89 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:25  [ main:90 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:25  [ main:91 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:25  [ main:91 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:25  [ main:92 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:25  [ kafka-producer-network-thread | DemoProducer1:106 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:25  [ main:107 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:25  [ main:107 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:25  [ main:108 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:25  [ main:110 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:25  [ main:110 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:25  [ main:111 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:28  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:28  [ main:98 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:28  [ main:108 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:28  [ main:111 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:28  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:28  [ main:126 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:28  [ main:127 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:28  [ main:128 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:28  [ main:129 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:28  [ main:130 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:28  [ main:131 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:28  [ main:135 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:28  [ main:136 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:28  [ main:137 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:28  [ main:138 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:28  [ main:138 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:28  [ main:149 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:28  [ main:150 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:28  [ main:150 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:28  [ main:151 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:28  [ kafka-producer-network-thread | DemoProducer1:166 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:28  [ main:166 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:28  [ main:167 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:28  [ main:167 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:28  [ main:170 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:28  [ main:170 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:28  [ main:171 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:32  [ main:1 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:32  [ main:62 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:32  [ main:68 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:32  [ main:70 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:32  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:32  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:32  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:32  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:32  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:32  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:32  [ main:84 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:32  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:32  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:32  [ main:85 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:32  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:32  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:32  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:32  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:32  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:32  [ kafka-producer-network-thread | DemoProducer1:89 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:32  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:32  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:32  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:32  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:32  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:32  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:34  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:34  [ main:87 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:34  [ main:95 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:34  [ main:101 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:55:34  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:34  [ main:113 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:34  [ main:114 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:34  [ main:115 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:34  [ main:117 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:34  [ main:118 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:34  [ main:118 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:34  [ main:135 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:34  [ main:136 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:34  [ main:137 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:34  [ main:137 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:34  [ main:137 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:34  [ main:139 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:34  [ main:139 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:34  [ main:140 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:34  [ main:140 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:34  [ kafka-producer-network-thread | DemoProducer1:145 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:34  [ main:145 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:34  [ main:146 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:34  [ main:146 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:34  [ main:149 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:34  [ main:158 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:34  [ main:159 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:36  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:36  [ main:84 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:36  [ main:91 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:36  [ main:93 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:36  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:36  [ main:101 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:36  [ main:101 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:36  [ main:102 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:36  [ main:103 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:36  [ main:103 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:36  [ main:103 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:36  [ main:107 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:36  [ main:108 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:36  [ main:108 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:36  [ main:109 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:36  [ main:109 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:36  [ main:111 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:36  [ main:111 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:36  [ main:111 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:36  [ main:111 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:36  [ kafka-producer-network-thread | DemoProducer1:116 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:36  [ main:117 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:36  [ main:119 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:36  [ main:119 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:36  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:36  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:36  [ main:128 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:38  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:38  [ main:53 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:38  [ main:57 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:38  [ main:59 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:38  [ main:66 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:38  [ main:67 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:38  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:38  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:38  [ main:68 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:38  [ main:69 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:38  [ main:69 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:38  [ main:72 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:38  [ main:73 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:38  [ main:73 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:38  [ main:74 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:38  [ main:74 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:38  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:38  [ main:76 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:38  [ main:76 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:38  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:38  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:38  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:38  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:38  [ kafka-producer-network-thread | DemoProducer1:81 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:38  [ main:83 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:38  [ main:84 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:38  [ main:84 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:41  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:41  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:41  [ main:62 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:41  [ main:63 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:41  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:41  [ main:72 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:41  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:41  [ main:73 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:41  [ main:74 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:41  [ main:74 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:41  [ main:75 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:41  [ main:85 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:41  [ main:86 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:41  [ main:86 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:41  [ main:87 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:41  [ main:87 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:41  [ main:89 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:41  [ main:96 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:41  [ main:97 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:41  [ main:97 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:41  [ kafka-producer-network-thread | DemoProducer1:111 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:41  [ main:112 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:41  [ main:113 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:41  [ main:113 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:41  [ main:127 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:41  [ main:127 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:41  [ main:132 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:56  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:56  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:56  [ main:61 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:56  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:55:56  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:56  [ main:70 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:56  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:56  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:56  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:56  [ main:72 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:56  [ main:72 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:56  [ main:75 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:56  [ main:76 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:56  [ main:76 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:56  [ main:76 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:56  [ main:77 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:56  [ main:78 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:56  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:56  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:56  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:56  [ main:81 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:56  [ main:81 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:56  [ main:81 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:56  [ kafka-producer-network-thread | DemoProducer1:86 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:56  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:56  [ main:90 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:56  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:55:58  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:58  [ main:60 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:55:58  [ main:67 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:55:58  [ main:69 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 19:55:58  [ main:76 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:55:58  [ main:77 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:55:58  [ main:77 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:55:58  [ main:78 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:55:58  [ main:79 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:55:58  [ main:79 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:55:58  [ main:80 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:55:58  [ main:83 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:55:58  [ main:84 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:55:58  [ main:84 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:55:58  [ main:84 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:55:58  [ main:85 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:55:58  [ main:86 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:55:58  [ main:87 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:55:58  [ main:87 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:55:58  [ main:87 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:55:58  [ main:89 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:55:58  [ main:90 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:55:58  [ main:90 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:55:58  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:55:58  [ main:92 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:55:58  [ main:92 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:55:58  [ main:93 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:56:00  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:56:00  [ main:74 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:56:00  [ main:80 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:56:00  [ main:82 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.221:9092 (id: -2 rack: null)], partitions = [])
2017-06-27 19:56:00  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:56:00  [ main:92 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:56:00  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:56:00  [ main:93 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:56:00  [ main:95 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:56:00  [ main:96 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:56:00  [ main:98 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:56:00  [ main:102 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:56:00  [ main:103 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:56:00  [ main:104 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:56:00  [ main:106 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:56:00  [ main:106 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:56:00  [ main:116 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:56:00  [ main:117 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:56:00  [ main:117 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:56:00  [ main:117 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:56:00  [ kafka-producer-network-thread | DemoProducer1:119 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:56:00  [ main:120 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:56:00  [ main:120 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:56:00  [ main:121 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:56:00  [ main:124 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:56:00  [ main:124 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:56:00  [ main:125 ] - [ DEBUG ]  Kafka producer started
2017-06-27 19:59:32  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:59:32  [ main:52 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 19:59:32  [ main:56 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 19:59:32  [ main:58 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null), 192.168.0.222:9092 (id: -3 rack: null)], partitions = [])
2017-06-27 19:59:32  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 19:59:32  [ main:65 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 19:59:32  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 19:59:32  [ main:66 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 19:59:32  [ main:67 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 19:59:32  [ main:67 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 19:59:32  [ main:68 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 19:59:32  [ main:71 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 19:59:32  [ main:71 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 19:59:32  [ main:72 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 19:59:32  [ main:72 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 19:59:32  [ main:73 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 19:59:32  [ main:75 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 19:59:32  [ main:75 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 19:59:32  [ main:75 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 19:59:32  [ main:76 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 19:59:32  [ kafka-producer-network-thread | DemoProducer1:79 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 19:59:32  [ main:79 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 19:59:32  [ main:80 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 19:59:32  [ main:80 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 19:59:32  [ main:82 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 19:59:32  [ main:83 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 19:59:32  [ main:83 ] - [ DEBUG ]  Kafka producer started
2017-06-27 20:01:15  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 20:01:15  [ main:55 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 20:01:15  [ main:59 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 20:01:15  [ main:61 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.222:9092 (id: -3 rack: null), 192.168.0.221:9092 (id: -2 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 20:01:15  [ main:68 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 20:01:15  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 20:01:15  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 20:01:15  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 20:01:15  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 20:01:15  [ main:70 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 20:01:15  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 20:01:15  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 20:01:15  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 20:01:15  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 20:01:15  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 20:01:15  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 20:01:15  [ main:77 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 20:01:15  [ main:78 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 20:01:15  [ main:78 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 20:01:15  [ main:78 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 20:01:15  [ kafka-producer-network-thread | DemoProducer1:91 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 20:01:15  [ main:92 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 20:01:15  [ main:93 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 20:01:15  [ main:93 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 20:01:15  [ main:95 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 20:01:15  [ main:96 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 20:01:15  [ main:101 ] - [ DEBUG ]  Kafka producer started
2017-06-27 20:01:16  [ main:1216 ] - [ INFO ]  user number : 1224  , send message count : 18671
2017-06-27 20:01:24  [ main:9584 ] - [ INFO ]  user number : 1224  , send message count : 18676
2017-06-27 20:01:30  [ main:0 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 20:01:30  [ main:54 ] - [ DEBUG ]  Added sensor with name bufferpool-wait-time
2017-06-27 20:01:30  [ main:60 ] - [ DEBUG ]  Added sensor with name buffer-exhausted-records
2017-06-27 20:01:30  [ main:62 ] - [ DEBUG ]  Updated cluster metadata version 1 to Cluster(nodes = [192.168.0.221:9092 (id: -2 rack: null), 192.168.0.222:9092 (id: -3 rack: null), 192.168.0.220:9092 (id: -1 rack: null)], partitions = [])
2017-06-27 20:01:30  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-closed:
2017-06-27 20:01:30  [ main:69 ] - [ DEBUG ]  Added sensor with name connections-created:
2017-06-27 20:01:30  [ main:69 ] - [ DEBUG ]  Added sensor with name bytes-sent-received:
2017-06-27 20:01:30  [ main:70 ] - [ DEBUG ]  Added sensor with name bytes-sent:
2017-06-27 20:01:30  [ main:71 ] - [ DEBUG ]  Added sensor with name bytes-received:
2017-06-27 20:01:30  [ main:71 ] - [ DEBUG ]  Added sensor with name select-time:
2017-06-27 20:01:30  [ main:71 ] - [ DEBUG ]  Added sensor with name io-time:
2017-06-27 20:01:30  [ main:74 ] - [ DEBUG ]  Added sensor with name batch-size
2017-06-27 20:01:30  [ main:75 ] - [ DEBUG ]  Added sensor with name compression-rate
2017-06-27 20:01:30  [ main:75 ] - [ DEBUG ]  Added sensor with name queue-time
2017-06-27 20:01:30  [ main:75 ] - [ DEBUG ]  Added sensor with name request-time
2017-06-27 20:01:30  [ main:76 ] - [ DEBUG ]  Added sensor with name produce-throttle-time
2017-06-27 20:01:30  [ main:79 ] - [ DEBUG ]  Added sensor with name records-per-request
2017-06-27 20:01:30  [ main:79 ] - [ DEBUG ]  Added sensor with name record-retries
2017-06-27 20:01:30  [ main:79 ] - [ DEBUG ]  Added sensor with name errors
2017-06-27 20:01:30  [ main:79 ] - [ DEBUG ]  Added sensor with name record-size-max
2017-06-27 20:01:30  [ kafka-producer-network-thread | DemoProducer1:83 ] - [ DEBUG ]  Starting Kafka producer I/O thread.
2017-06-27 20:01:30  [ main:84 ] - [ INFO ]  ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.0.220:9092, 192.168.0.221:9092, 192.168.0.222:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = DemoProducer1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

2017-06-27 20:01:30  [ main:85 ] - [ WARN ]  The configuration numOfDayBefore = 1 was supplied but isn't a known config.
2017-06-27 20:01:30  [ main:85 ] - [ WARN ]  The configuration topic = testRealTime0626 was supplied but isn't a known config.
2017-06-27 20:01:30  [ main:90 ] - [ INFO ]  Kafka version : 0.10.0.1
2017-06-27 20:01:30  [ main:91 ] - [ INFO ]  Kafka commitId : a7a17cdec9eaa6c5
2017-06-27 20:01:30  [ main:91 ] - [ DEBUG ]  Kafka producer started
2017-06-27 20:01:31  [ main:962 ] - [ INFO ]  user number : 1232  , send message count : 18275
2017-06-27 20:01:42  [ main:12015 ] - [ INFO ]  user number : 1232  , send message count : 18280
2017-06-27 20:01:53  [ main:23583 ] - [ INFO ]  user number : 1233  , send message count : 18312
2017-06-27 20:01:54  [ main:24127 ] - [ INFO ]  user number : 1234  , send message count : 18317
2017-06-27 20:01:54  [ main:24308 ] - [ INFO ]  user number : 1234  , send message count : 18319
2017-06-27 20:01:57  [ main:26745 ] - [ INFO ]  user number : 1234  , send message count : 18327
2017-06-27 20:02:10  [ main:40062 ] - [ INFO ]  user number : 1234  , send message count : 18329
2017-06-27 20:02:21  [ main:50738 ] - [ INFO ]  user number : 1235  , send message count : 18340
2017-06-27 20:02:22  [ main:52170 ] - [ INFO ]  user number : 1236  , send message count : 18354
2017-06-27 20:02:31  [ main:61488 ] - [ INFO ]  user number : 1236  , send message count : 18359
2017-06-27 20:02:44  [ main:74369 ] - [ INFO ]  user number : 1236  , send message count : 18367
2017-06-27 20:02:57  [ main:87398 ] - [ INFO ]  user number : 1236  , send message count : 18380
2017-06-27 20:03:04  [ main:93997 ] - [ INFO ]  user number : 1237  , send message count : 18385
2017-06-27 20:03:15  [ main:105555 ] - [ INFO ]  user number : 1237  , send message count : 18410
2017-06-27 20:03:28  [ main:118445 ] - [ INFO ]  user number : 1237  , send message count : 18416
2017-06-27 20:03:41  [ main:130828 ] - [ INFO ]  user number : 1238  , send message count : 18430
2017-06-27 20:03:53  [ main:143581 ] - [ INFO ]  user number : 1238  , send message count : 18457
2017-06-27 20:04:00  [ main:150566 ] - [ INFO ]  user number : 1238  , send message count : 18465
2017-06-27 20:04:10  [ main:160537 ] - [ INFO ]  user number : 1238  , send message count : 18467
2017-06-27 20:04:22  [ main:171688 ] - [ INFO ]  user number : 1239  , send message count : 18475
2017-06-27 20:04:29  [ main:179521 ] - [ INFO ]  user number : 1239  , send message count : 18483
2017-06-27 20:04:44  [ main:193907 ] - [ INFO ]  user number : 1239  , send message count : 18488
2017-06-27 20:04:44  [ main:194223 ] - [ INFO ]  user number : 1239  , send message count : 18493
